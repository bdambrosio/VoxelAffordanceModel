{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 12790,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0,
      "step": 0,
      "train/forward_time_ms": 626.1322498321533,
      "train/loss": 2.300182580947876,
      "train/loss_affordance": 0.7955203652381897,
      "train/loss_compute_time_ms": 77.34537124633789,
      "train/loss_risk": 0.7955203652381897,
      "train/loss_structure": 0.7091418504714966
    },
    {
      "epoch": 0,
      "step": 0,
      "train/forward_time_ms": 744.68994140625,
      "train/step_time_ms": 744.6911334991455
    },
    {
      "epoch": 0.039093041438623924,
      "grad_norm": 1.3060911893844604,
      "learning_rate": 9.961688819390149e-05,
      "loss": 2.1844,
      "step": 50
    },
    {
      "epoch": 0.039093041438623924,
      "step": 50,
      "train/forward_time_ms": 2.5458335876464844,
      "train/loss": 1.933010458946228,
      "train/loss_affordance": 0.6504721641540527,
      "train/loss_compute_time_ms": 0.2589225769042969,
      "train/loss_risk": 0.6504721641540527,
      "train/loss_structure": 0.6320661306381226
    },
    {
      "epoch": 0.039093041438623924,
      "step": 50,
      "train/forward_time_ms": 4.572644233703613,
      "train/step_time_ms": 4.5731401443481445
    },
    {
      "epoch": 0.07818608287724785,
      "grad_norm": 1.393845558166504,
      "learning_rate": 9.922595777951526e-05,
      "loss": 1.46,
      "step": 100
    },
    {
      "epoch": 0.07818608287724785,
      "step": 100,
      "train/forward_time_ms": 2.707958221435547,
      "train/loss": 0.9735536575317383,
      "train/loss_affordance": 0.310770720243454,
      "train/loss_compute_time_ms": 0.3509521484375,
      "train/loss_risk": 0.310770720243454,
      "train/loss_structure": 0.3520122170448303
    },
    {
      "epoch": 0.07818608287724785,
      "step": 100,
      "train/forward_time_ms": 4.394207000732422,
      "train/step_time_ms": 4.394664764404297
    },
    {
      "epoch": 0.11727912431587177,
      "grad_norm": 0.88113933801651,
      "learning_rate": 9.8835027365129e-05,
      "loss": 0.7529,
      "step": 150
    },
    {
      "epoch": 0.11727912431587177,
      "step": 150,
      "train/forward_time_ms": 2.6264190673828125,
      "train/loss": 0.562127411365509,
      "train/loss_affordance": 0.15845512598752975,
      "train/loss_compute_time_ms": 0.3802776336669922,
      "train/loss_risk": 0.15845512598752975,
      "train/loss_structure": 0.24521715939044952
    },
    {
      "epoch": 0.11727912431587177,
      "step": 150,
      "train/forward_time_ms": 4.411482810974121,
      "train/step_time_ms": 4.412598609924316
    },
    {
      "epoch": 0.1563721657544957,
      "grad_norm": 0.5166680812835693,
      "learning_rate": 9.844409695074277e-05,
      "loss": 0.4386,
      "step": 200
    },
    {
      "epoch": 0.1563721657544957,
      "step": 200,
      "train/forward_time_ms": 2.4573802947998047,
      "train/loss": 0.3429056406021118,
      "train/loss_affordance": 0.09582524001598358,
      "train/loss_compute_time_ms": 0.2994537353515625,
      "train/loss_risk": 0.09582524001598358,
      "train/loss_structure": 0.15125516057014465
    },
    {
      "epoch": 0.1563721657544957,
      "step": 200,
      "train/forward_time_ms": 4.757847785949707,
      "train/step_time_ms": 4.758424758911133
    },
    {
      "epoch": 0.19546520719311963,
      "grad_norm": 0.33237072825431824,
      "learning_rate": 9.805316653635653e-05,
      "loss": 0.3488,
      "step": 250
    },
    {
      "epoch": 0.19546520719311963,
      "step": 250,
      "train/forward_time_ms": 2.2478103637695312,
      "train/loss": 0.3886489272117615,
      "train/loss_affordance": 0.10730805993080139,
      "train/loss_compute_time_ms": 0.28777122497558594,
      "train/loss_risk": 0.10730805993080139,
      "train/loss_structure": 0.1740328073501587
    },
    {
      "epoch": 0.19546520719311963,
      "step": 250,
      "train/forward_time_ms": 4.43394660949707,
      "train/step_time_ms": 4.4344329833984375
    },
    {
      "epoch": 0.23455824863174354,
      "grad_norm": 0.43805474042892456,
      "learning_rate": 9.76622361219703e-05,
      "loss": 0.3163,
      "step": 300
    },
    {
      "epoch": 0.23455824863174354,
      "step": 300,
      "train/forward_time_ms": 2.430438995361328,
      "train/loss": 0.3255821466445923,
      "train/loss_affordance": 0.09295137226581573,
      "train/loss_compute_time_ms": 0.27108192443847656,
      "train/loss_risk": 0.09295137226581573,
      "train/loss_structure": 0.13967940211296082
    },
    {
      "epoch": 0.23455824863174354,
      "step": 300,
      "train/forward_time_ms": 4.420042037963867,
      "train/step_time_ms": 4.420504570007324
    },
    {
      "epoch": 0.2736512900703675,
      "grad_norm": 0.44033437967300415,
      "learning_rate": 9.727130570758406e-05,
      "loss": 0.2888,
      "step": 350
    },
    {
      "epoch": 0.2736512900703675,
      "step": 350,
      "train/forward_time_ms": 2.212047576904297,
      "train/loss": 0.2259121686220169,
      "train/loss_affordance": 0.06829111278057098,
      "train/loss_compute_time_ms": 0.31948089599609375,
      "train/loss_risk": 0.06829111278057098,
      "train/loss_structure": 0.08932994306087494
    },
    {
      "epoch": 0.2736512900703675,
      "step": 350,
      "train/forward_time_ms": 4.3689727783203125,
      "train/step_time_ms": 4.3694257736206055
    },
    {
      "epoch": 0.3127443315089914,
      "grad_norm": 0.4883783161640167,
      "learning_rate": 9.688037529319781e-05,
      "loss": 0.2608,
      "step": 400
    },
    {
      "epoch": 0.3127443315089914,
      "step": 400,
      "train/forward_time_ms": 2.2971630096435547,
      "train/loss": 0.2476242631673813,
      "train/loss_affordance": 0.07723405957221985,
      "train/loss_compute_time_ms": 0.3027915954589844,
      "train/loss_risk": 0.07723405957221985,
      "train/loss_structure": 0.09315614402294159
    },
    {
      "epoch": 0.3127443315089914,
      "step": 400,
      "train/forward_time_ms": 4.700865745544434,
      "train/step_time_ms": 4.701504707336426
    },
    {
      "epoch": 0.3518373729476153,
      "grad_norm": 0.38212016224861145,
      "learning_rate": 9.648944487881157e-05,
      "loss": 0.2359,
      "step": 450
    },
    {
      "epoch": 0.3518373729476153,
      "step": 450,
      "train/forward_time_ms": 2.353191375732422,
      "train/loss": 0.2458326518535614,
      "train/loss_affordance": 0.07897322624921799,
      "train/loss_compute_time_ms": 0.3192424774169922,
      "train/loss_risk": 0.07897322624921799,
      "train/loss_structure": 0.08788619935512543
    },
    {
      "epoch": 0.3518373729476153,
      "step": 450,
      "train/forward_time_ms": 4.423642158508301,
      "train/step_time_ms": 4.4242143630981445
    },
    {
      "epoch": 0.39093041438623927,
      "grad_norm": 0.4232000708580017,
      "learning_rate": 9.609851446442534e-05,
      "loss": 0.2301,
      "step": 500
    },
    {
      "epoch": 0.39093041438623927,
      "step": 500,
      "train/forward_time_ms": 2.3975372314453125,
      "train/loss": 0.17426159977912903,
      "train/loss_affordance": 0.050573352724313736,
      "train/loss_compute_time_ms": 0.37026405334472656,
      "train/loss_risk": 0.050573352724313736,
      "train/loss_structure": 0.07311489433050156
    },
    {
      "epoch": 0.39093041438623927,
      "step": 500,
      "train/forward_time_ms": 4.314060211181641,
      "train/step_time_ms": 4.3145036697387695
    },
    {
      "epoch": 0.4300234558248632,
      "grad_norm": 0.3419315218925476,
      "learning_rate": 9.57075840500391e-05,
      "loss": 0.2179,
      "step": 550
    },
    {
      "epoch": 0.4300234558248632,
      "step": 550,
      "train/forward_time_ms": 2.247333526611328,
      "train/loss": 0.20670254528522491,
      "train/loss_affordance": 0.059467412531375885,
      "train/loss_compute_time_ms": 0.33473968505859375,
      "train/loss_risk": 0.059467412531375885,
      "train/loss_structure": 0.08776772022247314
    },
    {
      "epoch": 0.4300234558248632,
      "step": 550,
      "train/forward_time_ms": 4.5446062088012695,
      "train/step_time_ms": 4.545116424560547
    },
    {
      "epoch": 0.4691164972634871,
      "grad_norm": 0.22553113102912903,
      "learning_rate": 9.531665363565287e-05,
      "loss": 0.2017,
      "step": 600
    },
    {
      "epoch": 0.4691164972634871,
      "step": 600,
      "train/forward_time_ms": 2.319812774658203,
      "train/loss": 0.16507616639137268,
      "train/loss_affordance": 0.05199854634702206,
      "train/loss_compute_time_ms": 0.3268718719482422,
      "train/loss_risk": 0.05199854634702206,
      "train/loss_structure": 0.06107907369732857
    },
    {
      "epoch": 0.4691164972634871,
      "step": 600,
      "train/forward_time_ms": 4.5252180099487305,
      "train/step_time_ms": 4.525794982910156
    },
    {
      "epoch": 0.508209538702111,
      "grad_norm": 0.31278276443481445,
      "learning_rate": 9.492572322126661e-05,
      "loss": 0.2038,
      "step": 650
    },
    {
      "epoch": 0.508209538702111,
      "step": 650,
      "train/forward_time_ms": 2.277851104736328,
      "train/loss": 0.13881944119930267,
      "train/loss_affordance": 0.042821187525987625,
      "train/loss_compute_time_ms": 0.3066062927246094,
      "train/loss_risk": 0.042821187525987625,
      "train/loss_structure": 0.05317706614732742
    },
    {
      "epoch": 0.508209538702111,
      "step": 650,
      "train/forward_time_ms": 4.278807640075684,
      "train/step_time_ms": 4.279303550720215
    },
    {
      "epoch": 0.547302580140735,
      "grad_norm": 0.5098376870155334,
      "learning_rate": 9.453479280688038e-05,
      "loss": 0.185,
      "step": 700
    },
    {
      "epoch": 0.547302580140735,
      "step": 700,
      "train/forward_time_ms": 2.242565155029297,
      "train/loss": 0.15295688807964325,
      "train/loss_affordance": 0.045610930770635605,
      "train/loss_compute_time_ms": 0.3783702850341797,
      "train/loss_risk": 0.045610930770635605,
      "train/loss_structure": 0.06173502653837204
    },
    {
      "epoch": 0.547302580140735,
      "step": 700,
      "train/forward_time_ms": 4.3821001052856445,
      "train/step_time_ms": 4.382519721984863
    },
    {
      "epoch": 0.5863956215793589,
      "grad_norm": 0.1621398776769638,
      "learning_rate": 9.414386239249414e-05,
      "loss": 0.1731,
      "step": 750
    },
    {
      "epoch": 0.5863956215793589,
      "step": 750,
      "train/forward_time_ms": 2.343893051147461,
      "train/loss": 0.17602112889289856,
      "train/loss_affordance": 0.05747925862669945,
      "train/loss_compute_time_ms": 0.3020763397216797,
      "train/loss_risk": 0.05747925862669945,
      "train/loss_structure": 0.061062611639499664
    },
    {
      "epoch": 0.5863956215793589,
      "step": 750,
      "train/forward_time_ms": 4.578976631164551,
      "train/step_time_ms": 4.57942008972168
    },
    {
      "epoch": 0.6254886630179828,
      "grad_norm": 0.5561844706535339,
      "learning_rate": 9.375293197810791e-05,
      "loss": 0.1775,
      "step": 800
    },
    {
      "epoch": 0.6254886630179828,
      "step": 800,
      "train/forward_time_ms": 2.372264862060547,
      "train/loss": 0.11559832841157913,
      "train/loss_affordance": 0.036069922149181366,
      "train/loss_compute_time_ms": 0.34689903259277344,
      "train/loss_risk": 0.036069922149181366,
      "train/loss_structure": 0.0434584841132164
    },
    {
      "epoch": 0.6254886630179828,
      "step": 800,
      "train/forward_time_ms": 4.452943801879883,
      "train/step_time_ms": 4.453415870666504
    },
    {
      "epoch": 0.6645817044566067,
      "grad_norm": 0.1893274486064911,
      "learning_rate": 9.336200156372165e-05,
      "loss": 0.1715,
      "step": 850
    },
    {
      "epoch": 0.6645817044566067,
      "step": 850,
      "train/forward_time_ms": 2.6056766510009766,
      "train/loss": 0.16798606514930725,
      "train/loss_affordance": 0.05209814012050629,
      "train/loss_compute_time_ms": 0.38433074951171875,
      "train/loss_risk": 0.05209814012050629,
      "train/loss_structure": 0.06378978490829468
    },
    {
      "epoch": 0.6645817044566067,
      "step": 850,
      "train/forward_time_ms": 4.6942138671875,
      "train/step_time_ms": 4.694652557373047
    },
    {
      "epoch": 0.7036747458952306,
      "grad_norm": 0.49645334482192993,
      "learning_rate": 9.297107114933542e-05,
      "loss": 0.1635,
      "step": 900
    },
    {
      "epoch": 0.7036747458952306,
      "step": 900,
      "train/forward_time_ms": 2.9637813568115234,
      "train/loss": 0.13381697237491608,
      "train/loss_affordance": 0.03959042578935623,
      "train/loss_compute_time_ms": 0.331878662109375,
      "train/loss_risk": 0.03959042578935623,
      "train/loss_structure": 0.05463612079620361
    },
    {
      "epoch": 0.7036747458952306,
      "step": 900,
      "train/forward_time_ms": 4.759550094604492,
      "train/step_time_ms": 4.760065078735352
    },
    {
      "epoch": 0.7427677873338546,
      "grad_norm": 0.20195864140987396,
      "learning_rate": 9.258014073494918e-05,
      "loss": 0.1689,
      "step": 950
    },
    {
      "epoch": 0.7427677873338546,
      "step": 950,
      "train/forward_time_ms": 2.466917037963867,
      "train/loss": 0.16435469686985016,
      "train/loss_affordance": 0.04310588538646698,
      "train/loss_compute_time_ms": 0.6074905395507812,
      "train/loss_risk": 0.04310588538646698,
      "train/loss_structure": 0.0781429260969162
    },
    {
      "epoch": 0.7427677873338546,
      "step": 950,
      "train/forward_time_ms": 4.589686393737793,
      "train/step_time_ms": 4.590182304382324
    },
    {
      "epoch": 0.7818608287724785,
      "grad_norm": 0.44512391090393066,
      "learning_rate": 9.218921032056295e-05,
      "loss": 0.1602,
      "step": 1000
    },
    {
      "epoch": 0.7818608287724785,
      "step": 1000,
      "train/forward_time_ms": 2.3467540740966797,
      "train/loss": 0.12241800129413605,
      "train/loss_affordance": 0.03497269004583359,
      "train/loss_compute_time_ms": 0.3254413604736328,
      "train/loss_risk": 0.03497269004583359,
      "train/loss_structure": 0.05247262120246887
    },
    {
      "epoch": 0.7818608287724785,
      "step": 1000,
      "train/forward_time_ms": 4.464302062988281,
      "train/step_time_ms": 4.464845657348633
    },
    {
      "epoch": 0.8209538702111024,
      "grad_norm": 0.23758244514465332,
      "learning_rate": 9.17982799061767e-05,
      "loss": 0.1596,
      "step": 1050
    },
    {
      "epoch": 0.8209538702111024,
      "step": 1050,
      "train/forward_time_ms": 2.5959014892578125,
      "train/loss": 0.12939408421516418,
      "train/loss_affordance": 0.04014919325709343,
      "train/loss_compute_time_ms": 0.35452842712402344,
      "train/loss_risk": 0.04014919325709343,
      "train/loss_structure": 0.049095697700977325
    },
    {
      "epoch": 0.8209538702111024,
      "step": 1050,
      "train/forward_time_ms": 4.419035911560059,
      "train/step_time_ms": 4.419541358947754
    },
    {
      "epoch": 0.8600469116497264,
      "grad_norm": 0.3518640398979187,
      "learning_rate": 9.140734949179046e-05,
      "loss": 0.1537,
      "step": 1100
    },
    {
      "epoch": 0.8600469116497264,
      "step": 1100,
      "train/forward_time_ms": 2.256631851196289,
      "train/loss": 0.10684119910001755,
      "train/loss_affordance": 0.03753420151770115,
      "train/loss_compute_time_ms": 0.31685829162597656,
      "train/loss_risk": 0.03753420151770115,
      "train/loss_structure": 0.03177279606461525
    },
    {
      "epoch": 0.8600469116497264,
      "step": 1100,
      "train/forward_time_ms": 4.714779853820801,
      "train/step_time_ms": 4.71531867980957
    },
    {
      "epoch": 0.8991399530883503,
      "grad_norm": 0.467791885137558,
      "learning_rate": 9.101641907740422e-05,
      "loss": 0.148,
      "step": 1150
    },
    {
      "epoch": 0.8991399530883503,
      "step": 1150,
      "train/forward_time_ms": 2.6063919067382812,
      "train/loss": 0.12859080731868744,
      "train/loss_affordance": 0.04221189767122269,
      "train/loss_compute_time_ms": 0.33211708068847656,
      "train/loss_risk": 0.04221189767122269,
      "train/loss_structure": 0.044167011976242065
    },
    {
      "epoch": 0.8991399530883503,
      "step": 1150,
      "train/forward_time_ms": 4.788522720336914,
      "train/step_time_ms": 4.789018630981445
    },
    {
      "epoch": 0.9382329945269742,
      "grad_norm": 0.6652710437774658,
      "learning_rate": 9.062548866301799e-05,
      "loss": 0.1517,
      "step": 1200
    },
    {
      "epoch": 0.9382329945269742,
      "step": 1200,
      "train/forward_time_ms": 2.3641586303710938,
      "train/loss": 0.18750008940696716,
      "train/loss_affordance": 0.05753043293952942,
      "train/loss_compute_time_ms": 0.3161430358886719,
      "train/loss_risk": 0.05753043293952942,
      "train/loss_structure": 0.07243922352790833
    },
    {
      "epoch": 0.9382329945269742,
      "step": 1200,
      "train/forward_time_ms": 4.588885307312012,
      "train/step_time_ms": 4.589371681213379
    },
    {
      "epoch": 0.9773260359655981,
      "grad_norm": 0.4177783727645874,
      "learning_rate": 9.023455824863175e-05,
      "loss": 0.1434,
      "step": 1250
    },
    {
      "epoch": 0.9773260359655981,
      "step": 1250,
      "train/forward_time_ms": 2.6502609252929688,
      "train/loss": 0.19053766131401062,
      "train/loss_affordance": 0.0569021999835968,
      "train/loss_compute_time_ms": 0.37598609924316406,
      "train/loss_risk": 0.0569021999835968,
      "train/loss_structure": 0.07673326134681702
    },
    {
      "epoch": 0.9773260359655981,
      "step": 1250,
      "train/forward_time_ms": 4.26607608795166,
      "train/step_time_ms": 4.2665815353393555
    },
    {
      "epoch": 1.016419077404222,
      "grad_norm": 0.4300459921360016,
      "learning_rate": 8.984362783424552e-05,
      "loss": 0.144,
      "step": 1300
    },
    {
      "epoch": 1.016419077404222,
      "step": 1300,
      "train/forward_time_ms": 2.6319026947021484,
      "train/loss": 0.12845276296138763,
      "train/loss_affordance": 0.03579281456768513,
      "train/loss_compute_time_ms": 0.32258033752441406,
      "train/loss_risk": 0.03579281456768513,
      "train/loss_structure": 0.05686713382601738
    },
    {
      "epoch": 1.016419077404222,
      "step": 1300,
      "train/forward_time_ms": 4.29779052734375,
      "train/step_time_ms": 4.298205375671387
    },
    {
      "epoch": 1.055512118842846,
      "grad_norm": 0.5932654142379761,
      "learning_rate": 8.945269741985926e-05,
      "loss": 0.142,
      "step": 1350
    },
    {
      "epoch": 1.055512118842846,
      "step": 1350,
      "train/forward_time_ms": 2.3038387298583984,
      "train/loss": 0.16581660509109497,
      "train/loss_affordance": 0.043745141476392746,
      "train/loss_compute_time_ms": 0.3368854522705078,
      "train/loss_risk": 0.043745141476392746,
      "train/loss_structure": 0.07832632213830948
    },
    {
      "epoch": 1.055512118842846,
      "step": 1350,
      "train/forward_time_ms": 4.333906173706055,
      "train/step_time_ms": 4.334425926208496
    },
    {
      "epoch": 1.09460516028147,
      "grad_norm": 0.24445514380931854,
      "learning_rate": 8.906176700547303e-05,
      "loss": 0.1306,
      "step": 1400
    },
    {
      "epoch": 1.09460516028147,
      "step": 1400,
      "train/forward_time_ms": 2.7413368225097656,
      "train/loss": 0.12810730934143066,
      "train/loss_affordance": 0.04222843423485756,
      "train/loss_compute_time_ms": 0.3333091735839844,
      "train/loss_risk": 0.04222843423485756,
      "train/loss_structure": 0.043650440871715546
    },
    {
      "epoch": 1.09460516028147,
      "step": 1400,
      "train/forward_time_ms": 4.379830360412598,
      "train/step_time_ms": 4.3802690505981445
    },
    {
      "epoch": 1.1336982017200938,
      "grad_norm": 0.41309231519699097,
      "learning_rate": 8.867083659108679e-05,
      "loss": 0.1344,
      "step": 1450
    },
    {
      "epoch": 1.1336982017200938,
      "step": 1450,
      "train/forward_time_ms": 2.457141876220703,
      "train/loss": 0.16425234079360962,
      "train/loss_affordance": 0.04949550703167915,
      "train/loss_compute_time_ms": 0.35262107849121094,
      "train/loss_risk": 0.04949550703167915,
      "train/loss_structure": 0.06526132673025131
    },
    {
      "epoch": 1.1336982017200938,
      "step": 1450,
      "train/forward_time_ms": 4.4110918045043945,
      "train/step_time_ms": 4.411520957946777
    },
    {
      "epoch": 1.1727912431587177,
      "grad_norm": 0.336224228143692,
      "learning_rate": 8.827990617670056e-05,
      "loss": 0.1356,
      "step": 1500
    },
    {
      "epoch": 1.1727912431587177,
      "step": 1500,
      "train/forward_time_ms": 2.610921859741211,
      "train/loss": 0.1309511363506317,
      "train/loss_affordance": 0.03585359454154968,
      "train/loss_compute_time_ms": 0.3437995910644531,
      "train/loss_risk": 0.03585359454154968,
      "train/loss_structure": 0.05924394726753235
    },
    {
      "epoch": 1.1727912431587177,
      "step": 1500,
      "train/forward_time_ms": 4.342226982116699,
      "train/step_time_ms": 4.342679977416992
    },
    {
      "epoch": 1.2118842845973417,
      "grad_norm": 0.7098152041435242,
      "learning_rate": 8.78889757623143e-05,
      "loss": 0.1325,
      "step": 1550
    },
    {
      "epoch": 1.2118842845973417,
      "step": 1550,
      "train/forward_time_ms": 2.1064281463623047,
      "train/loss": 0.1267586350440979,
      "train/loss_affordance": 0.030619531869888306,
      "train/loss_compute_time_ms": 0.3681182861328125,
      "train/loss_risk": 0.030619531869888306,
      "train/loss_structure": 0.06551957130432129
    },
    {
      "epoch": 1.2118842845973417,
      "step": 1550,
      "train/forward_time_ms": 4.183464050292969,
      "train/step_time_ms": 4.183921813964844
    },
    {
      "epoch": 1.2509773260359656,
      "grad_norm": 0.5838343501091003,
      "learning_rate": 8.749804534792807e-05,
      "loss": 0.124,
      "step": 1600
    },
    {
      "epoch": 1.2509773260359656,
      "step": 1600,
      "train/forward_time_ms": 2.627134323120117,
      "train/loss": 0.0912311002612114,
      "train/loss_affordance": 0.030143950134515762,
      "train/loss_compute_time_ms": 0.3216266632080078,
      "train/loss_risk": 0.030143950134515762,
      "train/loss_structure": 0.03094319999217987
    },
    {
      "epoch": 1.2509773260359656,
      "step": 1600,
      "train/forward_time_ms": 4.197168350219727,
      "train/step_time_ms": 4.197626113891602
    },
    {
      "epoch": 1.2900703674745895,
      "grad_norm": 0.4747708737850189,
      "learning_rate": 8.710711493354183e-05,
      "loss": 0.1211,
      "step": 1650
    },
    {
      "epoch": 1.2900703674745895,
      "step": 1650,
      "train/forward_time_ms": 2.456188201904297,
      "train/loss": 0.08239027857780457,
      "train/loss_affordance": 0.026468321681022644,
      "train/loss_compute_time_ms": 0.3628730773925781,
      "train/loss_risk": 0.026468321681022644,
      "train/loss_structure": 0.029453635215759277
    },
    {
      "epoch": 1.2900703674745895,
      "step": 1650,
      "train/forward_time_ms": 4.5311689376831055,
      "train/step_time_ms": 4.531683921813965
    },
    {
      "epoch": 1.3291634089132134,
      "grad_norm": 0.37473174929618835,
      "learning_rate": 8.67161845191556e-05,
      "loss": 0.1226,
      "step": 1700
    },
    {
      "epoch": 1.3291634089132134,
      "step": 1700,
      "train/forward_time_ms": 2.3479461669921875,
      "train/loss": 0.06718810647726059,
      "train/loss_affordance": 0.018424764275550842,
      "train/loss_compute_time_ms": 0.2968311309814453,
      "train/loss_risk": 0.018424764275550842,
      "train/loss_structure": 0.030338577926158905
    },
    {
      "epoch": 1.3291634089132134,
      "step": 1700,
      "train/forward_time_ms": 4.222688674926758,
      "train/step_time_ms": 4.223155975341797
    },
    {
      "epoch": 1.3682564503518373,
      "grad_norm": 0.4188203811645508,
      "learning_rate": 8.632525410476936e-05,
      "loss": 0.1179,
      "step": 1750
    },
    {
      "epoch": 1.3682564503518373,
      "step": 1750,
      "train/forward_time_ms": 2.599954605102539,
      "train/loss": 0.11621592938899994,
      "train/loss_affordance": 0.03254521265625954,
      "train/loss_compute_time_ms": 0.32258033752441406,
      "train/loss_risk": 0.03254521265625954,
      "train/loss_structure": 0.051125504076480865
    },
    {
      "epoch": 1.3682564503518373,
      "step": 1750,
      "train/forward_time_ms": 4.334602355957031,
      "train/step_time_ms": 4.335041046142578
    },
    {
      "epoch": 1.4073494917904612,
      "grad_norm": 0.2864297032356262,
      "learning_rate": 8.593432369038311e-05,
      "loss": 0.1222,
      "step": 1800
    },
    {
      "epoch": 1.4073494917904612,
      "step": 1800,
      "train/forward_time_ms": 2.434968948364258,
      "train/loss": 0.13349343836307526,
      "train/loss_affordance": 0.03283277153968811,
      "train/loss_compute_time_ms": 0.3147125244140625,
      "train/loss_risk": 0.03283277153968811,
      "train/loss_structure": 0.06782789528369904
    },
    {
      "epoch": 1.4073494917904612,
      "step": 1800,
      "train/forward_time_ms": 4.263362884521484,
      "train/step_time_ms": 4.263806343078613
    },
    {
      "epoch": 1.4464425332290851,
      "grad_norm": 0.3684828281402588,
      "learning_rate": 8.554339327599687e-05,
      "loss": 0.1196,
      "step": 1850
    },
    {
      "epoch": 1.4464425332290851,
      "step": 1850,
      "train/forward_time_ms": 2.433300018310547,
      "train/loss": 0.14276781678199768,
      "train/loss_affordance": 0.04513312876224518,
      "train/loss_compute_time_ms": 0.33354759216308594,
      "train/loss_risk": 0.04513312876224518,
      "train/loss_structure": 0.052501559257507324
    },
    {
      "epoch": 1.4464425332290851,
      "step": 1850,
      "train/forward_time_ms": 4.334268569946289,
      "train/step_time_ms": 4.334745407104492
    },
    {
      "epoch": 1.485535574667709,
      "grad_norm": 0.24116361141204834,
      "learning_rate": 8.515246286161064e-05,
      "loss": 0.1217,
      "step": 1900
    },
    {
      "epoch": 1.485535574667709,
      "step": 1900,
      "train/forward_time_ms": 2.416372299194336,
      "train/loss": 0.09746440500020981,
      "train/loss_affordance": 0.02381749264895916,
      "train/loss_compute_time_ms": 0.4324913024902344,
      "train/loss_risk": 0.02381749264895916,
      "train/loss_structure": 0.04982941970229149
    },
    {
      "epoch": 1.485535574667709,
      "step": 1900,
      "train/forward_time_ms": 4.222822189331055,
      "train/step_time_ms": 4.2232465744018555
    },
    {
      "epoch": 1.524628616106333,
      "grad_norm": 0.4035160541534424,
      "learning_rate": 8.47615324472244e-05,
      "loss": 0.1076,
      "step": 1950
    },
    {
      "epoch": 1.524628616106333,
      "step": 1950,
      "train/forward_time_ms": 2.415895462036133,
      "train/loss": 0.09945764392614365,
      "train/loss_affordance": 0.028974242508411407,
      "train/loss_compute_time_ms": 0.3056526184082031,
      "train/loss_risk": 0.028974242508411407,
      "train/loss_structure": 0.04150915890932083
    },
    {
      "epoch": 1.524628616106333,
      "step": 1950,
      "train/forward_time_ms": 4.426312446594238,
      "train/step_time_ms": 4.426913261413574
    },
    {
      "epoch": 1.5637216575449568,
      "grad_norm": 0.4463594853878021,
      "learning_rate": 8.437060203283817e-05,
      "loss": 0.1092,
      "step": 2000
    },
    {
      "epoch": 1.5637216575449568,
      "step": 2000,
      "train/forward_time_ms": 3.103017807006836,
      "train/loss": 0.1262226700782776,
      "train/loss_affordance": 0.03982960432767868,
      "train/loss_compute_time_ms": 0.3407001495361328,
      "train/loss_risk": 0.03982960432767868,
      "train/loss_structure": 0.04656346142292023
    },
    {
      "epoch": 1.5637216575449568,
      "step": 2000,
      "train/forward_time_ms": 4.298110008239746,
      "train/step_time_ms": 4.298539161682129
    },
    {
      "epoch": 1.602814698983581,
      "grad_norm": 0.3435443043708801,
      "learning_rate": 8.397967161845191e-05,
      "loss": 0.1065,
      "step": 2050
    },
    {
      "epoch": 1.602814698983581,
      "step": 2050,
      "train/forward_time_ms": 2.4213790893554688,
      "train/loss": 0.1495562642812729,
      "train/loss_affordance": 0.04657175578176975,
      "train/loss_compute_time_ms": 0.2949237823486328,
      "train/loss_risk": 0.04657175578176975,
      "train/loss_structure": 0.05641275271773338
    },
    {
      "epoch": 1.602814698983581,
      "step": 2050,
      "train/forward_time_ms": 4.170107841491699,
      "train/step_time_ms": 4.170560836791992
    },
    {
      "epoch": 1.6419077404222049,
      "grad_norm": 0.4803473651409149,
      "learning_rate": 8.358874120406568e-05,
      "loss": 0.1057,
      "step": 2100
    },
    {
      "epoch": 1.6419077404222049,
      "step": 2100,
      "train/forward_time_ms": 2.536296844482422,
      "train/loss": 0.13189741969108582,
      "train/loss_affordance": 0.04361937195062637,
      "train/loss_compute_time_ms": 0.3886222839355469,
      "train/loss_risk": 0.04361937195062637,
      "train/loss_structure": 0.04465867578983307
    },
    {
      "epoch": 1.6419077404222049,
      "step": 2100,
      "train/forward_time_ms": 4.512920379638672,
      "train/step_time_ms": 4.513344764709473
    },
    {
      "epoch": 1.6810007818608288,
      "grad_norm": 0.5659018754959106,
      "learning_rate": 8.319781078967944e-05,
      "loss": 0.1014,
      "step": 2150
    },
    {
      "epoch": 1.6810007818608288,
      "step": 2150,
      "train/forward_time_ms": 2.2678375244140625,
      "train/loss": 0.09962141513824463,
      "train/loss_affordance": 0.03536292817443609,
      "train/loss_compute_time_ms": 0.2636909484863281,
      "train/loss_risk": 0.03536292817443609,
      "train/loss_structure": 0.028895558789372444
    },
    {
      "epoch": 1.6810007818608288,
      "step": 2150,
      "train/forward_time_ms": 4.231710433959961,
      "train/step_time_ms": 4.232211112976074
    },
    {
      "epoch": 1.7200938232994527,
      "grad_norm": 0.2929922640323639,
      "learning_rate": 8.280688037529321e-05,
      "loss": 0.1084,
      "step": 2200
    },
    {
      "epoch": 1.7200938232994527,
      "step": 2200,
      "train/forward_time_ms": 2.5734901428222656,
      "train/loss": 0.10336164385080338,
      "train/loss_affordance": 0.030697934329509735,
      "train/loss_compute_time_ms": 0.31304359436035156,
      "train/loss_risk": 0.030697934329509735,
      "train/loss_structure": 0.041965775191783905
    },
    {
      "epoch": 1.7200938232994527,
      "step": 2200,
      "train/forward_time_ms": 4.206371307373047,
      "train/step_time_ms": 4.206829071044922
    },
    {
      "epoch": 1.7591868647380766,
      "grad_norm": 0.4129070043563843,
      "learning_rate": 8.241594996090695e-05,
      "loss": 0.1029,
      "step": 2250
    },
    {
      "epoch": 1.7591868647380766,
      "step": 2250,
      "train/forward_time_ms": 2.361297607421875,
      "train/loss": 0.14747075736522675,
      "train/loss_affordance": 0.040799640119075775,
      "train/loss_compute_time_ms": 0.3237724304199219,
      "train/loss_risk": 0.040799640119075775,
      "train/loss_structure": 0.0658714771270752
    },
    {
      "epoch": 1.7591868647380766,
      "step": 2250,
      "train/forward_time_ms": 4.271664619445801,
      "train/step_time_ms": 4.272122383117676
    },
    {
      "epoch": 1.7982799061767005,
      "grad_norm": 0.7059535980224609,
      "learning_rate": 8.202501954652072e-05,
      "loss": 0.1004,
      "step": 2300
    },
    {
      "epoch": 1.7982799061767005,
      "step": 2300,
      "train/forward_time_ms": 2.4340152740478516,
      "train/loss": 0.10037796944379807,
      "train/loss_affordance": 0.03247835673391819,
      "train/loss_compute_time_ms": 0.39649009704589844,
      "train/loss_risk": 0.03247835673391819,
      "train/loss_structure": 0.035421255975961685
    },
    {
      "epoch": 1.7982799061767005,
      "step": 2300,
      "train/forward_time_ms": 4.167232513427734,
      "train/step_time_ms": 4.167680740356445
    },
    {
      "epoch": 1.8373729476153244,
      "grad_norm": 0.289756178855896,
      "learning_rate": 8.163408913213448e-05,
      "loss": 0.1013,
      "step": 2350
    },
    {
      "epoch": 1.8373729476153244,
      "step": 2350,
      "train/forward_time_ms": 2.9447078704833984,
      "train/loss": 0.11301152408123016,
      "train/loss_affordance": 0.032868966460227966,
      "train/loss_compute_time_ms": 0.3542900085449219,
      "train/loss_risk": 0.032868966460227966,
      "train/loss_structure": 0.04727359116077423
    },
    {
      "epoch": 1.8373729476153244,
      "step": 2350,
      "train/forward_time_ms": 4.369626045227051,
      "train/step_time_ms": 4.370064735412598
    },
    {
      "epoch": 1.8764659890539483,
      "grad_norm": 0.5333461761474609,
      "learning_rate": 8.124315871774825e-05,
      "loss": 0.097,
      "step": 2400
    },
    {
      "epoch": 1.8764659890539483,
      "step": 2400,
      "train/forward_time_ms": 2.3660659790039062,
      "train/loss": 0.11764015257358551,
      "train/loss_affordance": 0.034097377210855484,
      "train/loss_compute_time_ms": 0.2982616424560547,
      "train/loss_risk": 0.034097377210855484,
      "train/loss_structure": 0.04944539815187454
    },
    {
      "epoch": 1.8764659890539483,
      "step": 2400,
      "train/forward_time_ms": 4.244847297668457,
      "train/step_time_ms": 4.24527645111084
    },
    {
      "epoch": 1.9155590304925725,
      "grad_norm": 0.1790797859430313,
      "learning_rate": 8.0852228303362e-05,
      "loss": 0.0981,
      "step": 2450
    },
    {
      "epoch": 1.9155590304925725,
      "step": 2450,
      "train/forward_time_ms": 2.233266830444336,
      "train/loss": 0.10083603858947754,
      "train/loss_affordance": 0.031166790053248405,
      "train/loss_compute_time_ms": 0.3108978271484375,
      "train/loss_risk": 0.031166790053248405,
      "train/loss_structure": 0.03850245848298073
    },
    {
      "epoch": 1.9155590304925725,
      "step": 2450,
      "train/forward_time_ms": 4.220256805419922,
      "train/step_time_ms": 4.220666885375977
    },
    {
      "epoch": 1.9546520719311964,
      "grad_norm": 0.272848516702652,
      "learning_rate": 8.046129788897576e-05,
      "loss": 0.1005,
      "step": 2500
    },
    {
      "epoch": 1.9546520719311964,
      "step": 2500,
      "train/forward_time_ms": 2.4971961975097656,
      "train/loss": 0.11970213055610657,
      "train/loss_affordance": 0.038953306153416634,
      "train/loss_compute_time_ms": 0.4246234893798828,
      "train/loss_risk": 0.038953306153416634,
      "train/loss_structure": 0.0417955182492733
    },
    {
      "epoch": 1.9546520719311964,
      "step": 2500,
      "train/forward_time_ms": 4.169163703918457,
      "train/step_time_ms": 4.169611930847168
    },
    {
      "epoch": 1.9937451133698203,
      "grad_norm": 0.7203724980354309,
      "learning_rate": 8.007036747458952e-05,
      "loss": 0.1006,
      "step": 2550
    },
    {
      "epoch": 1.9937451133698203,
      "step": 2550,
      "train/forward_time_ms": 2.537965774536133,
      "train/loss": 0.08706539869308472,
      "train/loss_affordance": 0.028707453981041908,
      "train/loss_compute_time_ms": 0.3330707550048828,
      "train/loss_risk": 0.028707453981041908,
      "train/loss_structure": 0.0296504907310009
    },
    {
      "epoch": 1.9937451133698203,
      "step": 2550,
      "train/forward_time_ms": 4.292850494384766,
      "train/step_time_ms": 4.293308258056641
    },
    {
      "epoch": 2.032838154808444,
      "grad_norm": 0.4097731113433838,
      "learning_rate": 7.967943706020329e-05,
      "loss": 0.094,
      "step": 2600
    },
    {
      "epoch": 2.032838154808444,
      "step": 2600,
      "train/forward_time_ms": 2.303600311279297,
      "train/loss": 0.12397471070289612,
      "train/loss_affordance": 0.038267707452178,
      "train/loss_compute_time_ms": 0.3402233123779297,
      "train/loss_risk": 0.038267707452178,
      "train/loss_structure": 0.047439295798540115
    },
    {
      "epoch": 2.032838154808444,
      "step": 2600,
      "train/forward_time_ms": 4.460725784301758,
      "train/step_time_ms": 4.461188316345215
    },
    {
      "epoch": 2.071931196247068,
      "grad_norm": 0.7724022269248962,
      "learning_rate": 7.928850664581705e-05,
      "loss": 0.0969,
      "step": 2650
    },
    {
      "epoch": 2.071931196247068,
      "step": 2650,
      "train/forward_time_ms": 2.1538734436035156,
      "train/loss": 0.08733509480953217,
      "train/loss_affordance": 0.02275552786886692,
      "train/loss_compute_time_ms": 0.2613067626953125,
      "train/loss_risk": 0.02275552786886692,
      "train/loss_structure": 0.041824039071798325
    },
    {
      "epoch": 2.071931196247068,
      "step": 2650,
      "train/forward_time_ms": 4.251737594604492,
      "train/step_time_ms": 4.252176284790039
    },
    {
      "epoch": 2.111024237685692,
      "grad_norm": 0.29092928767204285,
      "learning_rate": 7.889757623143082e-05,
      "loss": 0.0897,
      "step": 2700
    },
    {
      "epoch": 2.111024237685692,
      "step": 2700,
      "train/forward_time_ms": 2.4182796478271484,
      "train/loss": 0.10146196186542511,
      "train/loss_affordance": 0.029223497956991196,
      "train/loss_compute_time_ms": 0.37932395935058594,
      "train/loss_risk": 0.029223497956991196,
      "train/loss_structure": 0.04301496595144272
    },
    {
      "epoch": 2.111024237685692,
      "step": 2700,
      "train/forward_time_ms": 4.247121810913086,
      "train/step_time_ms": 4.247989654541016
    },
    {
      "epoch": 2.150117279124316,
      "grad_norm": 0.16278021037578583,
      "learning_rate": 7.850664581704456e-05,
      "loss": 0.0925,
      "step": 2750
    },
    {
      "epoch": 2.150117279124316,
      "step": 2750,
      "train/forward_time_ms": 2.662181854248047,
      "train/loss": 0.0898108035326004,
      "train/loss_affordance": 0.02557944692671299,
      "train/loss_compute_time_ms": 0.3101825714111328,
      "train/loss_risk": 0.02557944692671299,
      "train/loss_structure": 0.03865190967917442
    },
    {
      "epoch": 2.150117279124316,
      "step": 2750,
      "train/forward_time_ms": 4.352092742919922,
      "train/step_time_ms": 4.35267448425293
    },
    {
      "epoch": 2.18921032056294,
      "grad_norm": 0.266985148191452,
      "learning_rate": 7.811571540265833e-05,
      "loss": 0.0866,
      "step": 2800
    },
    {
      "epoch": 2.18921032056294,
      "step": 2800,
      "train/forward_time_ms": 2.3713111877441406,
      "train/loss": 0.0624055489897728,
      "train/loss_affordance": 0.02111777290701866,
      "train/loss_compute_time_ms": 0.3147125244140625,
      "train/loss_risk": 0.02111777290701866,
      "train/loss_structure": 0.020170003175735474
    },
    {
      "epoch": 2.18921032056294,
      "step": 2800,
      "train/forward_time_ms": 4.32861328125,
      "train/step_time_ms": 4.329113960266113
    },
    {
      "epoch": 2.2283033620015638,
      "grad_norm": 0.5430927276611328,
      "learning_rate": 7.772478498827209e-05,
      "loss": 0.0858,
      "step": 2850
    },
    {
      "epoch": 2.2283033620015638,
      "step": 2850,
      "train/forward_time_ms": 2.637624740600586,
      "train/loss": 0.06979355216026306,
      "train/loss_affordance": 0.024834847077727318,
      "train/loss_compute_time_ms": 0.32782554626464844,
      "train/loss_risk": 0.024834847077727318,
      "train/loss_structure": 0.020123858004808426
    },
    {
      "epoch": 2.2283033620015638,
      "step": 2850,
      "train/forward_time_ms": 4.369487762451172,
      "train/step_time_ms": 4.3701982498168945
    },
    {
      "epoch": 2.2673964034401877,
      "grad_norm": 0.22971183061599731,
      "learning_rate": 7.733385457388586e-05,
      "loss": 0.0876,
      "step": 2900
    },
    {
      "epoch": 2.2673964034401877,
      "step": 2900,
      "train/forward_time_ms": 2.413511276245117,
      "train/loss": 0.06709703803062439,
      "train/loss_affordance": 0.01697382517158985,
      "train/loss_compute_time_ms": 0.4115104675292969,
      "train/loss_risk": 0.01697382517158985,
      "train/loss_structure": 0.03314938768744469
    },
    {
      "epoch": 2.2673964034401877,
      "step": 2900,
      "train/forward_time_ms": 4.231224060058594,
      "train/step_time_ms": 4.2316389083862305
    },
    {
      "epoch": 2.3064894448788116,
      "grad_norm": 0.23338045179843903,
      "learning_rate": 7.69429241594996e-05,
      "loss": 0.0846,
      "step": 2950
    },
    {
      "epoch": 2.3064894448788116,
      "step": 2950,
      "train/forward_time_ms": 2.3360252380371094,
      "train/loss": 0.07328537106513977,
      "train/loss_affordance": 0.02071356400847435,
      "train/loss_compute_time_ms": 0.3268718719482422,
      "train/loss_risk": 0.02071356400847435,
      "train/loss_structure": 0.03185824304819107
    },
    {
      "epoch": 2.3064894448788116,
      "step": 2950,
      "train/forward_time_ms": 4.347667694091797,
      "train/step_time_ms": 4.348158836364746
    },
    {
      "epoch": 2.3455824863174355,
      "grad_norm": 0.31894081830978394,
      "learning_rate": 7.655199374511337e-05,
      "loss": 0.0827,
      "step": 3000
    },
    {
      "epoch": 2.3455824863174355,
      "step": 3000,
      "train/forward_time_ms": 2.4847984313964844,
      "train/loss": 0.07945121824741364,
      "train/loss_affordance": 0.029831537976861,
      "train/loss_compute_time_ms": 0.3635883331298828,
      "train/loss_risk": 0.029831537976861,
      "train/loss_structure": 0.019788142293691635
    },
    {
      "epoch": 2.3455824863174355,
      "step": 3000,
      "train/forward_time_ms": 4.293107986450195,
      "train/step_time_ms": 4.293522834777832
    },
    {
      "epoch": 2.3846755277560594,
      "grad_norm": 0.4688921272754669,
      "learning_rate": 7.616106333072713e-05,
      "loss": 0.0875,
      "step": 3050
    },
    {
      "epoch": 2.3846755277560594,
      "step": 3050,
      "train/forward_time_ms": 2.9299259185791016,
      "train/loss": 0.10938063263893127,
      "train/loss_affordance": 0.03261123597621918,
      "train/loss_compute_time_ms": 0.35500526428222656,
      "train/loss_risk": 0.03261123597621918,
      "train/loss_structure": 0.04415816068649292
    },
    {
      "epoch": 2.3846755277560594,
      "step": 3050,
      "train/forward_time_ms": 4.30145263671875,
      "train/step_time_ms": 4.301886558532715
    },
    {
      "epoch": 2.4237685691946833,
      "grad_norm": 0.48967990279197693,
      "learning_rate": 7.57701329163409e-05,
      "loss": 0.0827,
      "step": 3100
    },
    {
      "epoch": 2.4237685691946833,
      "step": 3100,
      "train/forward_time_ms": 2.468585968017578,
      "train/loss": 0.0944671481847763,
      "train/loss_affordance": 0.032809991389513016,
      "train/loss_compute_time_ms": 0.2799034118652344,
      "train/loss_risk": 0.032809991389513016,
      "train/loss_structure": 0.028847165405750275
    },
    {
      "epoch": 2.4237685691946833,
      "step": 3100,
      "train/forward_time_ms": 4.368481636047363,
      "train/step_time_ms": 4.368915557861328
    },
    {
      "epoch": 2.462861610633307,
      "grad_norm": 0.49182409048080444,
      "learning_rate": 7.537920250195466e-05,
      "loss": 0.0843,
      "step": 3150
    },
    {
      "epoch": 2.462861610633307,
      "step": 3150,
      "train/forward_time_ms": 2.3403167724609375,
      "train/loss": 0.08094838261604309,
      "train/loss_affordance": 0.024543574079871178,
      "train/loss_compute_time_ms": 0.2970695495605469,
      "train/loss_risk": 0.024543574079871178,
      "train/loss_structure": 0.031861234456300735
    },
    {
      "epoch": 2.462861610633307,
      "step": 3150,
      "train/forward_time_ms": 4.200863838195801,
      "train/step_time_ms": 4.20130729675293
    },
    {
      "epoch": 2.501954652071931,
      "grad_norm": 0.24597936868667603,
      "learning_rate": 7.498827208756841e-05,
      "loss": 0.0812,
      "step": 3200
    },
    {
      "epoch": 2.501954652071931,
      "step": 3200,
      "train/forward_time_ms": 2.590179443359375,
      "train/loss": 0.08919857442378998,
      "train/loss_affordance": 0.017645172774791718,
      "train/loss_compute_time_ms": 0.3402233123779297,
      "train/loss_risk": 0.017645172774791718,
      "train/loss_structure": 0.05390822887420654
    },
    {
      "epoch": 2.501954652071931,
      "step": 3200,
      "train/forward_time_ms": 4.294953346252441,
      "train/step_time_ms": 4.295463562011719
    },
    {
      "epoch": 2.541047693510555,
      "grad_norm": 0.2271527796983719,
      "learning_rate": 7.459734167318217e-05,
      "loss": 0.0818,
      "step": 3250
    },
    {
      "epoch": 2.541047693510555,
      "step": 3250,
      "train/forward_time_ms": 2.619504928588867,
      "train/loss": 0.09209278970956802,
      "train/loss_affordance": 0.02732468768954277,
      "train/loss_compute_time_ms": 0.3025531768798828,
      "train/loss_risk": 0.02732468768954277,
      "train/loss_structure": 0.03744341433048248
    },
    {
      "epoch": 2.541047693510555,
      "step": 3250,
      "train/forward_time_ms": 4.313802719116211,
      "train/step_time_ms": 4.31427001953125
    },
    {
      "epoch": 2.580140734949179,
      "grad_norm": 0.573379635810852,
      "learning_rate": 7.420641125879594e-05,
      "loss": 0.0804,
      "step": 3300
    },
    {
      "epoch": 2.580140734949179,
      "step": 3300,
      "train/forward_time_ms": 3.2258033752441406,
      "train/loss": 0.08899354934692383,
      "train/loss_affordance": 0.029776527546346188,
      "train/loss_compute_time_ms": 0.41484832763671875,
      "train/loss_risk": 0.029776527546346188,
      "train/loss_structure": 0.029440494254231453
    },
    {
      "epoch": 2.580140734949179,
      "step": 3300,
      "train/forward_time_ms": 4.343080520629883,
      "train/step_time_ms": 4.343552589416504
    },
    {
      "epoch": 2.619233776387803,
      "grad_norm": 0.17177845537662506,
      "learning_rate": 7.38154808444097e-05,
      "loss": 0.0807,
      "step": 3350
    },
    {
      "epoch": 2.619233776387803,
      "step": 3350,
      "train/forward_time_ms": 2.203226089477539,
      "train/loss": 0.06538990139961243,
      "train/loss_affordance": 0.018560228869318962,
      "train/loss_compute_time_ms": 0.31828880310058594,
      "train/loss_risk": 0.018560228869318962,
      "train/loss_structure": 0.028269443660974503
    },
    {
      "epoch": 2.619233776387803,
      "step": 3350,
      "train/forward_time_ms": 4.400625228881836,
      "train/step_time_ms": 4.401125907897949
    },
    {
      "epoch": 2.6583268178264268,
      "grad_norm": 0.4355534315109253,
      "learning_rate": 7.342455043002347e-05,
      "loss": 0.0773,
      "step": 3400
    },
    {
      "epoch": 2.6583268178264268,
      "step": 3400,
      "train/forward_time_ms": 2.350330352783203,
      "train/loss": 0.07686491310596466,
      "train/loss_affordance": 0.0255343709141016,
      "train/loss_compute_time_ms": 0.30040740966796875,
      "train/loss_risk": 0.0255343709141016,
      "train/loss_structure": 0.02579617127776146
    },
    {
      "epoch": 2.6583268178264268,
      "step": 3400,
      "train/forward_time_ms": 4.176545143127441,
      "train/step_time_ms": 4.177002906799316
    },
    {
      "epoch": 2.6974198592650507,
      "grad_norm": 0.6202059388160706,
      "learning_rate": 7.303362001563721e-05,
      "loss": 0.0785,
      "step": 3450
    },
    {
      "epoch": 2.6974198592650507,
      "step": 3450,
      "train/forward_time_ms": 2.456188201904297,
      "train/loss": 0.06729064136743546,
      "train/loss_affordance": 0.02395169623196125,
      "train/loss_compute_time_ms": 0.3275871276855469,
      "train/loss_risk": 0.02395169623196125,
      "train/loss_structure": 0.019387248903512955
    },
    {
      "epoch": 2.6974198592650507,
      "step": 3450,
      "train/forward_time_ms": 4.197101593017578,
      "train/step_time_ms": 4.197573661804199
    },
    {
      "epoch": 2.7365129007036746,
      "grad_norm": 0.2843089699745178,
      "learning_rate": 7.264268960125098e-05,
      "loss": 0.0748,
      "step": 3500
    },
    {
      "epoch": 2.7365129007036746,
      "step": 3500,
      "train/forward_time_ms": 2.3550987243652344,
      "train/loss": 0.06992433965206146,
      "train/loss_affordance": 0.022019876167178154,
      "train/loss_compute_time_ms": 0.3223419189453125,
      "train/loss_risk": 0.022019876167178154,
      "train/loss_structure": 0.025884587317705154
    },
    {
      "epoch": 2.7365129007036746,
      "step": 3500,
      "train/forward_time_ms": 4.224996566772461,
      "train/step_time_ms": 4.225444793701172
    },
    {
      "epoch": 2.775605942142299,
      "grad_norm": 0.3958965539932251,
      "learning_rate": 7.225175918686474e-05,
      "loss": 0.0778,
      "step": 3550
    },
    {
      "epoch": 2.775605942142299,
      "step": 3550,
      "train/forward_time_ms": 2.4480819702148438,
      "train/loss": 0.0782073438167572,
      "train/loss_affordance": 0.02664724551141262,
      "train/loss_compute_time_ms": 0.32591819763183594,
      "train/loss_risk": 0.02664724551141262,
      "train/loss_structure": 0.02491285279393196
    },
    {
      "epoch": 2.775605942142299,
      "step": 3550,
      "train/forward_time_ms": 4.451799392700195,
      "train/step_time_ms": 4.45220947265625
    },
    {
      "epoch": 2.8146989835809224,
      "grad_norm": 0.36919111013412476,
      "learning_rate": 7.186082877247851e-05,
      "loss": 0.0746,
      "step": 3600
    },
    {
      "epoch": 2.8146989835809224,
      "step": 3600,
      "train/forward_time_ms": 2.4924278259277344,
      "train/loss": 0.07217548787593842,
      "train/loss_affordance": 0.024424810893833637,
      "train/loss_compute_time_ms": 0.2944469451904297,
      "train/loss_risk": 0.024424810893833637,
      "train/loss_structure": 0.02332586608827114
    },
    {
      "epoch": 2.8146989835809224,
      "step": 3600,
      "train/forward_time_ms": 4.236783981323242,
      "train/step_time_ms": 4.237189292907715
    },
    {
      "epoch": 2.8537920250195468,
      "grad_norm": 0.14821314811706543,
      "learning_rate": 7.146989835809225e-05,
      "loss": 0.0762,
      "step": 3650
    },
    {
      "epoch": 2.8537920250195468,
      "step": 3650,
      "train/forward_time_ms": 2.530336380004883,
      "train/loss": 0.07108020782470703,
      "train/loss_affordance": 0.021884742192924023,
      "train/loss_compute_time_ms": 0.3509521484375,
      "train/loss_risk": 0.021884742192924023,
      "train/loss_structure": 0.027310723438858986
    },
    {
      "epoch": 2.8537920250195468,
      "step": 3650,
      "train/forward_time_ms": 4.256253242492676,
      "train/step_time_ms": 4.256701469421387
    },
    {
      "epoch": 2.8928850664581702,
      "grad_norm": 0.42441314458847046,
      "learning_rate": 7.107896794370602e-05,
      "loss": 0.0734,
      "step": 3700
    },
    {
      "epoch": 2.8928850664581702,
      "step": 3700,
      "train/forward_time_ms": 2.382993698120117,
      "train/loss": 0.0714966207742691,
      "train/loss_affordance": 0.025583330541849136,
      "train/loss_compute_time_ms": 0.270843505859375,
      "train/loss_risk": 0.025583330541849136,
      "train/loss_structure": 0.02032995969057083
    },
    {
      "epoch": 2.8928850664581702,
      "step": 3700,
      "train/forward_time_ms": 4.367494583129883,
      "train/step_time_ms": 4.367928504943848
    },
    {
      "epoch": 2.9319781078967946,
      "grad_norm": 0.48606181144714355,
      "learning_rate": 7.068803752931978e-05,
      "loss": 0.0724,
      "step": 3750
    },
    {
      "epoch": 2.9319781078967946,
      "step": 3750,
      "train/forward_time_ms": 2.035856246948242,
      "train/loss": 0.08194237947463989,
      "train/loss_affordance": 0.027419153600931168,
      "train/loss_compute_time_ms": 0.2760887145996094,
      "train/loss_risk": 0.027419153600931168,
      "train/loss_structure": 0.027104072272777557
    },
    {
      "epoch": 2.9319781078967946,
      "step": 3750,
      "train/forward_time_ms": 4.208736419677734,
      "train/step_time_ms": 4.2092180252075195
    },
    {
      "epoch": 2.971071149335418,
      "grad_norm": 0.2294812798500061,
      "learning_rate": 7.029710711493355e-05,
      "loss": 0.074,
      "step": 3800
    },
    {
      "epoch": 2.971071149335418,
      "step": 3800,
      "train/forward_time_ms": 1.9488334655761719,
      "train/loss": 0.07035981118679047,
      "train/loss_affordance": 0.026408851146697998,
      "train/loss_compute_time_ms": 0.2789497375488281,
      "train/loss_risk": 0.026408851146697998,
      "train/loss_structure": 0.01754210889339447
    },
    {
      "epoch": 2.971071149335418,
      "step": 3800,
      "train/forward_time_ms": 4.418168067932129,
      "train/step_time_ms": 4.41866397857666
    },
    {
      "epoch": 3.0101641907740424,
      "grad_norm": 0.42337262630462646,
      "learning_rate": 6.99061767005473e-05,
      "loss": 0.0689,
      "step": 3850
    },
    {
      "epoch": 3.0101641907740424,
      "step": 3850,
      "train/forward_time_ms": 2.4285316467285156,
      "train/loss": 0.05580064654350281,
      "train/loss_affordance": 0.0159250907599926,
      "train/loss_compute_time_ms": 0.36716461181640625,
      "train/loss_risk": 0.0159250907599926,
      "train/loss_structure": 0.02395046502351761
    },
    {
      "epoch": 3.0101641907740424,
      "step": 3850,
      "train/forward_time_ms": 4.231381416320801,
      "train/step_time_ms": 4.23184871673584
    },
    {
      "epoch": 3.0492572322126663,
      "grad_norm": 0.5367348790168762,
      "learning_rate": 6.951524628616106e-05,
      "loss": 0.0702,
      "step": 3900
    },
    {
      "epoch": 3.0492572322126663,
      "step": 3900,
      "train/forward_time_ms": 2.3565292358398438,
      "train/loss": 0.06498226523399353,
      "train/loss_affordance": 0.01812269352376461,
      "train/loss_compute_time_ms": 0.3809928894042969,
      "train/loss_risk": 0.01812269352376461,
      "train/loss_structure": 0.02873687818646431
    },
    {
      "epoch": 3.0492572322126663,
      "step": 3900,
      "train/forward_time_ms": 4.292130470275879,
      "train/step_time_ms": 4.292616844177246
    },
    {
      "epoch": 3.0883502736512902,
      "grad_norm": 0.2623121738433838,
      "learning_rate": 6.912431587177482e-05,
      "loss": 0.0679,
      "step": 3950
    },
    {
      "epoch": 3.0883502736512902,
      "step": 3950,
      "train/forward_time_ms": 2.268075942993164,
      "train/loss": 0.068031445145607,
      "train/loss_affordance": 0.02334811817854643,
      "train/loss_compute_time_ms": 0.31757354736328125,
      "train/loss_risk": 0.02334811817854643,
      "train/loss_structure": 0.021335208788514137
    },
    {
      "epoch": 3.0883502736512902,
      "step": 3950,
      "train/forward_time_ms": 4.237260818481445,
      "train/step_time_ms": 4.237685203552246
    },
    {
      "epoch": 3.127443315089914,
      "grad_norm": 0.43151944875717163,
      "learning_rate": 6.873338545738859e-05,
      "loss": 0.0694,
      "step": 4000
    },
    {
      "epoch": 3.127443315089914,
      "step": 4000,
      "train/forward_time_ms": 2.3682117462158203,
      "train/loss": 0.06616121530532837,
      "train/loss_affordance": 0.017472967505455017,
      "train/loss_compute_time_ms": 0.29754638671875,
      "train/loss_risk": 0.017472967505455017,
      "train/loss_structure": 0.031215280294418335
    },
    {
      "epoch": 3.127443315089914,
      "step": 4000,
      "train/forward_time_ms": 4.355936050415039,
      "train/step_time_ms": 4.356441497802734
    },
    {
      "epoch": 3.166536356528538,
      "grad_norm": 0.3781315088272095,
      "learning_rate": 6.834245504300235e-05,
      "loss": 0.0675,
      "step": 4050
    },
    {
      "epoch": 3.166536356528538,
      "step": 4050,
      "train/forward_time_ms": 2.4378299713134766,
      "train/loss": 0.06815715879201889,
      "train/loss_affordance": 0.022963525727391243,
      "train/loss_compute_time_ms": 0.3192424774169922,
      "train/loss_risk": 0.022963525727391243,
      "train/loss_structure": 0.022230107337236404
    },
    {
      "epoch": 3.166536356528538,
      "step": 4050,
      "train/forward_time_ms": 4.438943862915039,
      "train/step_time_ms": 4.439444541931152
    },
    {
      "epoch": 3.205629397967162,
      "grad_norm": 0.2498294860124588,
      "learning_rate": 6.795152462861612e-05,
      "loss": 0.0682,
      "step": 4100
    },
    {
      "epoch": 3.205629397967162,
      "step": 4100,
      "train/forward_time_ms": 2.794981002807617,
      "train/loss": 0.05921034887433052,
      "train/loss_affordance": 0.016837994568049908,
      "train/loss_compute_time_ms": 0.34308433532714844,
      "train/loss_risk": 0.016837994568049908,
      "train/loss_structure": 0.025534359738230705
    },
    {
      "epoch": 3.205629397967162,
      "step": 4100,
      "train/forward_time_ms": 4.4870758056640625,
      "train/step_time_ms": 4.487566947937012
    },
    {
      "epoch": 3.244722439405786,
      "grad_norm": 0.1927141547203064,
      "learning_rate": 6.756059421422986e-05,
      "loss": 0.0669,
      "step": 4150
    },
    {
      "epoch": 3.244722439405786,
      "step": 4150,
      "train/forward_time_ms": 2.465963363647461,
      "train/loss": 0.06722802668809891,
      "train/loss_affordance": 0.02482554130256176,
      "train/loss_compute_time_ms": 0.3044605255126953,
      "train/loss_risk": 0.02482554130256176,
      "train/loss_structure": 0.017576944082975388
    },
    {
      "epoch": 3.244722439405786,
      "step": 4150,
      "train/forward_time_ms": 4.456605911254883,
      "train/step_time_ms": 4.457144737243652
    },
    {
      "epoch": 3.2838154808444098,
      "grad_norm": 0.4479442238807678,
      "learning_rate": 6.716966379984363e-05,
      "loss": 0.0685,
      "step": 4200
    },
    {
      "epoch": 3.2838154808444098,
      "step": 4200,
      "train/forward_time_ms": 2.5634765625,
      "train/loss": 0.07447555661201477,
      "train/loss_affordance": 0.02581675536930561,
      "train/loss_compute_time_ms": 0.37097930908203125,
      "train/loss_risk": 0.02581675536930561,
      "train/loss_structure": 0.02284204587340355
    },
    {
      "epoch": 3.2838154808444098,
      "step": 4200,
      "train/forward_time_ms": 4.584603309631348,
      "train/step_time_ms": 4.585065841674805
    },
    {
      "epoch": 3.3229085222830337,
      "grad_norm": 0.306803822517395,
      "learning_rate": 6.677873338545739e-05,
      "loss": 0.065,
      "step": 4250
    },
    {
      "epoch": 3.3229085222830337,
      "step": 4250,
      "train/forward_time_ms": 3.727436065673828,
      "train/loss": 0.08703663945198059,
      "train/loss_affordance": 0.0336636072024703,
      "train/loss_compute_time_ms": 0.3097057342529297,
      "train/loss_risk": 0.0336636072024703,
      "train/loss_structure": 0.019709425047039986
    },
    {
      "epoch": 3.3229085222830337,
      "step": 4250,
      "train/forward_time_ms": 4.361443519592285,
      "train/step_time_ms": 4.361834526062012
    },
    {
      "epoch": 3.3620015637216576,
      "grad_norm": 0.29534220695495605,
      "learning_rate": 6.638780297107116e-05,
      "loss": 0.0694,
      "step": 4300
    },
    {
      "epoch": 3.3620015637216576,
      "step": 4300,
      "train/forward_time_ms": 2.3314952850341797,
      "train/loss": 0.07422804832458496,
      "train/loss_affordance": 0.018059037625789642,
      "train/loss_compute_time_ms": 0.324249267578125,
      "train/loss_risk": 0.018059037625789642,
      "train/loss_structure": 0.038109973073005676
    },
    {
      "epoch": 3.3620015637216576,
      "step": 4300,
      "train/forward_time_ms": 4.521698951721191,
      "train/step_time_ms": 4.522209167480469
    },
    {
      "epoch": 3.4010946051602815,
      "grad_norm": 0.29646605253219604,
      "learning_rate": 6.59968725566849e-05,
      "loss": 0.0645,
      "step": 4350
    },
    {
      "epoch": 3.4010946051602815,
      "step": 4350,
      "train/forward_time_ms": 2.249479293823242,
      "train/loss": 0.05178992077708244,
      "train/loss_affordance": 0.0155672337859869,
      "train/loss_compute_time_ms": 0.2868175506591797,
      "train/loss_risk": 0.0155672337859869,
      "train/loss_structure": 0.020655453205108643
    },
    {
      "epoch": 3.4010946051602815,
      "step": 4350,
      "train/forward_time_ms": 4.32772159576416,
      "train/step_time_ms": 4.328169822692871
    },
    {
      "epoch": 3.4401876465989054,
      "grad_norm": 0.33945974707603455,
      "learning_rate": 6.560594214229867e-05,
      "loss": 0.0641,
      "step": 4400
    },
    {
      "epoch": 3.4401876465989054,
      "step": 4400,
      "train/forward_time_ms": 2.8100013732910156,
      "train/loss": 0.07485142350196838,
      "train/loss_affordance": 0.02589650172740221,
      "train/loss_compute_time_ms": 0.44274330139160156,
      "train/loss_risk": 0.02589650172740221,
      "train/loss_structure": 0.023058420047163963
    },
    {
      "epoch": 3.4401876465989054,
      "step": 4400,
      "train/forward_time_ms": 4.283289909362793,
      "train/step_time_ms": 4.28375244140625
    },
    {
      "epoch": 3.4792806880375293,
      "grad_norm": 0.5200709700584412,
      "learning_rate": 6.521501172791243e-05,
      "loss": 0.0636,
      "step": 4450
    },
    {
      "epoch": 3.4792806880375293,
      "step": 4450,
      "train/forward_time_ms": 3.1197071075439453,
      "train/loss": 0.05827118456363678,
      "train/loss_affordance": 0.01990948896855116,
      "train/loss_compute_time_ms": 0.4203319549560547,
      "train/loss_risk": 0.01990948896855116,
      "train/loss_structure": 0.018452206626534462
    },
    {
      "epoch": 3.4792806880375293,
      "step": 4450,
      "train/forward_time_ms": 4.505681991577148,
      "train/step_time_ms": 4.506125450134277
    },
    {
      "epoch": 3.5183737294761532,
      "grad_norm": 0.17194712162017822,
      "learning_rate": 6.48240813135262e-05,
      "loss": 0.0632,
      "step": 4500
    },
    {
      "epoch": 3.5183737294761532,
      "step": 4500,
      "train/forward_time_ms": 2.6235580444335938,
      "train/loss": 0.056670982390642166,
      "train/loss_affordance": 0.023335896898061037,
      "train/loss_compute_time_ms": 0.3848075866699219,
      "train/loss_risk": 0.023335896898061037,
      "train/loss_structure": 0.009999188594520092
    },
    {
      "epoch": 3.5183737294761532,
      "step": 4500,
      "train/forward_time_ms": 4.632511138916016,
      "train/step_time_ms": 4.633011817932129
    },
    {
      "epoch": 3.557466770914777,
      "grad_norm": 0.26054248213768005,
      "learning_rate": 6.443315089913996e-05,
      "loss": 0.0644,
      "step": 4550
    },
    {
      "epoch": 3.557466770914777,
      "step": 4550,
      "train/forward_time_ms": 2.5157928466796875,
      "train/loss": 0.06387230008840561,
      "train/loss_affordance": 0.02485692175105214,
      "train/loss_compute_time_ms": 0.4706382751464844,
      "train/loss_risk": 0.02485692175105214,
      "train/loss_structure": 0.014158456586301327
    },
    {
      "epoch": 3.557466770914777,
      "step": 4550,
      "train/forward_time_ms": 4.303011894226074,
      "train/step_time_ms": 4.303417205810547
    },
    {
      "epoch": 3.596559812353401,
      "grad_norm": 0.1674020141363144,
      "learning_rate": 6.404222048475371e-05,
      "loss": 0.0638,
      "step": 4600
    },
    {
      "epoch": 3.596559812353401,
      "step": 4600,
      "train/forward_time_ms": 2.5665760040283203,
      "train/loss": 0.04996471852064133,
      "train/loss_affordance": 0.017148232087492943,
      "train/loss_compute_time_ms": 0.3440380096435547,
      "train/loss_risk": 0.017148232087492943,
      "train/loss_structure": 0.01566825434565544
    },
    {
      "epoch": 3.596559812353401,
      "step": 4600,
      "train/forward_time_ms": 4.253878593444824,
      "train/step_time_ms": 4.254298210144043
    },
    {
      "epoch": 3.635652853792025,
      "grad_norm": 1.057292103767395,
      "learning_rate": 6.365129007036747e-05,
      "loss": 0.0631,
      "step": 4650
    },
    {
      "epoch": 3.635652853792025,
      "step": 4650,
      "train/forward_time_ms": 2.7310848236083984,
      "train/loss": 0.06715303659439087,
      "train/loss_affordance": 0.0210323054343462,
      "train/loss_compute_time_ms": 0.2620220184326172,
      "train/loss_risk": 0.0210323054343462,
      "train/loss_structure": 0.02508842572569847
    },
    {
      "epoch": 3.635652853792025,
      "step": 4650,
      "train/forward_time_ms": 4.331579208374023,
      "train/step_time_ms": 4.332056045532227
    },
    {
      "epoch": 3.674745895230649,
      "grad_norm": 0.25276654958724976,
      "learning_rate": 6.326035965598124e-05,
      "loss": 0.0631,
      "step": 4700
    },
    {
      "epoch": 3.674745895230649,
      "step": 4700,
      "train/forward_time_ms": 2.4695396423339844,
      "train/loss": 0.06885940581560135,
      "train/loss_affordance": 0.02349959034472704,
      "train/loss_compute_time_ms": 0.3800392150878906,
      "train/loss_risk": 0.02349959034472704,
      "train/loss_structure": 0.02186022512614727
    },
    {
      "epoch": 3.674745895230649,
      "step": 4700,
      "train/forward_time_ms": 4.253907203674316,
      "train/step_time_ms": 4.254369735717773
    },
    {
      "epoch": 3.713838936669273,
      "grad_norm": 0.18010203540325165,
      "learning_rate": 6.2869429241595e-05,
      "loss": 0.0648,
      "step": 4750
    },
    {
      "epoch": 3.713838936669273,
      "step": 4750,
      "train/forward_time_ms": 2.3202896118164062,
      "train/loss": 0.06425322592258453,
      "train/loss_affordance": 0.022577792406082153,
      "train/loss_compute_time_ms": 0.2911090850830078,
      "train/loss_risk": 0.022577792406082153,
      "train/loss_structure": 0.019097641110420227
    },
    {
      "epoch": 3.713838936669273,
      "step": 4750,
      "train/forward_time_ms": 4.3781232833862305,
      "train/step_time_ms": 4.378595352172852
    },
    {
      "epoch": 3.7529319781078967,
      "grad_norm": 0.37535640597343445,
      "learning_rate": 6.247849882720877e-05,
      "loss": 0.0619,
      "step": 4800
    },
    {
      "epoch": 3.7529319781078967,
      "step": 4800,
      "train/forward_time_ms": 2.285003662109375,
      "train/loss": 0.05454239249229431,
      "train/loss_affordance": 0.021520091220736504,
      "train/loss_compute_time_ms": 0.3833770751953125,
      "train/loss_risk": 0.021520091220736504,
      "train/loss_structure": 0.011502210050821304
    },
    {
      "epoch": 3.7529319781078967,
      "step": 4800,
      "train/forward_time_ms": 4.2426347732543945,
      "train/step_time_ms": 4.243102073669434
    },
    {
      "epoch": 3.7920250195465206,
      "grad_norm": 0.2436237782239914,
      "learning_rate": 6.208756841282251e-05,
      "loss": 0.0615,
      "step": 4850
    },
    {
      "epoch": 3.7920250195465206,
      "step": 4850,
      "train/forward_time_ms": 2.223968505859375,
      "train/loss": 0.06160644441843033,
      "train/loss_affordance": 0.020366469398140907,
      "train/loss_compute_time_ms": 0.3104209899902344,
      "train/loss_risk": 0.020366469398140907,
      "train/loss_structure": 0.020873505622148514
    },
    {
      "epoch": 3.7920250195465206,
      "step": 4850,
      "train/forward_time_ms": 4.250969886779785,
      "train/step_time_ms": 4.251441955566406
    },
    {
      "epoch": 3.8311180609851445,
      "grad_norm": 0.6396572589874268,
      "learning_rate": 6.169663799843628e-05,
      "loss": 0.06,
      "step": 4900
    },
    {
      "epoch": 3.8311180609851445,
      "step": 4900,
      "train/forward_time_ms": 2.6962757110595703,
      "train/loss": 0.0733097493648529,
      "train/loss_affordance": 0.023272154852747917,
      "train/loss_compute_time_ms": 0.36907196044921875,
      "train/loss_risk": 0.023272154852747917,
      "train/loss_structure": 0.02676543965935707
    },
    {
      "epoch": 3.8311180609851445,
      "step": 4900,
      "train/forward_time_ms": 4.297981262207031,
      "train/step_time_ms": 4.298372268676758
    },
    {
      "epoch": 3.8702111024237684,
      "grad_norm": 0.45452845096588135,
      "learning_rate": 6.130570758405004e-05,
      "loss": 0.0606,
      "step": 4950
    },
    {
      "epoch": 3.8702111024237684,
      "step": 4950,
      "train/forward_time_ms": 2.4213790893554688,
      "train/loss": 0.05663469061255455,
      "train/loss_affordance": 0.02020491473376751,
      "train/loss_compute_time_ms": 0.32401084899902344,
      "train/loss_risk": 0.02020491473376751,
      "train/loss_structure": 0.01622486114501953
    },
    {
      "epoch": 3.8702111024237684,
      "step": 4950,
      "train/forward_time_ms": 4.343352317810059,
      "train/step_time_ms": 4.343776702880859
    },
    {
      "epoch": 3.9093041438623923,
      "grad_norm": 0.35625919699668884,
      "learning_rate": 6.091477716966381e-05,
      "loss": 0.0592,
      "step": 5000
    },
    {
      "epoch": 3.9093041438623923,
      "step": 5000,
      "train/forward_time_ms": 2.6521682739257812,
      "train/loss": 0.053645770996809006,
      "train/loss_affordance": 0.017491898499429226,
      "train/loss_compute_time_ms": 0.4558563232421875,
      "train/loss_risk": 0.017491898499429226,
      "train/loss_structure": 0.018661973997950554
    },
    {
      "epoch": 3.9093041438623923,
      "step": 5000,
      "train/forward_time_ms": 4.443445205688477,
      "train/step_time_ms": 4.443926811218262
    },
    {
      "epoch": 3.9483971853010162,
      "grad_norm": 0.23120875656604767,
      "learning_rate": 6.052384675527757e-05,
      "loss": 0.0597,
      "step": 5050
    },
    {
      "epoch": 3.9483971853010162,
      "step": 5050,
      "train/forward_time_ms": 2.2764205932617188,
      "train/loss": 0.07173530757427216,
      "train/loss_affordance": 0.029877271968871355,
      "train/loss_compute_time_ms": 0.29206275939941406,
      "train/loss_risk": 0.029877271968871355,
      "train/loss_structure": 0.011980763636529446
    },
    {
      "epoch": 3.9483971853010162,
      "step": 5050,
      "train/forward_time_ms": 4.346356391906738,
      "train/step_time_ms": 4.346785545349121
    },
    {
      "epoch": 3.9874902267396406,
      "grad_norm": 0.3534241318702698,
      "learning_rate": 6.013291634089132e-05,
      "loss": 0.0597,
      "step": 5100
    },
    {
      "epoch": 3.9874902267396406,
      "step": 5100,
      "train/forward_time_ms": 2.459287643432617,
      "train/loss": 0.058600593358278275,
      "train/loss_affordance": 0.02127084042876959,
      "train/loss_compute_time_ms": 0.32830238342285156,
      "train/loss_risk": 0.02127084042876959,
      "train/loss_structure": 0.016058912500739098
    },
    {
      "epoch": 3.9874902267396406,
      "step": 5100,
      "train/forward_time_ms": 4.334468841552734,
      "train/step_time_ms": 4.334931373596191
    },
    {
      "epoch": 4.026583268178264,
      "grad_norm": 0.21342891454696655,
      "learning_rate": 5.9741985926505086e-05,
      "loss": 0.0593,
      "step": 5150
    },
    {
      "epoch": 4.026583268178264,
      "step": 5150,
      "train/forward_time_ms": 2.488374710083008,
      "train/loss": 0.06386488676071167,
      "train/loss_affordance": 0.022142786532640457,
      "train/loss_compute_time_ms": 0.3485679626464844,
      "train/loss_risk": 0.022142786532640457,
      "train/loss_structure": 0.019579313695430756
    },
    {
      "epoch": 4.026583268178264,
      "step": 5150,
      "train/forward_time_ms": 4.257302284240723,
      "train/step_time_ms": 4.257745742797852
    },
    {
      "epoch": 4.065676309616888,
      "grad_norm": 0.1891809105873108,
      "learning_rate": 5.935105551211885e-05,
      "loss": 0.0595,
      "step": 5200
    },
    {
      "epoch": 4.065676309616888,
      "step": 5200,
      "train/forward_time_ms": 2.964496612548828,
      "train/loss": 0.053956422954797745,
      "train/loss_affordance": 0.018810556270182133,
      "train/loss_compute_time_ms": 0.35858154296875,
      "train/loss_risk": 0.018810556270182133,
      "train/loss_structure": 0.01633531041443348
    },
    {
      "epoch": 4.065676309616888,
      "step": 5200,
      "train/forward_time_ms": 4.565534591674805,
      "train/step_time_ms": 4.565954208374023
    },
    {
      "epoch": 4.104769351055512,
      "grad_norm": 0.1696978509426117,
      "learning_rate": 5.896012509773261e-05,
      "loss": 0.0588,
      "step": 5250
    },
    {
      "epoch": 4.104769351055512,
      "step": 5250,
      "train/forward_time_ms": 2.2530555725097656,
      "train/loss": 0.06848528236150742,
      "train/loss_affordance": 0.02827576780691743,
      "train/loss_compute_time_ms": 0.3085136413574219,
      "train/loss_risk": 0.02827576780691743,
      "train/loss_structure": 0.011933746747672558
    },
    {
      "epoch": 4.104769351055512,
      "step": 5250,
      "train/forward_time_ms": 4.303703308105469,
      "train/step_time_ms": 4.304065704345703
    },
    {
      "epoch": 4.143862392494136,
      "grad_norm": 0.3222469389438629,
      "learning_rate": 5.856919468334636e-05,
      "loss": 0.059,
      "step": 5300
    },
    {
      "epoch": 4.143862392494136,
      "step": 5300,
      "train/forward_time_ms": 2.3429393768310547,
      "train/loss": 0.06824814528226852,
      "train/loss_affordance": 0.026105099357664585,
      "train/loss_compute_time_ms": 0.3001689910888672,
      "train/loss_risk": 0.026105099357664585,
      "train/loss_structure": 0.016037946566939354
    },
    {
      "epoch": 4.143862392494136,
      "step": 5300,
      "train/forward_time_ms": 4.202589988708496,
      "train/step_time_ms": 4.203033447265625
    },
    {
      "epoch": 4.18295543393276,
      "grad_norm": 0.17409126460552216,
      "learning_rate": 5.817826426896013e-05,
      "loss": 0.0627,
      "step": 5350
    },
    {
      "epoch": 4.18295543393276,
      "step": 5350,
      "train/forward_time_ms": 2.308368682861328,
      "train/loss": 0.0602693036198616,
      "train/loss_affordance": 0.020313484594225883,
      "train/loss_compute_time_ms": 0.2968311309814453,
      "train/loss_risk": 0.020313484594225883,
      "train/loss_structure": 0.019642334431409836
    },
    {
      "epoch": 4.18295543393276,
      "step": 5350,
      "train/forward_time_ms": 4.286894798278809,
      "train/step_time_ms": 4.287314414978027
    },
    {
      "epoch": 4.222048475371384,
      "grad_norm": 0.1410510241985321,
      "learning_rate": 5.778733385457389e-05,
      "loss": 0.0593,
      "step": 5400
    },
    {
      "epoch": 4.222048475371384,
      "step": 5400,
      "train/forward_time_ms": 2.586841583251953,
      "train/loss": 0.06663349270820618,
      "train/loss_affordance": 0.021391673013567924,
      "train/loss_compute_time_ms": 0.3724098205566406,
      "train/loss_risk": 0.021391673013567924,
      "train/loss_structure": 0.023850146681070328
    },
    {
      "epoch": 4.222048475371384,
      "step": 5400,
      "train/forward_time_ms": 4.278926849365234,
      "train/step_time_ms": 4.2794036865234375
    },
    {
      "epoch": 4.2611415168100075,
      "grad_norm": 0.537773072719574,
      "learning_rate": 5.7396403440187654e-05,
      "loss": 0.0579,
      "step": 5450
    },
    {
      "epoch": 4.2611415168100075,
      "step": 5450,
      "train/forward_time_ms": 2.4251937866210938,
      "train/loss": 0.0670255720615387,
      "train/loss_affordance": 0.023812956176698208,
      "train/loss_compute_time_ms": 0.30732154846191406,
      "train/loss_risk": 0.023812956176698208,
      "train/loss_structure": 0.01939965970814228
    },
    {
      "epoch": 4.2611415168100075,
      "step": 5450,
      "train/forward_time_ms": 4.38084602355957,
      "train/step_time_ms": 4.381284713745117
    },
    {
      "epoch": 4.300234558248632,
      "grad_norm": 0.5523756146430969,
      "learning_rate": 5.700547302580142e-05,
      "loss": 0.0564,
      "step": 5500
    },
    {
      "epoch": 4.300234558248632,
      "step": 5500,
      "train/forward_time_ms": 2.4650096893310547,
      "train/loss": 0.05427074432373047,
      "train/loss_affordance": 0.019706309773027897,
      "train/loss_compute_time_ms": 0.30922889709472656,
      "train/loss_risk": 0.019706309773027897,
      "train/loss_structure": 0.014858124777674675
    },
    {
      "epoch": 4.300234558248632,
      "step": 5500,
      "train/forward_time_ms": 4.164419174194336,
      "train/step_time_ms": 4.164819717407227
    },
    {
      "epoch": 4.339327599687255,
      "grad_norm": 0.34673574566841125,
      "learning_rate": 5.661454261141517e-05,
      "loss": 0.0568,
      "step": 5550
    },
    {
      "epoch": 4.339327599687255,
      "step": 5550,
      "train/forward_time_ms": 2.306699752807617,
      "train/loss": 0.04266643524169922,
      "train/loss_affordance": 0.011767620220780373,
      "train/loss_compute_time_ms": 0.3216266632080078,
      "train/loss_risk": 0.011767620220780373,
      "train/loss_structure": 0.019131194800138474
    },
    {
      "epoch": 4.339327599687255,
      "step": 5550,
      "train/forward_time_ms": 4.210071563720703,
      "train/step_time_ms": 4.210515022277832
    },
    {
      "epoch": 4.37842064112588,
      "grad_norm": 0.16264566779136658,
      "learning_rate": 5.622361219702893e-05,
      "loss": 0.0595,
      "step": 5600
    },
    {
      "epoch": 4.37842064112588,
      "step": 5600,
      "train/forward_time_ms": 2.5572776794433594,
      "train/loss": 0.04810537025332451,
      "train/loss_affordance": 0.01840990874916315,
      "train/loss_compute_time_ms": 0.31876564025878906,
      "train/loss_risk": 0.01840990874916315,
      "train/loss_structure": 0.011285552754998207
    },
    {
      "epoch": 4.37842064112588,
      "step": 5600,
      "train/forward_time_ms": 4.2330169677734375,
      "train/step_time_ms": 4.233455657958984
    },
    {
      "epoch": 4.417513682564503,
      "grad_norm": 0.30766355991363525,
      "learning_rate": 5.5832681782642695e-05,
      "loss": 0.0566,
      "step": 5650
    },
    {
      "epoch": 4.417513682564503,
      "step": 5650,
      "train/forward_time_ms": 2.3450851440429688,
      "train/loss": 0.05433717370033264,
      "train/loss_affordance": 0.019169820472598076,
      "train/loss_compute_time_ms": 0.30112266540527344,
      "train/loss_risk": 0.019169820472598076,
      "train/loss_structure": 0.01599753275513649
    },
    {
      "epoch": 4.417513682564503,
      "step": 5650,
      "train/forward_time_ms": 4.300265312194824,
      "train/step_time_ms": 4.300713539123535
    },
    {
      "epoch": 4.4566067240031275,
      "grad_norm": 0.3372570276260376,
      "learning_rate": 5.544175136825646e-05,
      "loss": 0.0572,
      "step": 5700
    },
    {
      "epoch": 4.4566067240031275,
      "step": 5700,
      "train/forward_time_ms": 2.40325927734375,
      "train/loss": 0.04332860931754112,
      "train/loss_affordance": 0.015681262128055096,
      "train/loss_compute_time_ms": 0.3044605255126953,
      "train/loss_risk": 0.015681262128055096,
      "train/loss_structure": 0.011966085061430931
    },
    {
      "epoch": 4.4566067240031275,
      "step": 5700,
      "train/forward_time_ms": 4.470219612121582,
      "train/step_time_ms": 4.470725059509277
    },
    {
      "epoch": 4.495699765441751,
      "grad_norm": 0.318626344203949,
      "learning_rate": 5.505082095387022e-05,
      "loss": 0.0549,
      "step": 5750
    },
    {
      "epoch": 4.495699765441751,
      "step": 5750,
      "train/forward_time_ms": 2.5267601013183594,
      "train/loss": 0.05752861872315407,
      "train/loss_affordance": 0.01905775535851717,
      "train/loss_compute_time_ms": 0.4246234893798828,
      "train/loss_risk": 0.01905775535851717,
      "train/loss_structure": 0.019413108006119728
    },
    {
      "epoch": 4.495699765441751,
      "step": 5750,
      "train/forward_time_ms": 4.367213249206543,
      "train/step_time_ms": 4.36769962310791
    },
    {
      "epoch": 4.534792806880375,
      "grad_norm": 0.380488783121109,
      "learning_rate": 5.465989053948397e-05,
      "loss": 0.0576,
      "step": 5800
    },
    {
      "epoch": 4.534792806880375,
      "step": 5800,
      "train/forward_time_ms": 2.2857189178466797,
      "train/loss": 0.057455867528915405,
      "train/loss_affordance": 0.020064673386514187,
      "train/loss_compute_time_ms": 0.31280517578125,
      "train/loss_risk": 0.020064673386514187,
      "train/loss_structure": 0.01732652075588703
    },
    {
      "epoch": 4.534792806880375,
      "step": 5800,
      "train/forward_time_ms": 4.2852020263671875,
      "train/step_time_ms": 4.285616874694824
    },
    {
      "epoch": 4.573885848319,
      "grad_norm": 0.3676677644252777,
      "learning_rate": 5.4268960125097736e-05,
      "loss": 0.0542,
      "step": 5850
    },
    {
      "epoch": 4.573885848319,
      "step": 5850,
      "train/forward_time_ms": 2.3653507232666016,
      "train/loss": 0.06918607652187347,
      "train/loss_affordance": 0.0249585323035717,
      "train/loss_compute_time_ms": 0.3151893615722656,
      "train/loss_risk": 0.0249585323035717,
      "train/loss_structure": 0.019269011914730072
    },
    {
      "epoch": 4.573885848319,
      "step": 5850,
      "train/forward_time_ms": 4.219317436218262,
      "train/step_time_ms": 4.219775199890137
    },
    {
      "epoch": 4.612978889757623,
      "grad_norm": 0.1023329645395279,
      "learning_rate": 5.38780297107115e-05,
      "loss": 0.0592,
      "step": 5900
    },
    {
      "epoch": 4.612978889757623,
      "step": 5900,
      "train/forward_time_ms": 2.461671829223633,
      "train/loss": 0.06587964296340942,
      "train/loss_affordance": 0.01926831156015396,
      "train/loss_compute_time_ms": 0.3104209899902344,
      "train/loss_risk": 0.01926831156015396,
      "train/loss_structure": 0.0273430198431015
    },
    {
      "epoch": 4.612978889757623,
      "step": 5900,
      "train/forward_time_ms": 4.200735092163086,
      "train/step_time_ms": 4.201211929321289
    },
    {
      "epoch": 4.652071931196247,
      "grad_norm": 0.3708551824092865,
      "learning_rate": 5.348709929632526e-05,
      "loss": 0.0563,
      "step": 5950
    },
    {
      "epoch": 4.652071931196247,
      "step": 5950,
      "train/forward_time_ms": 2.410888671875,
      "train/loss": 0.04725845158100128,
      "train/loss_affordance": 0.015010040253400803,
      "train/loss_compute_time_ms": 0.2903938293457031,
      "train/loss_risk": 0.015010040253400803,
      "train/loss_structure": 0.017238371074199677
    },
    {
      "epoch": 4.652071931196247,
      "step": 5950,
      "train/forward_time_ms": 4.494838714599609,
      "train/step_time_ms": 4.495296478271484
    },
    {
      "epoch": 4.691164972634871,
      "grad_norm": 0.29411017894744873,
      "learning_rate": 5.309616888193901e-05,
      "loss": 0.0556,
      "step": 6000
    },
    {
      "epoch": 4.691164972634871,
      "step": 6000,
      "train/forward_time_ms": 2.3500919342041016,
      "train/loss": 0.04746130108833313,
      "train/loss_affordance": 0.016341520939022303,
      "train/loss_compute_time_ms": 0.3509521484375,
      "train/loss_risk": 0.016341520939022303,
      "train/loss_structure": 0.014778259210288525
    },
    {
      "epoch": 4.691164972634871,
      "step": 6000,
      "train/forward_time_ms": 4.358205795288086,
      "train/step_time_ms": 4.358649253845215
    },
    {
      "epoch": 4.730258014073495,
      "grad_norm": 0.37094688415527344,
      "learning_rate": 5.270523846755278e-05,
      "loss": 0.0561,
      "step": 6050
    },
    {
      "epoch": 4.730258014073495,
      "step": 6050,
      "train/forward_time_ms": 2.378225326538086,
      "train/loss": 0.0617702379822731,
      "train/loss_affordance": 0.02424642350524664,
      "train/loss_compute_time_ms": 0.3476142883300781,
      "train/loss_risk": 0.02424642350524664,
      "train/loss_structure": 0.013277390971779823
    },
    {
      "epoch": 4.730258014073495,
      "step": 6050,
      "train/forward_time_ms": 4.245619773864746,
      "train/step_time_ms": 4.246044158935547
    },
    {
      "epoch": 4.769351055512119,
      "grad_norm": 0.23377524316310883,
      "learning_rate": 5.231430805316654e-05,
      "loss": 0.0529,
      "step": 6100
    },
    {
      "epoch": 4.769351055512119,
      "step": 6100,
      "train/forward_time_ms": 2.237081527709961,
      "train/loss": 0.06745575368404388,
      "train/loss_affordance": 0.02655598009005189,
      "train/loss_compute_time_ms": 0.3116130828857422,
      "train/loss_risk": 0.02655598009005189,
      "train/loss_structure": 0.014343793503940105
    },
    {
      "epoch": 4.769351055512119,
      "step": 6100,
      "train/forward_time_ms": 4.275665283203125,
      "train/step_time_ms": 4.276123046875
    },
    {
      "epoch": 4.808444096950743,
      "grad_norm": 0.41158977150917053,
      "learning_rate": 5.1923377638780304e-05,
      "loss": 0.0537,
      "step": 6150
    },
    {
      "epoch": 4.808444096950743,
      "step": 6150,
      "train/forward_time_ms": 2.3369789123535156,
      "train/loss": 0.05983676016330719,
      "train/loss_affordance": 0.021700648590922356,
      "train/loss_compute_time_ms": 0.31495094299316406,
      "train/loss_risk": 0.021700648590922356,
      "train/loss_structure": 0.01643546298146248
    },
    {
      "epoch": 4.808444096950743,
      "step": 6150,
      "train/forward_time_ms": 4.240775108337402,
      "train/step_time_ms": 4.241242408752441
    },
    {
      "epoch": 4.847537138389367,
      "grad_norm": 0.34121015667915344,
      "learning_rate": 5.153244722439407e-05,
      "loss": 0.0563,
      "step": 6200
    },
    {
      "epoch": 4.847537138389367,
      "step": 6200,
      "train/forward_time_ms": 2.32696533203125,
      "train/loss": 0.04630674794316292,
      "train/loss_affordance": 0.017743325792253017,
      "train/loss_compute_time_ms": 0.3018379211425781,
      "train/loss_risk": 0.017743325792253017,
      "train/loss_structure": 0.010820096358656883
    },
    {
      "epoch": 4.847537138389367,
      "step": 6200,
      "train/forward_time_ms": 4.358730316162109,
      "train/step_time_ms": 4.360218048095703
    },
    {
      "epoch": 4.886630179827991,
      "grad_norm": 0.19914190471172333,
      "learning_rate": 5.114151681000782e-05,
      "loss": 0.0558,
      "step": 6250
    },
    {
      "epoch": 4.886630179827991,
      "step": 6250,
      "train/forward_time_ms": 2.3870468139648438,
      "train/loss": 0.09445153921842575,
      "train/loss_affordance": 0.030621301382780075,
      "train/loss_compute_time_ms": 0.301361083984375,
      "train/loss_risk": 0.030621301382780075,
      "train/loss_structure": 0.0332089364528656
    },
    {
      "epoch": 4.886630179827991,
      "step": 6250,
      "train/forward_time_ms": 4.282932281494141,
      "train/step_time_ms": 4.2833709716796875
    },
    {
      "epoch": 4.925723221266614,
      "grad_norm": 0.14406226575374603,
      "learning_rate": 5.075058639562158e-05,
      "loss": 0.0546,
      "step": 6300
    },
    {
      "epoch": 4.925723221266614,
      "step": 6300,
      "train/forward_time_ms": 2.7484893798828125,
      "train/loss": 0.06696119159460068,
      "train/loss_affordance": 0.02620359044522047,
      "train/loss_compute_time_ms": 0.33783912658691406,
      "train/loss_risk": 0.02620359044522047,
      "train/loss_structure": 0.014554010704159737
    },
    {
      "epoch": 4.925723221266614,
      "step": 6300,
      "train/forward_time_ms": 4.364032745361328,
      "train/step_time_ms": 4.366583824157715
    },
    {
      "epoch": 4.964816262705239,
      "grad_norm": 0.3306550681591034,
      "learning_rate": 5.0359655981235345e-05,
      "loss": 0.054,
      "step": 6350
    },
    {
      "epoch": 4.964816262705239,
      "step": 6350,
      "train/forward_time_ms": 2.6159286499023438,
      "train/loss": 0.059414032846689224,
      "train/loss_affordance": 0.022279849275946617,
      "train/loss_compute_time_ms": 0.3209114074707031,
      "train/loss_risk": 0.022279849275946617,
      "train/loss_structure": 0.01485433429479599
    },
    {
      "epoch": 4.964816262705239,
      "step": 6350,
      "train/forward_time_ms": 4.240612983703613,
      "train/step_time_ms": 4.241032600402832
    },
    {
      "epoch": 5.003909304143862,
      "grad_norm": 0.4621531069278717,
      "learning_rate": 4.99687255668491e-05,
      "loss": 0.0564,
      "step": 6400
    },
    {
      "epoch": 5.003909304143862,
      "step": 6400,
      "train/forward_time_ms": 2.3479461669921875,
      "train/loss": 0.05344204604625702,
      "train/loss_affordance": 0.019410409033298492,
      "train/loss_compute_time_ms": 0.3750324249267578,
      "train/loss_risk": 0.019410409033298492,
      "train/loss_structure": 0.014621227979660034
    },
    {
      "epoch": 5.003909304143862,
      "step": 6400,
      "train/forward_time_ms": 4.743537902832031,
      "train/step_time_ms": 4.7440385818481445
    },
    {
      "epoch": 5.043002345582487,
      "grad_norm": 0.15141059458255768,
      "learning_rate": 4.9577795152462865e-05,
      "loss": 0.0544,
      "step": 6450
    },
    {
      "epoch": 5.043002345582487,
      "step": 6450,
      "train/forward_time_ms": 2.086162567138672,
      "train/loss": 0.043481431901454926,
      "train/loss_affordance": 0.014486498199403286,
      "train/loss_compute_time_ms": 0.3063678741455078,
      "train/loss_risk": 0.014486498199403286,
      "train/loss_structure": 0.014508435502648354
    },
    {
      "epoch": 5.043002345582487,
      "step": 6450,
      "train/forward_time_ms": 4.653468132019043,
      "train/step_time_ms": 4.653940200805664
    },
    {
      "epoch": 5.08209538702111,
      "grad_norm": 0.47929731011390686,
      "learning_rate": 4.918686473807663e-05,
      "loss": 0.0521,
      "step": 6500
    },
    {
      "epoch": 5.08209538702111,
      "step": 6500,
      "train/forward_time_ms": 3.266572952270508,
      "train/loss": 0.07574974745512009,
      "train/loss_affordance": 0.02851237077265978,
      "train/loss_compute_time_ms": 0.5033016204833984,
      "train/loss_risk": 0.02851237077265978,
      "train/loss_structure": 0.01872500590980053
    },
    {
      "epoch": 5.08209538702111,
      "step": 6500,
      "train/forward_time_ms": 4.650173187255859,
      "train/step_time_ms": 4.650683403015137
    },
    {
      "epoch": 5.121188428459734,
      "grad_norm": 0.21175231039524078,
      "learning_rate": 4.8795934323690386e-05,
      "loss": 0.0552,
      "step": 6550
    },
    {
      "epoch": 5.121188428459734,
      "step": 6550,
      "train/forward_time_ms": 2.3953914642333984,
      "train/loss": 0.03949663043022156,
      "train/loss_affordance": 0.011433200910687447,
      "train/loss_compute_time_ms": 0.3695487976074219,
      "train/loss_risk": 0.011433200910687447,
      "train/loss_structure": 0.016630228608846664
    },
    {
      "epoch": 5.121188428459734,
      "step": 6550,
      "train/forward_time_ms": 4.6067094802856445,
      "train/step_time_ms": 4.607172012329102
    },
    {
      "epoch": 5.160281469898358,
      "grad_norm": 0.17184197902679443,
      "learning_rate": 4.840500390930415e-05,
      "loss": 0.0521,
      "step": 6600
    },
    {
      "epoch": 5.160281469898358,
      "step": 6600,
      "train/forward_time_ms": 2.3512840270996094,
      "train/loss": 0.057173922657966614,
      "train/loss_affordance": 0.01750537008047104,
      "train/loss_compute_time_ms": 0.33974647521972656,
      "train/loss_risk": 0.01750537008047104,
      "train/loss_structure": 0.022163182497024536
    },
    {
      "epoch": 5.160281469898358,
      "step": 6600,
      "train/forward_time_ms": 4.510965347290039,
      "train/step_time_ms": 4.51146125793457
    },
    {
      "epoch": 5.199374511336982,
      "grad_norm": 0.23560932278633118,
      "learning_rate": 4.8014073494917906e-05,
      "loss": 0.053,
      "step": 6650
    },
    {
      "epoch": 5.199374511336982,
      "step": 6650,
      "train/forward_time_ms": 2.275705337524414,
      "train/loss": 0.055733148008584976,
      "train/loss_affordance": 0.022549147717654705,
      "train/loss_compute_time_ms": 0.3483295440673828,
      "train/loss_risk": 0.022549147717654705,
      "train/loss_structure": 0.010634852573275566
    },
    {
      "epoch": 5.199374511336982,
      "step": 6650,
      "train/forward_time_ms": 4.673361778259277,
      "train/step_time_ms": 4.673867225646973
    },
    {
      "epoch": 5.238467552775606,
      "grad_norm": 0.22248463332653046,
      "learning_rate": 4.762314308053167e-05,
      "loss": 0.0556,
      "step": 6700
    },
    {
      "epoch": 5.238467552775606,
      "step": 6700,
      "train/forward_time_ms": 2.440929412841797,
      "train/loss": 0.07214783132076263,
      "train/loss_affordance": 0.023681117221713066,
      "train/loss_compute_time_ms": 0.3762245178222656,
      "train/loss_risk": 0.023681117221713066,
      "train/loss_structure": 0.024785596877336502
    },
    {
      "epoch": 5.238467552775606,
      "step": 6700,
      "train/forward_time_ms": 4.416708946228027,
      "train/step_time_ms": 4.417119026184082
    },
    {
      "epoch": 5.27756059421423,
      "grad_norm": 0.25911200046539307,
      "learning_rate": 4.723221266614543e-05,
      "loss": 0.054,
      "step": 6750
    },
    {
      "epoch": 5.27756059421423,
      "step": 6750,
      "train/forward_time_ms": 2.7763843536376953,
      "train/loss": 0.04628276452422142,
      "train/loss_affordance": 0.01724758418276906,
      "train/loss_compute_time_ms": 0.38504600524902344,
      "train/loss_risk": 0.01724758418276906,
      "train/loss_structure": 0.0117875961586833
    },
    {
      "epoch": 5.27756059421423,
      "step": 6750,
      "train/forward_time_ms": 4.477953910827637,
      "train/step_time_ms": 4.47845458984375
    },
    {
      "epoch": 5.3166536356528535,
      "grad_norm": 0.17969287931919098,
      "learning_rate": 4.684128225175919e-05,
      "loss": 0.0524,
      "step": 6800
    },
    {
      "epoch": 5.3166536356528535,
      "step": 6800,
      "train/forward_time_ms": 2.4161338806152344,
      "train/loss": 0.04335954785346985,
      "train/loss_affordance": 0.013726440258324146,
      "train/loss_compute_time_ms": 0.30803680419921875,
      "train/loss_risk": 0.013726440258324146,
      "train/loss_structure": 0.015906667336821556
    },
    {
      "epoch": 5.3166536356528535,
      "step": 6800,
      "train/forward_time_ms": 4.423074722290039,
      "train/step_time_ms": 4.42349910736084
    },
    {
      "epoch": 5.355746677091478,
      "grad_norm": 0.2390952855348587,
      "learning_rate": 4.6450351837372954e-05,
      "loss": 0.0555,
      "step": 6850
    },
    {
      "epoch": 5.355746677091478,
      "step": 6850,
      "train/forward_time_ms": 2.228975296020508,
      "train/loss": 0.05861372500658035,
      "train/loss_affordance": 0.021365804597735405,
      "train/loss_compute_time_ms": 0.308990478515625,
      "train/loss_risk": 0.021365804597735405,
      "train/loss_structure": 0.015882115811109543
    },
    {
      "epoch": 5.355746677091478,
      "step": 6850,
      "train/forward_time_ms": 4.628925323486328,
      "train/step_time_ms": 4.629430770874023
    },
    {
      "epoch": 5.394839718530101,
      "grad_norm": 0.15109781920909882,
      "learning_rate": 4.605942142298671e-05,
      "loss": 0.0521,
      "step": 6900
    },
    {
      "epoch": 5.394839718530101,
      "step": 6900,
      "train/forward_time_ms": 2.600431442260742,
      "train/loss": 0.05390596762299538,
      "train/loss_affordance": 0.02391331153921783,
      "train/loss_compute_time_ms": 0.4475116729736328,
      "train/loss_risk": 0.02391331153921783,
      "train/loss_structure": 0.006079344544559717
    },
    {
      "epoch": 5.394839718530101,
      "step": 6900,
      "train/forward_time_ms": 4.442553520202637,
      "train/step_time_ms": 4.443330764770508
    },
    {
      "epoch": 5.433932759968726,
      "grad_norm": 0.3880223035812378,
      "learning_rate": 4.5668491008600475e-05,
      "loss": 0.0527,
      "step": 6950
    },
    {
      "epoch": 5.433932759968726,
      "step": 6950,
      "train/forward_time_ms": 2.3734569549560547,
      "train/loss": 0.04423008859157562,
      "train/loss_affordance": 0.015628241002559662,
      "train/loss_compute_time_ms": 0.3113746643066406,
      "train/loss_risk": 0.015628241002559662,
      "train/loss_structure": 0.012973606586456299
    },
    {
      "epoch": 5.433932759968726,
      "step": 6950,
      "train/forward_time_ms": 4.419713020324707,
      "train/step_time_ms": 4.420199394226074
    },
    {
      "epoch": 5.473025801407349,
      "grad_norm": 0.1792929768562317,
      "learning_rate": 4.527756059421423e-05,
      "loss": 0.0546,
      "step": 7000
    },
    {
      "epoch": 5.473025801407349,
      "step": 7000,
      "train/forward_time_ms": 2.6748180389404297,
      "train/loss": 0.04385891556739807,
      "train/loss_affordance": 0.014641117304563522,
      "train/loss_compute_time_ms": 0.38623809814453125,
      "train/loss_risk": 0.014641117304563522,
      "train/loss_structure": 0.014576680958271027
    },
    {
      "epoch": 5.473025801407349,
      "step": 7000,
      "train/forward_time_ms": 4.340014457702637,
      "train/step_time_ms": 4.340481758117676
    },
    {
      "epoch": 5.5121188428459735,
      "grad_norm": 0.21838299930095673,
      "learning_rate": 4.4886630179827995e-05,
      "loss": 0.0528,
      "step": 7050
    },
    {
      "epoch": 5.5121188428459735,
      "step": 7050,
      "train/forward_time_ms": 2.434253692626953,
      "train/loss": 0.05246013402938843,
      "train/loss_affordance": 0.019605060573667288,
      "train/loss_compute_time_ms": 0.3001689910888672,
      "train/loss_risk": 0.019605060573667288,
      "train/loss_structure": 0.013250012882053852
    },
    {
      "epoch": 5.5121188428459735,
      "step": 7050,
      "train/forward_time_ms": 4.319596290588379,
      "train/step_time_ms": 4.3199872970581055
    },
    {
      "epoch": 5.551211884284597,
      "grad_norm": 0.3304218351840973,
      "learning_rate": 4.449569976544176e-05,
      "loss": 0.0563,
      "step": 7100
    },
    {
      "epoch": 5.551211884284597,
      "step": 7100,
      "train/forward_time_ms": 4.476070404052734,
      "train/loss": 0.05262334644794464,
      "train/loss_affordance": 0.018119188025593758,
      "train/loss_compute_time_ms": 0.4456043243408203,
      "train/loss_risk": 0.018119188025593758,
      "train/loss_structure": 0.016384970396757126
    },
    {
      "epoch": 5.551211884284597,
      "step": 7100,
      "train/forward_time_ms": 4.767661094665527,
      "train/step_time_ms": 4.768180847167969
    },
    {
      "epoch": 5.590304925723221,
      "grad_norm": 0.16185560822486877,
      "learning_rate": 4.4104769351055516e-05,
      "loss": 0.0511,
      "step": 7150
    },
    {
      "epoch": 5.590304925723221,
      "step": 7150,
      "train/forward_time_ms": 3.0031204223632812,
      "train/loss": 0.060778237879276276,
      "train/loss_affordance": 0.025018510408699512,
      "train/loss_compute_time_ms": 0.30303001403808594,
      "train/loss_risk": 0.025018510408699512,
      "train/loss_structure": 0.01074121706187725
    },
    {
      "epoch": 5.590304925723221,
      "step": 7150,
      "train/forward_time_ms": 4.64838981628418,
      "train/step_time_ms": 4.648880958557129
    },
    {
      "epoch": 5.629397967161845,
      "grad_norm": 0.3181248903274536,
      "learning_rate": 4.371383893666928e-05,
      "loss": 0.0578,
      "step": 7200
    },
    {
      "epoch": 5.629397967161845,
      "step": 7200,
      "train/forward_time_ms": 2.4836063385009766,
      "train/loss": 0.055035196244716644,
      "train/loss_affordance": 0.020017157308757305,
      "train/loss_compute_time_ms": 0.3311634063720703,
      "train/loss_risk": 0.020017157308757305,
      "train/loss_structure": 0.015000881627202034
    },
    {
      "epoch": 5.629397967161845,
      "step": 7200,
      "train/forward_time_ms": 4.403281211853027,
      "train/step_time_ms": 4.403753280639648
    },
    {
      "epoch": 5.668491008600469,
      "grad_norm": 0.33108076453208923,
      "learning_rate": 4.3322908522283036e-05,
      "loss": 0.0529,
      "step": 7250
    },
    {
      "epoch": 5.668491008600469,
      "step": 7250,
      "train/forward_time_ms": 2.336740493774414,
      "train/loss": 0.06731954216957092,
      "train/loss_affordance": 0.024573941715061665,
      "train/loss_compute_time_ms": 0.3159046173095703,
      "train/loss_risk": 0.024573941715061665,
      "train/loss_structure": 0.018171658739447594
    },
    {
      "epoch": 5.668491008600469,
      "step": 7250,
      "train/forward_time_ms": 4.268627166748047,
      "train/step_time_ms": 4.269042015075684
    },
    {
      "epoch": 5.7075840500390935,
      "grad_norm": 0.88737553358078,
      "learning_rate": 4.29319781078968e-05,
      "loss": 0.0524,
      "step": 7300
    },
    {
      "epoch": 5.7075840500390935,
      "step": 7300,
      "train/forward_time_ms": 2.351045608520508,
      "train/loss": 0.06252305954694748,
      "train/loss_affordance": 0.02407136606052518,
      "train/loss_compute_time_ms": 0.29659271240234375,
      "train/loss_risk": 0.02407136606052518,
      "train/loss_structure": 0.014380327425897121
    },
    {
      "epoch": 5.7075840500390935,
      "step": 7300,
      "train/forward_time_ms": 4.271993637084961,
      "train/step_time_ms": 4.272470474243164
    },
    {
      "epoch": 5.746677091477717,
      "grad_norm": 0.17604757845401764,
      "learning_rate": 4.254104769351056e-05,
      "loss": 0.0533,
      "step": 7350
    },
    {
      "epoch": 5.746677091477717,
      "step": 7350,
      "train/forward_time_ms": 2.8171539306640625,
      "train/loss": 0.06085124984383583,
      "train/loss_affordance": 0.017536915838718414,
      "train/loss_compute_time_ms": 0.45418739318847656,
      "train/loss_risk": 0.017536915838718414,
      "train/loss_structure": 0.025777418166399002
    },
    {
      "epoch": 5.746677091477717,
      "step": 7350,
      "train/forward_time_ms": 4.854679107666016,
      "train/step_time_ms": 4.855189323425293
    },
    {
      "epoch": 5.7857701329163405,
      "grad_norm": 0.21249328553676605,
      "learning_rate": 4.215011727912432e-05,
      "loss": 0.0503,
      "step": 7400
    },
    {
      "epoch": 5.7857701329163405,
      "step": 7400,
      "train/forward_time_ms": 2.3546218872070312,
      "train/loss": 0.05944117531180382,
      "train/loss_affordance": 0.023160631768405437,
      "train/loss_compute_time_ms": 0.3390312194824219,
      "train/loss_risk": 0.023160631768405437,
      "train/loss_structure": 0.013119911774992943
    },
    {
      "epoch": 5.7857701329163405,
      "step": 7400,
      "train/forward_time_ms": 4.498167037963867,
      "train/step_time_ms": 4.498705863952637
    },
    {
      "epoch": 5.824863174354965,
      "grad_norm": 0.29915061593055725,
      "learning_rate": 4.1759186864738084e-05,
      "loss": 0.0499,
      "step": 7450
    },
    {
      "epoch": 5.824863174354965,
      "step": 7450,
      "train/forward_time_ms": 2.4077892303466797,
      "train/loss": 0.04110647365450859,
      "train/loss_affordance": 0.012670766562223434,
      "train/loss_compute_time_ms": 0.2982616424560547,
      "train/loss_risk": 0.012670766562223434,
      "train/loss_structure": 0.015764940530061722
    },
    {
      "epoch": 5.824863174354965,
      "step": 7450,
      "train/forward_time_ms": 4.297466278076172,
      "train/step_time_ms": 4.297904968261719
    },
    {
      "epoch": 5.863956215793589,
      "grad_norm": 0.4594075679779053,
      "learning_rate": 4.136825645035184e-05,
      "loss": 0.0517,
      "step": 7500
    },
    {
      "epoch": 5.863956215793589,
      "step": 7500,
      "train/forward_time_ms": 2.879619598388672,
      "train/loss": 0.05742165446281433,
      "train/loss_affordance": 0.020729662850499153,
      "train/loss_compute_time_ms": 0.41794776916503906,
      "train/loss_risk": 0.020729662850499153,
      "train/loss_structure": 0.015962328761816025
    },
    {
      "epoch": 5.863956215793589,
      "step": 7500,
      "train/forward_time_ms": 4.291467666625977,
      "train/step_time_ms": 4.291892051696777
    },
    {
      "epoch": 5.903049257232213,
      "grad_norm": 0.4966338276863098,
      "learning_rate": 4.0977326035965604e-05,
      "loss": 0.0513,
      "step": 7550
    },
    {
      "epoch": 5.903049257232213,
      "step": 7550,
      "train/forward_time_ms": 2.372264862060547,
      "train/loss": 0.055019162595272064,
      "train/loss_affordance": 0.022115953266620636,
      "train/loss_compute_time_ms": 0.3902912139892578,
      "train/loss_risk": 0.022115953266620636,
      "train/loss_structure": 0.010787256062030792
    },
    {
      "epoch": 5.903049257232213,
      "step": 7550,
      "train/forward_time_ms": 4.257106781005859,
      "train/step_time_ms": 4.257569313049316
    },
    {
      "epoch": 5.942142298670836,
      "grad_norm": 0.18585295975208282,
      "learning_rate": 4.058639562157936e-05,
      "loss": 0.0526,
      "step": 7600
    },
    {
      "epoch": 5.942142298670836,
      "step": 7600,
      "train/forward_time_ms": 2.7523040771484375,
      "train/loss": 0.04106444865465164,
      "train/loss_affordance": 0.01357426680624485,
      "train/loss_compute_time_ms": 0.28061866760253906,
      "train/loss_risk": 0.01357426680624485,
      "train/loss_structure": 0.013915915042161942
    },
    {
      "epoch": 5.942142298670836,
      "step": 7600,
      "train/forward_time_ms": 4.464735984802246,
      "train/step_time_ms": 4.465241432189941
    },
    {
      "epoch": 5.9812353401094605,
      "grad_norm": 0.43250352144241333,
      "learning_rate": 4.0195465207193125e-05,
      "loss": 0.0534,
      "step": 7650
    },
    {
      "epoch": 5.9812353401094605,
      "step": 7650,
      "train/forward_time_ms": 2.312898635864258,
      "train/loss": 0.05206054821610451,
      "train/loss_affordance": 0.0202808640897274,
      "train/loss_compute_time_ms": 0.26488304138183594,
      "train/loss_risk": 0.0202808640897274,
      "train/loss_structure": 0.011498820036649704
    },
    {
      "epoch": 5.9812353401094605,
      "step": 7650,
      "train/forward_time_ms": 4.271144866943359,
      "train/step_time_ms": 4.27154541015625
    },
    {
      "epoch": 6.020328381548085,
      "grad_norm": 0.13686108589172363,
      "learning_rate": 3.980453479280688e-05,
      "loss": 0.0536,
      "step": 7700
    },
    {
      "epoch": 6.020328381548085,
      "step": 7700,
      "train/forward_time_ms": 2.302408218383789,
      "train/loss": 0.05350597947835922,
      "train/loss_affordance": 0.021875549107789993,
      "train/loss_compute_time_ms": 0.3230571746826172,
      "train/loss_risk": 0.021875549107789993,
      "train/loss_structure": 0.009754881262779236
    },
    {
      "epoch": 6.020328381548085,
      "step": 7700,
      "train/forward_time_ms": 4.261198043823242,
      "train/step_time_ms": 4.261612892150879
    },
    {
      "epoch": 6.059421422986708,
      "grad_norm": 0.36442649364471436,
      "learning_rate": 3.9413604378420645e-05,
      "loss": 0.0515,
      "step": 7750
    },
    {
      "epoch": 6.059421422986708,
      "step": 7750,
      "train/forward_time_ms": 2.3283958435058594,
      "train/loss": 0.06811817735433578,
      "train/loss_affordance": 0.021177377551794052,
      "train/loss_compute_time_ms": 0.27823448181152344,
      "train/loss_risk": 0.021177377551794052,
      "train/loss_structure": 0.02576342225074768
    },
    {
      "epoch": 6.059421422986708,
      "step": 7750,
      "train/forward_time_ms": 4.36915397644043,
      "train/step_time_ms": 4.369635581970215
    },
    {
      "epoch": 6.098514464425333,
      "grad_norm": 0.4079168438911438,
      "learning_rate": 3.902267396403441e-05,
      "loss": 0.0515,
      "step": 7800
    },
    {
      "epoch": 6.098514464425333,
      "step": 7800,
      "train/forward_time_ms": 3.4894943237304688,
      "train/loss": 0.05737307667732239,
      "train/loss_affordance": 0.019895391538739204,
      "train/loss_compute_time_ms": 0.33593177795410156,
      "train/loss_risk": 0.019895391538739204,
      "train/loss_structure": 0.01758229359984398
    },
    {
      "epoch": 6.098514464425333,
      "step": 7800,
      "train/forward_time_ms": 4.324502944946289,
      "train/step_time_ms": 4.324951171875
    },
    {
      "epoch": 6.137607505863956,
      "grad_norm": 0.21909977495670319,
      "learning_rate": 3.8631743549648166e-05,
      "loss": 0.0538,
      "step": 7850
    },
    {
      "epoch": 6.137607505863956,
      "step": 7850,
      "train/forward_time_ms": 2.343416213989258,
      "train/loss": 0.049442291259765625,
      "train/loss_affordance": 0.01825144188478589,
      "train/loss_compute_time_ms": 0.3371238708496094,
      "train/loss_risk": 0.01825144188478589,
      "train/loss_structure": 0.012939407490193844
    },
    {
      "epoch": 6.137607505863956,
      "step": 7850,
      "train/forward_time_ms": 4.396677017211914,
      "train/step_time_ms": 4.397139549255371
    },
    {
      "epoch": 6.1767005473025804,
      "grad_norm": 0.25537124276161194,
      "learning_rate": 3.824081313526193e-05,
      "loss": 0.0483,
      "step": 7900
    },
    {
      "epoch": 6.1767005473025804,
      "step": 7900,
      "train/forward_time_ms": 2.270221710205078,
      "train/loss": 0.05517498403787613,
      "train/loss_affordance": 0.019732641987502575,
      "train/loss_compute_time_ms": 0.44417381286621094,
      "train/loss_risk": 0.019732641987502575,
      "train/loss_structure": 0.01570970006287098
    },
    {
      "epoch": 6.1767005473025804,
      "step": 7900,
      "train/forward_time_ms": 4.239330291748047,
      "train/step_time_ms": 4.239797592163086
    },
    {
      "epoch": 6.215793588741204,
      "grad_norm": 0.20889520645141602,
      "learning_rate": 3.7849882720875686e-05,
      "loss": 0.0532,
      "step": 7950
    },
    {
      "epoch": 6.215793588741204,
      "step": 7950,
      "train/forward_time_ms": 2.399444580078125,
      "train/loss": 0.03858958184719086,
      "train/loss_affordance": 0.014038301073014736,
      "train/loss_compute_time_ms": 0.30112266540527344,
      "train/loss_risk": 0.014038301073014736,
      "train/loss_structure": 0.010512979701161385
    },
    {
      "epoch": 6.215793588741204,
      "step": 7950,
      "train/forward_time_ms": 4.3836259841918945,
      "train/step_time_ms": 4.384098052978516
    },
    {
      "epoch": 6.254886630179828,
      "grad_norm": 0.3228614628314972,
      "learning_rate": 3.745895230648945e-05,
      "loss": 0.0499,
      "step": 8000
    },
    {
      "epoch": 6.254886630179828,
      "step": 8000,
      "train/forward_time_ms": 3.036975860595703,
      "train/loss": 0.046710237860679626,
      "train/loss_affordance": 0.018218782730400562,
      "train/loss_compute_time_ms": 0.3628730773925781,
      "train/loss_risk": 0.018218782730400562,
      "train/loss_structure": 0.010272672399878502
    },
    {
      "epoch": 6.254886630179828,
      "step": 8000,
      "train/forward_time_ms": 4.257211685180664,
      "train/step_time_ms": 4.257645606994629
    },
    {
      "epoch": 6.293979671618452,
      "grad_norm": 0.1283654421567917,
      "learning_rate": 3.706802189210321e-05,
      "loss": 0.049,
      "step": 8050
    },
    {
      "epoch": 6.293979671618452,
      "step": 8050,
      "train/forward_time_ms": 2.6702880859375,
      "train/loss": 0.04954063147306442,
      "train/loss_affordance": 0.017147345934063196,
      "train/loss_compute_time_ms": 0.6024837493896484,
      "train/loss_risk": 0.017147345934063196,
      "train/loss_structure": 0.01524593960493803
    },
    {
      "epoch": 6.293979671618452,
      "step": 8050,
      "train/forward_time_ms": 4.365720748901367,
      "train/step_time_ms": 4.36619758605957
    },
    {
      "epoch": 6.333072713057076,
      "grad_norm": 0.5878350734710693,
      "learning_rate": 3.667709147771697e-05,
      "loss": 0.05,
      "step": 8100
    },
    {
      "epoch": 6.333072713057076,
      "step": 8100,
      "train/forward_time_ms": 2.5374889373779297,
      "train/loss": 0.036640990525484085,
      "train/loss_affordance": 0.012477393262088299,
      "train/loss_compute_time_ms": 0.4715919494628906,
      "train/loss_risk": 0.012477393262088299,
      "train/loss_structure": 0.011686204001307487
    },
    {
      "epoch": 6.333072713057076,
      "step": 8100,
      "train/forward_time_ms": 4.272141456604004,
      "train/step_time_ms": 4.272565841674805
    },
    {
      "epoch": 6.3721657544956996,
      "grad_norm": 0.5488547682762146,
      "learning_rate": 3.6286161063330734e-05,
      "loss": 0.0534,
      "step": 8150
    },
    {
      "epoch": 6.3721657544956996,
      "step": 8150,
      "train/forward_time_ms": 2.3589134216308594,
      "train/loss": 0.06256499886512756,
      "train/loss_affordance": 0.02330626640468836,
      "train/loss_compute_time_ms": 0.40149688720703125,
      "train/loss_risk": 0.02330626640468836,
      "train/loss_structure": 0.015952466055750847
    },
    {
      "epoch": 6.3721657544956996,
      "step": 8150,
      "train/forward_time_ms": 4.2259979248046875,
      "train/step_time_ms": 4.226579666137695
    },
    {
      "epoch": 6.411258795934324,
      "grad_norm": 0.5445882678031921,
      "learning_rate": 3.589523064894449e-05,
      "loss": 0.0521,
      "step": 8200
    },
    {
      "epoch": 6.411258795934324,
      "step": 8200,
      "train/forward_time_ms": 2.1278858184814453,
      "train/loss": 0.06560750305652618,
      "train/loss_affordance": 0.026437532622367144,
      "train/loss_compute_time_ms": 0.2624988555908203,
      "train/loss_risk": 0.026437532622367144,
      "train/loss_structure": 0.012732437811791897
    },
    {
      "epoch": 6.411258795934324,
      "step": 8200,
      "train/forward_time_ms": 4.347438812255859,
      "train/step_time_ms": 4.347867965698242
    },
    {
      "epoch": 6.450351837372947,
      "grad_norm": 0.10374843329191208,
      "learning_rate": 3.5504300234558255e-05,
      "loss": 0.0514,
      "step": 8250
    },
    {
      "epoch": 6.450351837372947,
      "step": 8250,
      "train/forward_time_ms": 2.3810863494873047,
      "train/loss": 0.05527191981673241,
      "train/loss_affordance": 0.018074769526720047,
      "train/loss_compute_time_ms": 0.2951622009277344,
      "train/loss_risk": 0.018074769526720047,
      "train/loss_structure": 0.019122380763292313
    },
    {
      "epoch": 6.450351837372947,
      "step": 8250,
      "train/forward_time_ms": 4.383859634399414,
      "train/step_time_ms": 4.384346008300781
    },
    {
      "epoch": 6.489444878811572,
      "grad_norm": 0.42019250988960266,
      "learning_rate": 3.511336982017201e-05,
      "loss": 0.0498,
      "step": 8300
    },
    {
      "epoch": 6.489444878811572,
      "step": 8300,
      "train/forward_time_ms": 2.359151840209961,
      "train/loss": 0.04427286237478256,
      "train/loss_affordance": 0.016112116165459156,
      "train/loss_compute_time_ms": 0.31280517578125,
      "train/loss_risk": 0.016112116165459156,
      "train/loss_structure": 0.01204863004386425
    },
    {
      "epoch": 6.489444878811572,
      "step": 8300,
      "train/forward_time_ms": 4.493002891540527,
      "train/step_time_ms": 4.4934797286987305
    },
    {
      "epoch": 6.528537920250195,
      "grad_norm": 0.5378060340881348,
      "learning_rate": 3.4722439405785775e-05,
      "loss": 0.0511,
      "step": 8350
    },
    {
      "epoch": 6.528537920250195,
      "step": 8350,
      "train/forward_time_ms": 2.5551319122314453,
      "train/loss": 0.07196270674467087,
      "train/loss_affordance": 0.028831782285124063,
      "train/loss_compute_time_ms": 0.31065940856933594,
      "train/loss_risk": 0.028831782285124063,
      "train/loss_structure": 0.014299142174422741
    },
    {
      "epoch": 6.528537920250195,
      "step": 8350,
      "train/forward_time_ms": 4.278807640075684,
      "train/step_time_ms": 4.279232025146484
    },
    {
      "epoch": 6.5676309616888195,
      "grad_norm": 0.14431263506412506,
      "learning_rate": 3.433150899139953e-05,
      "loss": 0.0515,
      "step": 8400
    },
    {
      "epoch": 6.5676309616888195,
      "step": 8400,
      "train/forward_time_ms": 2.4461746215820312,
      "train/loss": 0.04420708492398262,
      "train/loss_affordance": 0.017582767643034458,
      "train/loss_compute_time_ms": 0.3161430358886719,
      "train/loss_risk": 0.017582767643034458,
      "train/loss_structure": 0.009041549637913704
    },
    {
      "epoch": 6.5676309616888195,
      "step": 8400,
      "train/forward_time_ms": 4.222116470336914,
      "train/step_time_ms": 4.222564697265625
    },
    {
      "epoch": 6.606724003127443,
      "grad_norm": 0.2202538400888443,
      "learning_rate": 3.3940578577013295e-05,
      "loss": 0.0519,
      "step": 8450
    },
    {
      "epoch": 6.606724003127443,
      "step": 8450,
      "train/forward_time_ms": 2.447843551635742,
      "train/loss": 0.058183394372463226,
      "train/loss_affordance": 0.018131842836737633,
      "train/loss_compute_time_ms": 0.29754638671875,
      "train/loss_risk": 0.018131842836737633,
      "train/loss_structure": 0.02191970869898796
    },
    {
      "epoch": 6.606724003127443,
      "step": 8450,
      "train/forward_time_ms": 4.21295166015625,
      "train/step_time_ms": 4.213371276855469
    },
    {
      "epoch": 6.645817044566067,
      "grad_norm": 0.244009330868721,
      "learning_rate": 3.354964816262706e-05,
      "loss": 0.0516,
      "step": 8500
    },
    {
      "epoch": 6.645817044566067,
      "step": 8500,
      "train/forward_time_ms": 2.455472946166992,
      "train/loss": 0.06526488065719604,
      "train/loss_affordance": 0.027047885581851006,
      "train/loss_compute_time_ms": 0.3266334533691406,
      "train/loss_risk": 0.027047885581851006,
      "train/loss_structure": 0.011169109493494034
    },
    {
      "epoch": 6.645817044566067,
      "step": 8500,
      "train/forward_time_ms": 4.300665855407715,
      "train/step_time_ms": 4.3011474609375
    },
    {
      "epoch": 6.684910086004691,
      "grad_norm": 0.625518262386322,
      "learning_rate": 3.3158717748240816e-05,
      "loss": 0.0487,
      "step": 8550
    },
    {
      "epoch": 6.684910086004691,
      "step": 8550,
      "train/forward_time_ms": 2.353191375732422,
      "train/loss": 0.07641351222991943,
      "train/loss_affordance": 0.026952162384986877,
      "train/loss_compute_time_ms": 0.33020973205566406,
      "train/loss_risk": 0.026952162384986877,
      "train/loss_structure": 0.02250918745994568
    },
    {
      "epoch": 6.684910086004691,
      "step": 8550,
      "train/forward_time_ms": 4.4722795486450195,
      "train/step_time_ms": 4.473128318786621
    },
    {
      "epoch": 6.724003127443315,
      "grad_norm": 0.39227890968322754,
      "learning_rate": 3.276778733385458e-05,
      "loss": 0.0526,
      "step": 8600
    },
    {
      "epoch": 6.724003127443315,
      "step": 8600,
      "train/forward_time_ms": 2.061128616333008,
      "train/loss": 0.052849024534225464,
      "train/loss_affordance": 0.018073408864438534,
      "train/loss_compute_time_ms": 0.29349327087402344,
      "train/loss_risk": 0.018073408864438534,
      "train/loss_structure": 0.016702206805348396
    },
    {
      "epoch": 6.724003127443315,
      "step": 8600,
      "train/forward_time_ms": 4.227046966552734,
      "train/step_time_ms": 4.227495193481445
    },
    {
      "epoch": 6.763096168881939,
      "grad_norm": 0.28291574120521545,
      "learning_rate": 3.2376856919468336e-05,
      "loss": 0.0513,
      "step": 8650
    },
    {
      "epoch": 6.763096168881939,
      "step": 8650,
      "train/forward_time_ms": 2.654552459716797,
      "train/loss": 0.04751122370362282,
      "train/loss_affordance": 0.01723759900778532,
      "train/loss_compute_time_ms": 0.3495216369628906,
      "train/loss_risk": 0.01723759900778532,
      "train/loss_structure": 0.013036025688052177
    },
    {
      "epoch": 6.763096168881939,
      "step": 8650,
      "train/forward_time_ms": 4.25358772277832,
      "train/step_time_ms": 4.2543745040893555
    },
    {
      "epoch": 6.802189210320563,
      "grad_norm": 0.28577107191085815,
      "learning_rate": 3.19859265050821e-05,
      "loss": 0.0486,
      "step": 8700
    },
    {
      "epoch": 6.802189210320563,
      "step": 8700,
      "train/forward_time_ms": 2.3288726806640625,
      "train/loss": 0.059613220393657684,
      "train/loss_affordance": 0.02028796076774597,
      "train/loss_compute_time_ms": 0.3039836883544922,
      "train/loss_risk": 0.02028796076774597,
      "train/loss_structure": 0.01903729885816574
    },
    {
      "epoch": 6.802189210320563,
      "step": 8700,
      "train/forward_time_ms": 4.244341850280762,
      "train/step_time_ms": 4.244794845581055
    },
    {
      "epoch": 6.841282251759187,
      "grad_norm": 0.6175938248634338,
      "learning_rate": 3.159499609069586e-05,
      "loss": 0.0501,
      "step": 8750
    },
    {
      "epoch": 6.841282251759187,
      "step": 8750,
      "train/forward_time_ms": 2.763986587524414,
      "train/loss": 0.053467102348804474,
      "train/loss_affordance": 0.021461570635437965,
      "train/loss_compute_time_ms": 0.4277229309082031,
      "train/loss_risk": 0.021461570635437965,
      "train/loss_structure": 0.010543961077928543
    },
    {
      "epoch": 6.841282251759187,
      "step": 8750,
      "train/forward_time_ms": 4.314584732055664,
      "train/step_time_ms": 4.315052032470703
    },
    {
      "epoch": 6.880375293197811,
      "grad_norm": 0.5139991044998169,
      "learning_rate": 3.120406567630962e-05,
      "loss": 0.0542,
      "step": 8800
    },
    {
      "epoch": 6.880375293197811,
      "step": 8800,
      "train/forward_time_ms": 2.4344921112060547,
      "train/loss": 0.08944003283977509,
      "train/loss_affordance": 0.03589952830225229,
      "train/loss_compute_time_ms": 0.33211708068847656,
      "train/loss_risk": 0.03589952830225229,
      "train/loss_structure": 0.0176409762352705
    },
    {
      "epoch": 6.880375293197811,
      "step": 8800,
      "train/forward_time_ms": 4.408745765686035,
      "train/step_time_ms": 4.409213066101074
    },
    {
      "epoch": 6.919468334636434,
      "grad_norm": 0.7016293406486511,
      "learning_rate": 3.0813135261923384e-05,
      "loss": 0.0519,
      "step": 8850
    },
    {
      "epoch": 6.919468334636434,
      "step": 8850,
      "train/forward_time_ms": 2.4919509887695312,
      "train/loss": 0.05368313193321228,
      "train/loss_affordance": 0.01817170437425375,
      "train/loss_compute_time_ms": 0.39958953857421875,
      "train/loss_risk": 0.01817170437425375,
      "train/loss_structure": 0.01733972318470478
    },
    {
      "epoch": 6.919468334636434,
      "step": 8850,
      "train/forward_time_ms": 4.316411018371582,
      "train/step_time_ms": 4.316864013671875
    },
    {
      "epoch": 6.958561376075059,
      "grad_norm": 0.22513623535633087,
      "learning_rate": 3.0422204847537138e-05,
      "loss": 0.0497,
      "step": 8900
    },
    {
      "epoch": 6.958561376075059,
      "step": 8900,
      "train/forward_time_ms": 3.123760223388672,
      "train/loss": 0.06563838571310043,
      "train/loss_affordance": 0.02568229753524065,
      "train/loss_compute_time_ms": 0.3437995910644531,
      "train/loss_risk": 0.02568229753524065,
      "train/loss_structure": 0.014273790642619133
    },
    {
      "epoch": 6.958561376075059,
      "step": 8900,
      "train/forward_time_ms": 4.217252731323242,
      "train/step_time_ms": 4.217715263366699
    },
    {
      "epoch": 6.997654417513683,
      "grad_norm": 0.22824019193649292,
      "learning_rate": 3.00312744331509e-05,
      "loss": 0.0512,
      "step": 8950
    },
    {
      "epoch": 6.997654417513683,
      "step": 8950,
      "train/forward_time_ms": 2.3987293243408203,
      "train/loss": 0.06172776594758034,
      "train/loss_affordance": 0.025165689177811146,
      "train/loss_compute_time_ms": 0.32210350036621094,
      "train/loss_risk": 0.025165689177811146,
      "train/loss_structure": 0.011396387591958046
    },
    {
      "epoch": 6.997654417513683,
      "step": 8950,
      "train/forward_time_ms": 4.369468688964844,
      "train/step_time_ms": 4.369935989379883
    },
    {
      "epoch": 7.0367474589523065,
      "grad_norm": 0.36967700719833374,
      "learning_rate": 2.9640344018764658e-05,
      "loss": 0.0524,
      "step": 9000
    },
    {
      "epoch": 7.0367474589523065,
      "step": 9000,
      "train/forward_time_ms": 2.773761749267578,
      "train/loss": 0.037224993109703064,
      "train/loss_affordance": 0.014058423228561878,
      "train/loss_compute_time_ms": 0.3829002380371094,
      "train/loss_risk": 0.014058423228561878,
      "train/loss_structure": 0.009108146652579308
    },
    {
      "epoch": 7.0367474589523065,
      "step": 9000,
      "train/forward_time_ms": 4.522428512573242,
      "train/step_time_ms": 4.522957801818848
    },
    {
      "epoch": 7.075840500390931,
      "grad_norm": 0.5374194383621216,
      "learning_rate": 2.9249413604378422e-05,
      "loss": 0.0495,
      "step": 9050
    },
    {
      "epoch": 7.075840500390931,
      "step": 9050,
      "train/forward_time_ms": 2.3431777954101562,
      "train/loss": 0.040044452995061874,
      "train/loss_affordance": 0.014357403852045536,
      "train/loss_compute_time_ms": 0.3101825714111328,
      "train/loss_risk": 0.014357403852045536,
      "train/loss_structure": 0.011329645290970802
    },
    {
      "epoch": 7.075840500390931,
      "step": 9050,
      "train/forward_time_ms": 4.296722412109375,
      "train/step_time_ms": 4.29720401763916
    },
    {
      "epoch": 7.114933541829554,
      "grad_norm": 0.39621418714523315,
      "learning_rate": 2.8858483189992182e-05,
      "loss": 0.0479,
      "step": 9100
    },
    {
      "epoch": 7.114933541829554,
      "step": 9100,
      "train/forward_time_ms": 2.3186206817626953,
      "train/loss": 0.05299259349703789,
      "train/loss_affordance": 0.018917374778538942,
      "train/loss_compute_time_ms": 0.3056526184082031,
      "train/loss_risk": 0.018917374778538942,
      "train/loss_structure": 0.015157843939960003
    },
    {
      "epoch": 7.114933541829554,
      "step": 9100,
      "train/forward_time_ms": 4.239869117736816,
      "train/step_time_ms": 4.240331649780273
    },
    {
      "epoch": 7.154026583268179,
      "grad_norm": 0.2398701012134552,
      "learning_rate": 2.8467552775605942e-05,
      "loss": 0.049,
      "step": 9150
    },
    {
      "epoch": 7.154026583268179,
      "step": 9150,
      "train/forward_time_ms": 2.362489700317383,
      "train/loss": 0.049561239778995514,
      "train/loss_affordance": 0.02060639252886176,
      "train/loss_compute_time_ms": 0.30994415283203125,
      "train/loss_risk": 0.02060639252886176,
      "train/loss_structure": 0.008348454721271992
    },
    {
      "epoch": 7.154026583268179,
      "step": 9150,
      "train/forward_time_ms": 4.2212629318237305,
      "train/step_time_ms": 4.221711158752441
    },
    {
      "epoch": 7.193119624706802,
      "grad_norm": 0.24206580221652985,
      "learning_rate": 2.8076622361219706e-05,
      "loss": 0.0486,
      "step": 9200
    },
    {
      "epoch": 7.193119624706802,
      "step": 9200,
      "train/forward_time_ms": 2.2611618041992188,
      "train/loss": 0.028353959321975708,
      "train/loss_affordance": 0.009531288873404264,
      "train/loss_compute_time_ms": 0.2713203430175781,
      "train/loss_risk": 0.009531288873404264,
      "train/loss_structure": 0.009291381575167179
    },
    {
      "epoch": 7.193119624706802,
      "step": 9200,
      "train/forward_time_ms": 4.117326736450195,
      "train/step_time_ms": 4.117860794067383
    },
    {
      "epoch": 7.2322126661454265,
      "grad_norm": 0.15263433754444122,
      "learning_rate": 2.7685691946833463e-05,
      "loss": 0.0494,
      "step": 9250
    },
    {
      "epoch": 7.2322126661454265,
      "step": 9250,
      "train/forward_time_ms": 2.300262451171875,
      "train/loss": 0.045071862637996674,
      "train/loss_affordance": 0.015541000291705132,
      "train/loss_compute_time_ms": 0.3070831298828125,
      "train/loss_risk": 0.015541000291705132,
      "train/loss_structure": 0.01398986205458641
    },
    {
      "epoch": 7.2322126661454265,
      "step": 9250,
      "train/forward_time_ms": 4.452939033508301,
      "train/step_time_ms": 4.453401565551758
    },
    {
      "epoch": 7.27130570758405,
      "grad_norm": 0.12560273706912994,
      "learning_rate": 2.7294761532447226e-05,
      "loss": 0.0469,
      "step": 9300
    },
    {
      "epoch": 7.27130570758405,
      "step": 9300,
      "train/forward_time_ms": 2.188444137573242,
      "train/loss": 0.07100534439086914,
      "train/loss_affordance": 0.02726113051176071,
      "train/loss_compute_time_ms": 0.2675056457519531,
      "train/loss_risk": 0.02726113051176071,
      "train/loss_structure": 0.016483083367347717
    },
    {
      "epoch": 7.27130570758405,
      "step": 9300,
      "train/forward_time_ms": 4.174189567565918,
      "train/step_time_ms": 4.17454719543457
    },
    {
      "epoch": 7.310398749022674,
      "grad_norm": 0.8921745419502258,
      "learning_rate": 2.6903831118060983e-05,
      "loss": 0.0527,
      "step": 9350
    },
    {
      "epoch": 7.310398749022674,
      "step": 9350,
      "train/forward_time_ms": 2.309083938598633,
      "train/loss": 0.050956469029188156,
      "train/loss_affordance": 0.015055883675813675,
      "train/loss_compute_time_ms": 0.42438507080078125,
      "train/loss_risk": 0.015055883675813675,
      "train/loss_structure": 0.020844701677560806
    },
    {
      "epoch": 7.310398749022674,
      "step": 9350,
      "train/forward_time_ms": 4.194340705871582,
      "train/step_time_ms": 4.194812774658203
    },
    {
      "epoch": 7.349491790461298,
      "grad_norm": 0.26469022035598755,
      "learning_rate": 2.6512900703674747e-05,
      "loss": 0.0515,
      "step": 9400
    },
    {
      "epoch": 7.349491790461298,
      "step": 9400,
      "train/forward_time_ms": 2.8753280639648438,
      "train/loss": 0.06336183845996857,
      "train/loss_affordance": 0.025839265901595354,
      "train/loss_compute_time_ms": 0.3266334533691406,
      "train/loss_risk": 0.025839265901595354,
      "train/loss_structure": 0.011683306656777859
    },
    {
      "epoch": 7.349491790461298,
      "step": 9400,
      "train/forward_time_ms": 4.245562553405762,
      "train/step_time_ms": 4.246048927307129
    },
    {
      "epoch": 7.388584831899922,
      "grad_norm": 0.12917564809322357,
      "learning_rate": 2.6121970289288507e-05,
      "loss": 0.0497,
      "step": 9450
    },
    {
      "epoch": 7.388584831899922,
      "step": 9450,
      "train/forward_time_ms": 2.8400421142578125,
      "train/loss": 0.07395249605178833,
      "train/loss_affordance": 0.026099483482539654,
      "train/loss_compute_time_ms": 0.36978721618652344,
      "train/loss_risk": 0.026099483482539654,
      "train/loss_structure": 0.021753529086709023
    },
    {
      "epoch": 7.388584831899922,
      "step": 9450,
      "train/forward_time_ms": 4.323339462280273,
      "train/step_time_ms": 4.323792457580566
    },
    {
      "epoch": 7.427677873338546,
      "grad_norm": 0.494577556848526,
      "learning_rate": 2.5731039874902267e-05,
      "loss": 0.0489,
      "step": 9500
    },
    {
      "epoch": 7.427677873338546,
      "step": 9500,
      "train/forward_time_ms": 3.2002925872802734,
      "train/loss": 0.042520079761743546,
      "train/loss_affordance": 0.013480726163834333,
      "train/loss_compute_time_ms": 0.3631114959716797,
      "train/loss_risk": 0.013480726163834333,
      "train/loss_structure": 0.015558627434074879
    },
    {
      "epoch": 7.427677873338546,
      "step": 9500,
      "train/forward_time_ms": 4.418959617614746,
      "train/step_time_ms": 4.419450759887695
    },
    {
      "epoch": 7.46677091477717,
      "grad_norm": 0.1412617415189743,
      "learning_rate": 2.534010946051603e-05,
      "loss": 0.0507,
      "step": 9550
    },
    {
      "epoch": 7.46677091477717,
      "step": 9550,
      "train/forward_time_ms": 2.1915435791015625,
      "train/loss": 0.07391885668039322,
      "train/loss_affordance": 0.02324427105486393,
      "train/loss_compute_time_ms": 0.26488304138183594,
      "train/loss_risk": 0.02324427105486393,
      "train/loss_structure": 0.02743031457066536
    },
    {
      "epoch": 7.46677091477717,
      "step": 9550,
      "train/forward_time_ms": 4.345908164978027,
      "train/step_time_ms": 4.346408843994141
    },
    {
      "epoch": 7.505863956215793,
      "grad_norm": 0.26974815130233765,
      "learning_rate": 2.4949179046129788e-05,
      "loss": 0.0501,
      "step": 9600
    },
    {
      "epoch": 7.505863956215793,
      "step": 9600,
      "train/forward_time_ms": 2.538442611694336,
      "train/loss": 0.04615718126296997,
      "train/loss_affordance": 0.018573996145278215,
      "train/loss_compute_time_ms": 0.3218650817871094,
      "train/loss_risk": 0.018573996145278215,
      "train/loss_structure": 0.00900918897241354
    },
    {
      "epoch": 7.505863956215793,
      "step": 9600,
      "train/forward_time_ms": 4.231905937194824,
      "train/step_time_ms": 4.232325553894043
    },
    {
      "epoch": 7.544956997654418,
      "grad_norm": 0.623231828212738,
      "learning_rate": 2.4558248631743548e-05,
      "loss": 0.0499,
      "step": 9650
    },
    {
      "epoch": 7.544956997654418,
      "step": 9650,
      "train/forward_time_ms": 2.4657249450683594,
      "train/loss": 0.04989725351333618,
      "train/loss_affordance": 0.01885021384805441,
      "train/loss_compute_time_ms": 0.2968311309814453,
      "train/loss_risk": 0.01885021384805441,
      "train/loss_structure": 0.012196825817227364
    },
    {
      "epoch": 7.544956997654418,
      "step": 9650,
      "train/forward_time_ms": 4.170737266540527,
      "train/step_time_ms": 4.171199798583984
    },
    {
      "epoch": 7.584050039093041,
      "grad_norm": 0.1849460005760193,
      "learning_rate": 2.4167318217357312e-05,
      "loss": 0.0502,
      "step": 9700
    },
    {
      "epoch": 7.584050039093041,
      "step": 9700,
      "train/forward_time_ms": 3.072023391723633,
      "train/loss": 0.06557580828666687,
      "train/loss_affordance": 0.020908208563923836,
      "train/loss_compute_time_ms": 0.3497600555419922,
      "train/loss_risk": 0.020908208563923836,
      "train/loss_structure": 0.0237593911588192
    },
    {
      "epoch": 7.584050039093041,
      "step": 9700,
      "train/forward_time_ms": 4.302620887756348,
      "train/step_time_ms": 4.303097724914551
    },
    {
      "epoch": 7.623143080531666,
      "grad_norm": 0.3753573000431061,
      "learning_rate": 2.3776387802971072e-05,
      "loss": 0.0542,
      "step": 9750
    },
    {
      "epoch": 7.623143080531666,
      "step": 9750,
      "train/forward_time_ms": 2.1255016326904297,
      "train/loss": 0.04809843748807907,
      "train/loss_affordance": 0.017124075908213854,
      "train/loss_compute_time_ms": 0.28204917907714844,
      "train/loss_risk": 0.017124075908213854,
      "train/loss_structure": 0.013850285671651363
    },
    {
      "epoch": 7.623143080531666,
      "step": 9750,
      "train/forward_time_ms": 4.332723617553711,
      "train/step_time_ms": 4.333257675170898
    },
    {
      "epoch": 7.662236121970289,
      "grad_norm": 0.2577238380908966,
      "learning_rate": 2.3385457388584832e-05,
      "loss": 0.0485,
      "step": 9800
    },
    {
      "epoch": 7.662236121970289,
      "step": 9800,
      "train/forward_time_ms": 2.1796226501464844,
      "train/loss": 0.044005490839481354,
      "train/loss_affordance": 0.017293622717261314,
      "train/loss_compute_time_ms": 0.2980232238769531,
      "train/loss_risk": 0.017293622717261314,
      "train/loss_structure": 0.009418245404958725
    },
    {
      "epoch": 7.662236121970289,
      "step": 9800,
      "train/forward_time_ms": 4.254412651062012,
      "train/step_time_ms": 4.254879951477051
    },
    {
      "epoch": 7.701329163408913,
      "grad_norm": 0.2254759520292282,
      "learning_rate": 2.2994526974198592e-05,
      "loss": 0.0526,
      "step": 9850
    },
    {
      "epoch": 7.701329163408913,
      "step": 9850,
      "train/forward_time_ms": 2.833127975463867,
      "train/loss": 0.04739890620112419,
      "train/loss_affordance": 0.018703102134168148,
      "train/loss_compute_time_ms": 0.32591819763183594,
      "train/loss_risk": 0.018703102134168148,
      "train/loss_structure": 0.009992701932787895
    },
    {
      "epoch": 7.701329163408913,
      "step": 9850,
      "train/forward_time_ms": 4.269614219665527,
      "train/step_time_ms": 4.270071983337402
    },
    {
      "epoch": 7.740422204847537,
      "grad_norm": 0.19469895958900452,
      "learning_rate": 2.2603596559812353e-05,
      "loss": 0.0498,
      "step": 9900
    },
    {
      "epoch": 7.740422204847537,
      "step": 9900,
      "train/forward_time_ms": 2.2530555725097656,
      "train/loss": 0.049414098262786865,
      "train/loss_affordance": 0.017155890353024006,
      "train/loss_compute_time_ms": 0.32329559326171875,
      "train/loss_risk": 0.017155890353024006,
      "train/loss_structure": 0.015102317556738853
    },
    {
      "epoch": 7.740422204847537,
      "step": 9900,
      "train/forward_time_ms": 4.276952743530273,
      "train/step_time_ms": 4.277429580688477
    },
    {
      "epoch": 7.779515246286161,
      "grad_norm": 0.26529207825660706,
      "learning_rate": 2.2212666145426113e-05,
      "loss": 0.0479,
      "step": 9950
    },
    {
      "epoch": 7.779515246286161,
      "step": 9950,
      "train/forward_time_ms": 2.233743667602539,
      "train/loss": 0.04701054468750954,
      "train/loss_affordance": 0.01681192358955741,
      "train/loss_compute_time_ms": 0.2818107604980469,
      "train/loss_risk": 0.01681192358955741,
      "train/loss_structure": 0.013386697508394718
    },
    {
      "epoch": 7.779515246286161,
      "step": 9950,
      "train/forward_time_ms": 4.386229515075684,
      "train/step_time_ms": 4.3866682052612305
    },
    {
      "epoch": 7.818608287724785,
      "grad_norm": 0.17290814220905304,
      "learning_rate": 2.1821735731039873e-05,
      "loss": 0.0512,
      "step": 10000
    },
    {
      "epoch": 7.818608287724785,
      "step": 10000,
      "train/forward_time_ms": 2.7077198028564453,
      "train/loss": 0.05514271557331085,
      "train/loss_affordance": 0.024925266858190298,
      "train/loss_compute_time_ms": 0.3552436828613281,
      "train/loss_risk": 0.024925266858190298,
      "train/loss_structure": 0.005292181856930256
    },
    {
      "epoch": 7.818608287724785,
      "step": 10000,
      "train/forward_time_ms": 4.165077209472656,
      "train/step_time_ms": 4.165530204772949
    },
    {
      "epoch": 7.857701329163409,
      "grad_norm": 0.27276846766471863,
      "learning_rate": 2.1430805316653637e-05,
      "loss": 0.0506,
      "step": 10050
    },
    {
      "epoch": 7.857701329163409,
      "step": 10050,
      "train/forward_time_ms": 2.337217330932617,
      "train/loss": 0.05383145064115524,
      "train/loss_affordance": 0.021619465202093124,
      "train/loss_compute_time_ms": 0.3485679626464844,
      "train/loss_risk": 0.021619465202093124,
      "train/loss_structure": 0.010592520236968994
    },
    {
      "epoch": 7.857701329163409,
      "step": 10050,
      "train/forward_time_ms": 4.313807487487793,
      "train/step_time_ms": 4.314360618591309
    },
    {
      "epoch": 7.8967943706020325,
      "grad_norm": 0.2081473469734192,
      "learning_rate": 2.1039874902267397e-05,
      "loss": 0.0491,
      "step": 10100
    },
    {
      "epoch": 7.8967943706020325,
      "step": 10100,
      "train/forward_time_ms": 2.2788047790527344,
      "train/loss": 0.04872524365782738,
      "train/loss_affordance": 0.01830805465579033,
      "train/loss_compute_time_ms": 0.29754638671875,
      "train/loss_risk": 0.01830805465579033,
      "train/loss_structure": 0.01210913434624672
    },
    {
      "epoch": 7.8967943706020325,
      "step": 10100,
      "train/forward_time_ms": 4.295201301574707,
      "train/step_time_ms": 4.295687675476074
    },
    {
      "epoch": 7.935887412040657,
      "grad_norm": 0.3819335103034973,
      "learning_rate": 2.0648944487881157e-05,
      "loss": 0.0493,
      "step": 10150
    },
    {
      "epoch": 7.935887412040657,
      "step": 10150,
      "train/forward_time_ms": 2.222776412963867,
      "train/loss": 0.06604903936386108,
      "train/loss_affordance": 0.018604937940835953,
      "train/loss_compute_time_ms": 0.3056526184082031,
      "train/loss_risk": 0.018604937940835953,
      "train/loss_structure": 0.02883916348218918
    },
    {
      "epoch": 7.935887412040657,
      "step": 10150,
      "train/forward_time_ms": 4.272298812866211,
      "train/step_time_ms": 4.272732734680176
    },
    {
      "epoch": 7.97498045347928,
      "grad_norm": 0.7005886435508728,
      "learning_rate": 2.0258014073494918e-05,
      "loss": 0.048,
      "step": 10200
    },
    {
      "epoch": 7.97498045347928,
      "step": 10200,
      "train/forward_time_ms": 2.213001251220703,
      "train/loss": 0.0601380318403244,
      "train/loss_affordance": 0.022681349888443947,
      "train/loss_compute_time_ms": 0.2841949462890625,
      "train/loss_risk": 0.022681349888443947,
      "train/loss_structure": 0.014775332063436508
    },
    {
      "epoch": 7.97498045347928,
      "step": 10200,
      "train/forward_time_ms": 4.536895751953125,
      "train/step_time_ms": 4.53740119934082
    },
    {
      "epoch": 8.014073494917904,
      "grad_norm": 0.4257211983203888,
      "learning_rate": 1.9867083659108678e-05,
      "loss": 0.0495,
      "step": 10250
    },
    {
      "epoch": 8.014073494917904,
      "step": 10250,
      "train/forward_time_ms": 2.467632293701172,
      "train/loss": 0.05672745406627655,
      "train/loss_affordance": 0.021377782337367535,
      "train/loss_compute_time_ms": 0.3886222839355469,
      "train/loss_risk": 0.021377782337367535,
      "train/loss_structure": 0.013971889391541481
    },
    {
      "epoch": 8.014073494917904,
      "step": 10250,
      "train/forward_time_ms": 4.347596168518066,
      "train/step_time_ms": 4.34816837310791
    },
    {
      "epoch": 8.053166536356528,
      "grad_norm": 0.47647497057914734,
      "learning_rate": 1.9476153244722438e-05,
      "loss": 0.0475,
      "step": 10300
    },
    {
      "epoch": 8.053166536356528,
      "step": 10300,
      "train/forward_time_ms": 2.8657913208007812,
      "train/loss": 0.04611379653215408,
      "train/loss_affordance": 0.014748770743608475,
      "train/loss_compute_time_ms": 0.43201446533203125,
      "train/loss_risk": 0.014748770743608475,
      "train/loss_structure": 0.016616255044937134
    },
    {
      "epoch": 8.053166536356528,
      "step": 10300,
      "train/forward_time_ms": 4.29898738861084,
      "train/step_time_ms": 4.299416542053223
    },
    {
      "epoch": 8.092259577795152,
      "grad_norm": 0.33544349670410156,
      "learning_rate": 1.90852228303362e-05,
      "loss": 0.0476,
      "step": 10350
    },
    {
      "epoch": 8.092259577795152,
      "step": 10350,
      "train/forward_time_ms": 2.4602413177490234,
      "train/loss": 0.03095049224793911,
      "train/loss_affordance": 0.009750408120453358,
      "train/loss_compute_time_ms": 0.26988983154296875,
      "train/loss_risk": 0.009750408120453358,
      "train/loss_structure": 0.011449676007032394
    },
    {
      "epoch": 8.092259577795152,
      "step": 10350,
      "train/forward_time_ms": 4.168543815612793,
      "train/step_time_ms": 4.168963432312012
    },
    {
      "epoch": 8.131352619233777,
      "grad_norm": 0.193630188703537,
      "learning_rate": 1.8694292415949962e-05,
      "loss": 0.0529,
      "step": 10400
    },
    {
      "epoch": 8.131352619233777,
      "step": 10400,
      "train/forward_time_ms": 2.5691986083984375,
      "train/loss": 0.055618565529584885,
      "train/loss_affordance": 0.023107159417122602,
      "train/loss_compute_time_ms": 0.33783912658691406,
      "train/loss_risk": 0.023107159417122602,
      "train/loss_structure": 0.00940424669533968
    },
    {
      "epoch": 8.131352619233777,
      "step": 10400,
      "train/forward_time_ms": 4.312424659729004,
      "train/step_time_ms": 4.312872886657715
    },
    {
      "epoch": 8.1704456606724,
      "grad_norm": 0.15835444629192352,
      "learning_rate": 1.8303362001563722e-05,
      "loss": 0.0487,
      "step": 10450
    },
    {
      "epoch": 8.1704456606724,
      "step": 10450,
      "train/forward_time_ms": 2.382516860961914,
      "train/loss": 0.05497628450393677,
      "train/loss_affordance": 0.021353913005441427,
      "train/loss_compute_time_ms": 0.30684471130371094,
      "train/loss_risk": 0.021353913005441427,
      "train/loss_structure": 0.012268458493053913
    },
    {
      "epoch": 8.1704456606724,
      "step": 10450,
      "train/forward_time_ms": 4.510321617126465,
      "train/step_time_ms": 4.510774612426758
    },
    {
      "epoch": 8.209538702111024,
      "grad_norm": 0.33369627594947815,
      "learning_rate": 1.7912431587177482e-05,
      "loss": 0.0489,
      "step": 10500
    },
    {
      "epoch": 8.209538702111024,
      "step": 10500,
      "train/forward_time_ms": 2.727508544921875,
      "train/loss": 0.06517685949802399,
      "train/loss_affordance": 0.024290287867188454,
      "train/loss_compute_time_ms": 0.40721893310546875,
      "train/loss_risk": 0.024290287867188454,
      "train/loss_structure": 0.01659628376364708
    },
    {
      "epoch": 8.209538702111024,
      "step": 10500,
      "train/forward_time_ms": 4.3373870849609375,
      "train/step_time_ms": 4.337863922119141
    },
    {
      "epoch": 8.248631743549648,
      "grad_norm": 0.27404099702835083,
      "learning_rate": 1.7521501172791243e-05,
      "loss": 0.0491,
      "step": 10550
    },
    {
      "epoch": 8.248631743549648,
      "step": 10550,
      "train/forward_time_ms": 2.66265869140625,
      "train/loss": 0.10917269438505173,
      "train/loss_affordance": 0.03592240251600742,
      "train/loss_compute_time_ms": 0.324249267578125,
      "train/loss_risk": 0.03592240251600742,
      "train/loss_structure": 0.03732788935303688
    },
    {
      "epoch": 8.248631743549648,
      "step": 10550,
      "train/forward_time_ms": 4.295654296875,
      "train/step_time_ms": 4.296107292175293
    },
    {
      "epoch": 8.287724784988272,
      "grad_norm": 0.5919036865234375,
      "learning_rate": 1.7130570758405003e-05,
      "loss": 0.0517,
      "step": 10600
    },
    {
      "epoch": 8.287724784988272,
      "step": 10600,
      "train/forward_time_ms": 2.377033233642578,
      "train/loss": 0.03848332166671753,
      "train/loss_affordance": 0.01513691432774067,
      "train/loss_compute_time_ms": 0.2999305725097656,
      "train/loss_risk": 0.01513691432774067,
      "train/loss_structure": 0.00820949301123619
    },
    {
      "epoch": 8.287724784988272,
      "step": 10600,
      "train/forward_time_ms": 4.1951704025268555,
      "train/step_time_ms": 4.195594787597656
    },
    {
      "epoch": 8.326817826426897,
      "grad_norm": 0.36390045285224915,
      "learning_rate": 1.6739640344018763e-05,
      "loss": 0.0482,
      "step": 10650
    },
    {
      "epoch": 8.326817826426897,
      "step": 10650,
      "train/forward_time_ms": 2.5310516357421875,
      "train/loss": 0.03472278267145157,
      "train/loss_affordance": 0.011190292425453663,
      "train/loss_compute_time_ms": 0.5102157592773438,
      "train/loss_risk": 0.011190292425453663,
      "train/loss_structure": 0.012342197820544243
    },
    {
      "epoch": 8.326817826426897,
      "step": 10650,
      "train/forward_time_ms": 4.368863105773926,
      "train/step_time_ms": 4.369354248046875
    },
    {
      "epoch": 8.36591086786552,
      "grad_norm": 0.5534533858299255,
      "learning_rate": 1.6348709929632527e-05,
      "loss": 0.0506,
      "step": 10700
    },
    {
      "epoch": 8.36591086786552,
      "step": 10700,
      "train/forward_time_ms": 2.4280548095703125,
      "train/loss": 0.037140853703022,
      "train/loss_affordance": 0.01578990719281137,
      "train/loss_compute_time_ms": 0.29754638671875,
      "train/loss_risk": 0.01578990719281137,
      "train/loss_structure": 0.005561039317399263
    },
    {
      "epoch": 8.36591086786552,
      "step": 10700,
      "train/forward_time_ms": 4.394130706787109,
      "train/step_time_ms": 4.3946027755737305
    },
    {
      "epoch": 8.405003909304144,
      "grad_norm": 0.09719409048557281,
      "learning_rate": 1.5957779515246287e-05,
      "loss": 0.0477,
      "step": 10750
    },
    {
      "epoch": 8.405003909304144,
      "step": 10750,
      "train/forward_time_ms": 2.0723342895507812,
      "train/loss": 0.04462532699108124,
      "train/loss_affordance": 0.016651352867484093,
      "train/loss_compute_time_ms": 0.3173351287841797,
      "train/loss_risk": 0.016651352867484093,
      "train/loss_structure": 0.011322621256113052
    },
    {
      "epoch": 8.405003909304144,
      "step": 10750,
      "train/forward_time_ms": 4.257969856262207,
      "train/step_time_ms": 4.258394241333008
    },
    {
      "epoch": 8.444096950742768,
      "grad_norm": 0.45730122923851013,
      "learning_rate": 1.5566849100860047e-05,
      "loss": 0.0494,
      "step": 10800
    },
    {
      "epoch": 8.444096950742768,
      "step": 10800,
      "train/forward_time_ms": 2.468585968017578,
      "train/loss": 0.04785018414258957,
      "train/loss_affordance": 0.011792240664362907,
      "train/loss_compute_time_ms": 0.36263465881347656,
      "train/loss_risk": 0.011792240664362907,
      "train/loss_structure": 0.024265702813863754
    },
    {
      "epoch": 8.444096950742768,
      "step": 10800,
      "train/forward_time_ms": 4.391007423400879,
      "train/step_time_ms": 4.391489028930664
    },
    {
      "epoch": 8.483189992181392,
      "grad_norm": 0.18353883922100067,
      "learning_rate": 1.5175918686473809e-05,
      "loss": 0.0457,
      "step": 10850
    },
    {
      "epoch": 8.483189992181392,
      "step": 10850,
      "train/forward_time_ms": 2.5620460510253906,
      "train/loss": 0.05203607305884361,
      "train/loss_affordance": 0.018619350157678127,
      "train/loss_compute_time_ms": 0.30159950256347656,
      "train/loss_risk": 0.018619350157678127,
      "train/loss_structure": 0.014797372743487358
    },
    {
      "epoch": 8.483189992181392,
      "step": 10850,
      "train/forward_time_ms": 4.389071464538574,
      "train/step_time_ms": 4.389533996582031
    },
    {
      "epoch": 8.522283033620015,
      "grad_norm": 0.4533834159374237,
      "learning_rate": 1.478498827208757e-05,
      "loss": 0.0485,
      "step": 10900
    },
    {
      "epoch": 8.522283033620015,
      "step": 10900,
      "train/forward_time_ms": 2.6831626892089844,
      "train/loss": 0.04183698445558548,
      "train/loss_affordance": 0.016045412980020046,
      "train/loss_compute_time_ms": 0.31185150146484375,
      "train/loss_risk": 0.016045412980020046,
      "train/loss_structure": 0.009746158495545387
    },
    {
      "epoch": 8.522283033620015,
      "step": 10900,
      "train/forward_time_ms": 4.5272016525268555,
      "train/step_time_ms": 4.527688026428223
    },
    {
      "epoch": 8.56137607505864,
      "grad_norm": 0.6453115344047546,
      "learning_rate": 1.439405785770133e-05,
      "loss": 0.0502,
      "step": 10950
    },
    {
      "epoch": 8.56137607505864,
      "step": 10950,
      "train/forward_time_ms": 2.644777297973633,
      "train/loss": 0.0672401413321495,
      "train/loss_affordance": 0.02507863938808441,
      "train/loss_compute_time_ms": 0.3097057342529297,
      "train/loss_risk": 0.02507863938808441,
      "train/loss_structure": 0.017082862555980682
    },
    {
      "epoch": 8.56137607505864,
      "step": 10950,
      "train/forward_time_ms": 4.234790802001953,
      "train/step_time_ms": 4.23520565032959
    },
    {
      "epoch": 8.600469116497264,
      "grad_norm": 0.4888917803764343,
      "learning_rate": 1.400312744331509e-05,
      "loss": 0.0491,
      "step": 11000
    },
    {
      "epoch": 8.600469116497264,
      "step": 11000,
      "train/forward_time_ms": 3.0715465545654297,
      "train/loss": 0.0395054817199707,
      "train/loss_affordance": 0.012792475521564484,
      "train/loss_compute_time_ms": 0.4279613494873047,
      "train/loss_risk": 0.012792475521564484,
      "train/loss_structure": 0.013920530676841736
    },
    {
      "epoch": 8.600469116497264,
      "step": 11000,
      "train/forward_time_ms": 4.391741752624512,
      "train/step_time_ms": 4.392204284667969
    },
    {
      "epoch": 8.639562157935888,
      "grad_norm": 0.4001765847206116,
      "learning_rate": 1.3612197028928852e-05,
      "loss": 0.0507,
      "step": 11050
    },
    {
      "epoch": 8.639562157935888,
      "step": 11050,
      "train/forward_time_ms": 2.240419387817383,
      "train/loss": 0.036069318652153015,
      "train/loss_affordance": 0.014711821917444468,
      "train/loss_compute_time_ms": 0.30422210693359375,
      "train/loss_risk": 0.014711821917444468,
      "train/loss_structure": 0.00664567481726408
    },
    {
      "epoch": 8.639562157935888,
      "step": 11050,
      "train/forward_time_ms": 4.228515625,
      "train/step_time_ms": 4.228949546813965
    },
    {
      "epoch": 8.67865519937451,
      "grad_norm": 0.3115992844104767,
      "learning_rate": 1.3221266614542612e-05,
      "loss": 0.0472,
      "step": 11100
    },
    {
      "epoch": 8.67865519937451,
      "step": 11100,
      "train/forward_time_ms": 2.543926239013672,
      "train/loss": 0.041843753308057785,
      "train/loss_affordance": 0.015043001156300306,
      "train/loss_compute_time_ms": 0.26297569274902344,
      "train/loss_risk": 0.015043001156300306,
      "train/loss_structure": 0.011757750995457172
    },
    {
      "epoch": 8.67865519937451,
      "step": 11100,
      "train/forward_time_ms": 4.292130470275879,
      "train/step_time_ms": 4.292616844177246
    },
    {
      "epoch": 8.717748240813135,
      "grad_norm": 0.17913447320461273,
      "learning_rate": 1.2830336200156374e-05,
      "loss": 0.0479,
      "step": 11150
    },
    {
      "epoch": 8.717748240813135,
      "step": 11150,
      "train/forward_time_ms": 2.379179000854492,
      "train/loss": 0.04087681323289871,
      "train/loss_affordance": 0.014881930314004421,
      "train/loss_compute_time_ms": 0.3020763397216797,
      "train/loss_risk": 0.014881930314004421,
      "train/loss_structure": 0.01111295260488987
    },
    {
      "epoch": 8.717748240813135,
      "step": 11150,
      "train/forward_time_ms": 4.4168853759765625,
      "train/step_time_ms": 4.417319297790527
    },
    {
      "epoch": 8.75684128225176,
      "grad_norm": 0.30698859691619873,
      "learning_rate": 1.2439405785770134e-05,
      "loss": 0.0491,
      "step": 11200
    },
    {
      "epoch": 8.75684128225176,
      "step": 11200,
      "train/forward_time_ms": 2.376556396484375,
      "train/loss": 0.07056616246700287,
      "train/loss_affordance": 0.026593880727887154,
      "train/loss_compute_time_ms": 0.2987384796142578,
      "train/loss_risk": 0.026593880727887154,
      "train/loss_structure": 0.01737840101122856
    },
    {
      "epoch": 8.75684128225176,
      "step": 11200,
      "train/forward_time_ms": 4.259662628173828,
      "train/step_time_ms": 4.260106086730957
    },
    {
      "epoch": 8.795934323690384,
      "grad_norm": 0.5996144413948059,
      "learning_rate": 1.2048475371383894e-05,
      "loss": 0.0486,
      "step": 11250
    },
    {
      "epoch": 8.795934323690384,
      "step": 11250,
      "train/forward_time_ms": 2.9327869415283203,
      "train/loss": 0.04850387200713158,
      "train/loss_affordance": 0.01971624046564102,
      "train/loss_compute_time_ms": 0.3027915954589844,
      "train/loss_risk": 0.01971624046564102,
      "train/loss_structure": 0.009071391075849533
    },
    {
      "epoch": 8.795934323690384,
      "step": 11250,
      "train/forward_time_ms": 4.243912696838379,
      "train/step_time_ms": 4.244470596313477
    },
    {
      "epoch": 8.835027365129006,
      "grad_norm": 0.1091015487909317,
      "learning_rate": 1.1657544956997656e-05,
      "loss": 0.0493,
      "step": 11300
    },
    {
      "epoch": 8.835027365129006,
      "step": 11300,
      "train/forward_time_ms": 2.415180206298828,
      "train/loss": 0.04797852784395218,
      "train/loss_affordance": 0.016018647700548172,
      "train/loss_compute_time_ms": 0.34618377685546875,
      "train/loss_risk": 0.016018647700548172,
      "train/loss_structure": 0.015941232442855835
    },
    {
      "epoch": 8.835027365129006,
      "step": 11300,
      "train/forward_time_ms": 4.31370735168457,
      "train/step_time_ms": 4.314160346984863
    },
    {
      "epoch": 8.87412040656763,
      "grad_norm": 0.7067177295684814,
      "learning_rate": 1.1266614542611417e-05,
      "loss": 0.0523,
      "step": 11350
    },
    {
      "epoch": 8.87412040656763,
      "step": 11350,
      "train/forward_time_ms": 3.313302993774414,
      "train/loss": 0.051072459667921066,
      "train/loss_affordance": 0.01994470600038767,
      "train/loss_compute_time_ms": 0.46133995056152344,
      "train/loss_risk": 0.01994470600038767,
      "train/loss_structure": 0.011183047667145729
    },
    {
      "epoch": 8.87412040656763,
      "step": 11350,
      "train/forward_time_ms": 4.344344139099121,
      "train/step_time_ms": 4.34481143951416
    },
    {
      "epoch": 8.913213448006255,
      "grad_norm": 0.25519803166389465,
      "learning_rate": 1.0875684128225177e-05,
      "loss": 0.0496,
      "step": 11400
    },
    {
      "epoch": 8.913213448006255,
      "step": 11400,
      "train/forward_time_ms": 2.496004104614258,
      "train/loss": 0.07603063434362411,
      "train/loss_affordance": 0.032977054826915264,
      "train/loss_compute_time_ms": 0.27823448181152344,
      "train/loss_risk": 0.032977054826915264,
      "train/loss_structure": 0.010076524689793587
    },
    {
      "epoch": 8.913213448006255,
      "step": 11400,
      "train/forward_time_ms": 4.3076276779174805,
      "train/step_time_ms": 4.308071136474609
    },
    {
      "epoch": 8.95230648944488,
      "grad_norm": 0.46088510751724243,
      "learning_rate": 1.0484753713838937e-05,
      "loss": 0.0479,
      "step": 11450
    },
    {
      "epoch": 8.95230648944488,
      "step": 11450,
      "train/forward_time_ms": 2.2962093353271484,
      "train/loss": 0.04539579898118973,
      "train/loss_affordance": 0.015055529773235321,
      "train/loss_compute_time_ms": 0.29540061950683594,
      "train/loss_risk": 0.015055529773235321,
      "train/loss_structure": 0.015284739434719086
    },
    {
      "epoch": 8.95230648944488,
      "step": 11450,
      "train/forward_time_ms": 4.22971248626709,
      "train/step_time_ms": 4.230108261108398
    },
    {
      "epoch": 8.991399530883502,
      "grad_norm": 0.2552764117717743,
      "learning_rate": 1.0093823299452699e-05,
      "loss": 0.049,
      "step": 11500
    },
    {
      "epoch": 8.991399530883502,
      "step": 11500,
      "train/forward_time_ms": 2.5796890258789062,
      "train/loss": 0.036971837282180786,
      "train/loss_affordance": 0.014966159127652645,
      "train/loss_compute_time_ms": 0.3685951232910156,
      "train/loss_risk": 0.014966159127652645,
      "train/loss_structure": 0.007039519026875496
    },
    {
      "epoch": 8.991399530883502,
      "step": 11500,
      "train/forward_time_ms": 4.326725006103516,
      "train/step_time_ms": 4.3271636962890625
    },
    {
      "epoch": 9.030492572322126,
      "grad_norm": 0.20765303075313568,
      "learning_rate": 9.70289288506646e-06,
      "loss": 0.0506,
      "step": 11550
    },
    {
      "epoch": 9.030492572322126,
      "step": 11550,
      "train/forward_time_ms": 2.482175827026367,
      "train/loss": 0.04183652251958847,
      "train/loss_affordance": 0.011349847540259361,
      "train/loss_compute_time_ms": 0.31447410583496094,
      "train/loss_risk": 0.011349847540259361,
      "train/loss_structure": 0.019136827439069748
    },
    {
      "epoch": 9.030492572322126,
      "step": 11550,
      "train/forward_time_ms": 4.366693496704102,
      "train/step_time_ms": 4.367160797119141
    },
    {
      "epoch": 9.06958561376075,
      "grad_norm": 0.4383784830570221,
      "learning_rate": 9.31196247068022e-06,
      "loss": 0.0484,
      "step": 11600
    },
    {
      "epoch": 9.06958561376075,
      "step": 11600,
      "train/forward_time_ms": 2.2792816162109375,
      "train/loss": 0.0391899049282074,
      "train/loss_affordance": 0.013175664469599724,
      "train/loss_compute_time_ms": 0.3027915954589844,
      "train/loss_risk": 0.013175664469599724,
      "train/loss_structure": 0.01283857598900795
    },
    {
      "epoch": 9.06958561376075,
      "step": 11600,
      "train/forward_time_ms": 4.460864067077637,
      "train/step_time_ms": 4.4612836837768555
    },
    {
      "epoch": 9.108678655199375,
      "grad_norm": 0.4315052032470703,
      "learning_rate": 8.92103205629398e-06,
      "loss": 0.0472,
      "step": 11650
    },
    {
      "epoch": 9.108678655199375,
      "step": 11650,
      "train/forward_time_ms": 2.2666454315185547,
      "train/loss": 0.054682716727256775,
      "train/loss_affordance": 0.018062647432088852,
      "train/loss_compute_time_ms": 0.3635883331298828,
      "train/loss_risk": 0.018062647432088852,
      "train/loss_structure": 0.01855742186307907
    },
    {
      "epoch": 9.108678655199375,
      "step": 11650,
      "train/forward_time_ms": 4.41866397857666,
      "train/step_time_ms": 4.419140815734863
    },
    {
      "epoch": 9.147771696637998,
      "grad_norm": 0.42224258184432983,
      "learning_rate": 8.530101641907742e-06,
      "loss": 0.0487,
      "step": 11700
    },
    {
      "epoch": 9.147771696637998,
      "step": 11700,
      "train/forward_time_ms": 2.4156570434570312,
      "train/loss": 0.05223453789949417,
      "train/loss_affordance": 0.019551023840904236,
      "train/loss_compute_time_ms": 0.2956390380859375,
      "train/loss_risk": 0.019551023840904236,
      "train/loss_structure": 0.0131324902176857
    },
    {
      "epoch": 9.147771696637998,
      "step": 11700,
      "train/forward_time_ms": 4.2969560623168945,
      "train/step_time_ms": 4.297499656677246
    },
    {
      "epoch": 9.186864738076622,
      "grad_norm": 0.16306549310684204,
      "learning_rate": 8.139171227521502e-06,
      "loss": 0.0481,
      "step": 11750
    },
    {
      "epoch": 9.186864738076622,
      "step": 11750,
      "train/forward_time_ms": 2.5343894958496094,
      "train/loss": 0.03200036287307739,
      "train/loss_affordance": 0.012037536595016718,
      "train/loss_compute_time_ms": 0.3502368927001953,
      "train/loss_risk": 0.012037536595016718,
      "train/loss_structure": 0.007925289683043957
    },
    {
      "epoch": 9.186864738076622,
      "step": 11750,
      "train/forward_time_ms": 4.288702011108398,
      "train/step_time_ms": 4.289126396179199
    },
    {
      "epoch": 9.225957779515246,
      "grad_norm": 0.1667174994945526,
      "learning_rate": 7.748240813135262e-06,
      "loss": 0.0505,
      "step": 11800
    },
    {
      "epoch": 9.225957779515246,
      "step": 11800,
      "train/forward_time_ms": 2.511739730834961,
      "train/loss": 0.050445135682821274,
      "train/loss_affordance": 0.016485324129462242,
      "train/loss_compute_time_ms": 0.3829002380371094,
      "train/loss_risk": 0.016485324129462242,
      "train/loss_structure": 0.01747448742389679
    },
    {
      "epoch": 9.225957779515246,
      "step": 11800,
      "train/forward_time_ms": 4.315381050109863,
      "train/step_time_ms": 4.315853118896484
    },
    {
      "epoch": 9.26505082095387,
      "grad_norm": 0.3313473165035248,
      "learning_rate": 7.357310398749023e-06,
      "loss": 0.0453,
      "step": 11850
    },
    {
      "epoch": 9.26505082095387,
      "step": 11850,
      "train/forward_time_ms": 2.4101734161376953,
      "train/loss": 0.060619011521339417,
      "train/loss_affordance": 0.026269703172147274,
      "train/loss_compute_time_ms": 0.3829002380371094,
      "train/loss_risk": 0.026269703172147274,
      "train/loss_structure": 0.008079605177044868
    },
    {
      "epoch": 9.26505082095387,
      "step": 11850,
      "train/forward_time_ms": 4.534115791320801,
      "train/step_time_ms": 4.53460693359375
    },
    {
      "epoch": 9.304143862392493,
      "grad_norm": 0.16045433282852173,
      "learning_rate": 6.9663799843627835e-06,
      "loss": 0.0514,
      "step": 11900
    },
    {
      "epoch": 9.304143862392493,
      "step": 11900,
      "train/forward_time_ms": 2.171754837036133,
      "train/loss": 0.06407088041305542,
      "train/loss_affordance": 0.020181563682854176,
      "train/loss_compute_time_ms": 0.2582073211669922,
      "train/loss_risk": 0.020181563682854176,
      "train/loss_structure": 0.02370775304734707
    },
    {
      "epoch": 9.304143862392493,
      "step": 11900,
      "train/forward_time_ms": 4.162812232971191,
      "train/step_time_ms": 4.163298606872559
    },
    {
      "epoch": 9.343236903831118,
      "grad_norm": 0.5902100205421448,
      "learning_rate": 6.575449569976544e-06,
      "loss": 0.0478,
      "step": 11950
    },
    {
      "epoch": 9.343236903831118,
      "step": 11950,
      "train/forward_time_ms": 2.3779869079589844,
      "train/loss": 0.05416461452841759,
      "train/loss_affordance": 0.022210365626960993,
      "train/loss_compute_time_ms": 0.3132820129394531,
      "train/loss_risk": 0.022210365626960993,
      "train/loss_structure": 0.009743883274495602
    },
    {
      "epoch": 9.343236903831118,
      "step": 11950,
      "train/forward_time_ms": 4.232358932495117,
      "train/step_time_ms": 4.232807159423828
    },
    {
      "epoch": 9.382329945269742,
      "grad_norm": 0.4664210379123688,
      "learning_rate": 6.184519155590305e-06,
      "loss": 0.0511,
      "step": 12000
    },
    {
      "epoch": 9.382329945269742,
      "step": 12000,
      "train/forward_time_ms": 3.027200698852539,
      "train/loss": 0.03318290412425995,
      "train/loss_affordance": 0.014224671991541982,
      "train/loss_compute_time_ms": 0.43201446533203125,
      "train/loss_risk": 0.014224671991541982,
      "train/loss_structure": 0.004733560141175985
    },
    {
      "epoch": 9.382329945269742,
      "step": 12000,
      "train/forward_time_ms": 4.589800834655762,
      "train/step_time_ms": 4.590334892272949
    },
    {
      "epoch": 9.421422986708366,
      "grad_norm": 0.15847818553447723,
      "learning_rate": 5.793588741204066e-06,
      "loss": 0.0474,
      "step": 12050
    },
    {
      "epoch": 9.421422986708366,
      "step": 12050,
      "train/forward_time_ms": 2.642393112182617,
      "train/loss": 0.056276775896549225,
      "train/loss_affordance": 0.022427483461797237,
      "train/loss_compute_time_ms": 0.3762245178222656,
      "train/loss_risk": 0.022427483461797237,
      "train/loss_structure": 0.01142180897295475
    },
    {
      "epoch": 9.421422986708366,
      "step": 12050,
      "train/forward_time_ms": 4.521489143371582,
      "train/step_time_ms": 4.521985054016113
    },
    {
      "epoch": 9.46051602814699,
      "grad_norm": 0.4338489770889282,
      "learning_rate": 5.402658326817827e-06,
      "loss": 0.0479,
      "step": 12100
    },
    {
      "epoch": 9.46051602814699,
      "step": 12100,
      "train/forward_time_ms": 2.95257568359375,
      "train/loss": 0.05407983064651489,
      "train/loss_affordance": 0.019253472797572613,
      "train/loss_compute_time_ms": 0.4258155822753906,
      "train/loss_risk": 0.019253472797572613,
      "train/loss_structure": 0.015572885051369667
    },
    {
      "epoch": 9.46051602814699,
      "step": 12100,
      "train/forward_time_ms": 4.513306617736816,
      "train/step_time_ms": 4.513802528381348
    },
    {
      "epoch": 9.499609069585613,
      "grad_norm": 0.4417884647846222,
      "learning_rate": 5.011727912431587e-06,
      "loss": 0.0502,
      "step": 12150
    },
    {
      "epoch": 9.499609069585613,
      "step": 12150,
      "train/forward_time_ms": 2.588987350463867,
      "train/loss": 0.052966415882110596,
      "train/loss_affordance": 0.02254594024270773,
      "train/loss_compute_time_ms": 0.36787986755371094,
      "train/loss_risk": 0.02254594024270773,
      "train/loss_structure": 0.007874535396695137
    },
    {
      "epoch": 9.499609069585613,
      "step": 12150,
      "train/forward_time_ms": 4.319620132446289,
      "train/step_time_ms": 4.320006370544434
    },
    {
      "epoch": 9.538702111024238,
      "grad_norm": 0.14595282077789307,
      "learning_rate": 4.620797498045348e-06,
      "loss": 0.0494,
      "step": 12200
    },
    {
      "epoch": 9.538702111024238,
      "step": 12200,
      "train/forward_time_ms": 2.4576187133789062,
      "train/loss": 0.04119865968823433,
      "train/loss_affordance": 0.015065309591591358,
      "train/loss_compute_time_ms": 0.3082752227783203,
      "train/loss_risk": 0.015065309591591358,
      "train/loss_structure": 0.011068040505051613
    },
    {
      "epoch": 9.538702111024238,
      "step": 12200,
      "train/forward_time_ms": 4.30206298828125,
      "train/step_time_ms": 4.302506446838379
    },
    {
      "epoch": 9.577795152462862,
      "grad_norm": 0.5545633435249329,
      "learning_rate": 4.229867083659109e-06,
      "loss": 0.0487,
      "step": 12250
    },
    {
      "epoch": 9.577795152462862,
      "step": 12250,
      "train/forward_time_ms": 2.1278858184814453,
      "train/loss": 0.04517173767089844,
      "train/loss_affordance": 0.015910825692117214,
      "train/loss_compute_time_ms": 0.2675056457519531,
      "train/loss_risk": 0.015910825692117214,
      "train/loss_structure": 0.013350086286664009
    },
    {
      "epoch": 9.577795152462862,
      "step": 12250,
      "train/forward_time_ms": 4.291062355041504,
      "train/step_time_ms": 4.291481971740723
    },
    {
      "epoch": 9.616888193901486,
      "grad_norm": 0.819219708442688,
      "learning_rate": 3.83893666927287e-06,
      "loss": 0.0487,
      "step": 12300
    },
    {
      "epoch": 9.616888193901486,
      "step": 12300,
      "train/forward_time_ms": 3.2634735107421875,
      "train/loss": 0.030666202306747437,
      "train/loss_affordance": 0.012815713416785002,
      "train/loss_compute_time_ms": 0.4165172576904297,
      "train/loss_risk": 0.012815713416785002,
      "train/loss_structure": 0.005034775473177433
    },
    {
      "epoch": 9.616888193901486,
      "step": 12300,
      "train/forward_time_ms": 4.7036027908325195,
      "train/step_time_ms": 4.704174995422363
    },
    {
      "epoch": 9.655981235340109,
      "grad_norm": 0.19232644140720367,
      "learning_rate": 3.44800625488663e-06,
      "loss": 0.0476,
      "step": 12350
    },
    {
      "epoch": 9.655981235340109,
      "step": 12350,
      "train/forward_time_ms": 2.332448959350586,
      "train/loss": 0.034787364304065704,
      "train/loss_affordance": 0.01428155042231083,
      "train/loss_compute_time_ms": 0.3333091735839844,
      "train/loss_risk": 0.01428155042231083,
      "train/loss_structure": 0.006224263459444046
    },
    {
      "epoch": 9.655981235340109,
      "step": 12350,
      "train/forward_time_ms": 4.613289833068848,
      "train/step_time_ms": 4.613795280456543
    },
    {
      "epoch": 9.695074276778733,
      "grad_norm": 0.42102232575416565,
      "learning_rate": 3.057075840500391e-06,
      "loss": 0.0495,
      "step": 12400
    },
    {
      "epoch": 9.695074276778733,
      "step": 12400,
      "train/forward_time_ms": 2.1958351135253906,
      "train/loss": 0.04857706278562546,
      "train/loss_affordance": 0.016524120233953,
      "train/loss_compute_time_ms": 0.32210350036621094,
      "train/loss_risk": 0.016524120233953,
      "train/loss_structure": 0.01552882231771946
    },
    {
      "epoch": 9.695074276778733,
      "step": 12400,
      "train/forward_time_ms": 4.326457977294922,
      "train/step_time_ms": 4.326887130737305
    },
    {
      "epoch": 9.734167318217358,
      "grad_norm": 0.43133386969566345,
      "learning_rate": 2.6661454261141517e-06,
      "loss": 0.0486,
      "step": 12450
    },
    {
      "epoch": 9.734167318217358,
      "step": 12450,
      "train/forward_time_ms": 2.6144981384277344,
      "train/loss": 0.05065656080842018,
      "train/loss_affordance": 0.01671867072582245,
      "train/loss_compute_time_ms": 0.40435791015625,
      "train/loss_risk": 0.01671867072582245,
      "train/loss_structure": 0.017219219356775284
    },
    {
      "epoch": 9.734167318217358,
      "step": 12450,
      "train/forward_time_ms": 4.2604875564575195,
      "train/step_time_ms": 4.2609357833862305
    },
    {
      "epoch": 9.773260359655982,
      "grad_norm": 0.2592638432979584,
      "learning_rate": 2.2752150117279123e-06,
      "loss": 0.0509,
      "step": 12500
    },
    {
      "epoch": 9.773260359655982,
      "step": 12500,
      "train/forward_time_ms": 2.6552677154541016,
      "train/loss": 0.04379049316048622,
      "train/loss_affordance": 0.01775059662759304,
      "train/loss_compute_time_ms": 0.3192424774169922,
      "train/loss_risk": 0.01775059662759304,
      "train/loss_structure": 0.00828929990530014
    },
    {
      "epoch": 9.773260359655982,
      "step": 12500,
      "train/forward_time_ms": 4.30509090423584,
      "train/step_time_ms": 4.305553436279297
    },
    {
      "epoch": 9.812353401094605,
      "grad_norm": 0.3280102610588074,
      "learning_rate": 1.8842845973416734e-06,
      "loss": 0.046,
      "step": 12550
    },
    {
      "epoch": 9.812353401094605,
      "step": 12550,
      "train/forward_time_ms": 2.8791427612304688,
      "train/loss": 0.05102609097957611,
      "train/loss_affordance": 0.01882167626172304,
      "train/loss_compute_time_ms": 0.4532337188720703,
      "train/loss_risk": 0.01882167626172304,
      "train/loss_structure": 0.013382738456130028
    },
    {
      "epoch": 9.812353401094605,
      "step": 12550,
      "train/forward_time_ms": 4.498600959777832,
      "train/step_time_ms": 4.499082565307617
    },
    {
      "epoch": 9.851446442533229,
      "grad_norm": 0.6576547026634216,
      "learning_rate": 1.493354182955434e-06,
      "loss": 0.0487,
      "step": 12600
    },
    {
      "epoch": 9.851446442533229,
      "step": 12600,
      "train/forward_time_ms": 2.3643970489501953,
      "train/loss": 0.043120309710502625,
      "train/loss_affordance": 0.013106940314173698,
      "train/loss_compute_time_ms": 0.2932548522949219,
      "train/loss_risk": 0.013106940314173698,
      "train/loss_structure": 0.016906429082155228
    },
    {
      "epoch": 9.851446442533229,
      "step": 12600,
      "train/forward_time_ms": 4.335918426513672,
      "train/step_time_ms": 4.336338043212891
    },
    {
      "epoch": 9.890539483971853,
      "grad_norm": 0.4638737142086029,
      "learning_rate": 1.1024237685691948e-06,
      "loss": 0.046,
      "step": 12650
    },
    {
      "epoch": 9.890539483971853,
      "step": 12650,
      "train/forward_time_ms": 2.206563949584961,
      "train/loss": 0.03753967210650444,
      "train/loss_affordance": 0.013866616878658533,
      "train/loss_compute_time_ms": 0.29349327087402344,
      "train/loss_risk": 0.013866616878658533,
      "train/loss_structure": 0.009806438349187374
    },
    {
      "epoch": 9.890539483971853,
      "step": 12650,
      "train/forward_time_ms": 4.221630096435547,
      "train/step_time_ms": 4.222049713134766
    },
    {
      "epoch": 9.929632525410478,
      "grad_norm": 0.5314376950263977,
      "learning_rate": 7.114933541829555e-07,
      "loss": 0.0505,
      "step": 12700
    },
    {
      "epoch": 9.929632525410478,
      "step": 12700,
      "train/forward_time_ms": 2.5725364685058594,
      "train/loss": 0.0514235757291317,
      "train/loss_affordance": 0.02108618523925543,
      "train/loss_compute_time_ms": 0.31638145446777344,
      "train/loss_risk": 0.02108618523925543,
      "train/loss_structure": 0.009251205250620842
    },
    {
      "epoch": 9.929632525410478,
      "step": 12700,
      "train/forward_time_ms": 4.349665641784668,
      "train/step_time_ms": 4.350161552429199
    },
    {
      "epoch": 9.9687255668491,
      "grad_norm": 0.6322676539421082,
      "learning_rate": 3.205629397967162e-07,
      "loss": 0.0485,
      "step": 12750
    },
    {
      "epoch": 9.9687255668491,
      "step": 12750,
      "train/forward_time_ms": 2.349853515625,
      "train/loss": 0.06662851572036743,
      "train/loss_affordance": 0.02214754745364189,
      "train/loss_compute_time_ms": 0.38051605224609375,
      "train/loss_risk": 0.02214754745364189,
      "train/loss_structure": 0.02233342081308365
    },
    {
      "epoch": 9.9687255668491,
      "step": 12750,
      "train/forward_time_ms": 4.440627098083496,
      "train/step_time_ms": 4.441089630126953
    }
  ],
  "logging_steps": 50,
  "max_steps": 12790,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
