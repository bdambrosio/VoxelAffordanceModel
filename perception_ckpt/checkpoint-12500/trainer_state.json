{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.773260359655982,
  "eval_steps": 500,
  "global_step": 12500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0,
      "step": 0,
      "train/forward_time_ms": 614.2997741699219,
      "train/loss": 2.2846503257751465,
      "train/loss_affordance": 0.8025398254394531,
      "train/loss_compute_time_ms": 74.9661922454834,
      "train/loss_risk": 0.8025398254394531,
      "train/loss_structure": 0.6795706748962402
    },
    {
      "epoch": 0,
      "step": 0,
      "train/forward_time_ms": 727.9744148254395,
      "train/step_time_ms": 727.9758453369141
    },
    {
      "epoch": 0.039093041438623924,
      "grad_norm": 1.318522572517395,
      "learning_rate": 9.961688819390149e-05,
      "loss": 2.1656,
      "step": 50
    },
    {
      "epoch": 0.039093041438623924,
      "step": 50,
      "train/forward_time_ms": 2.604961395263672,
      "train/loss": 1.9162967205047607,
      "train/loss_affordance": 0.6740394234657288,
      "train/loss_compute_time_ms": 0.31304359436035156,
      "train/loss_risk": 0.6740394234657288,
      "train/loss_structure": 0.5682178735733032
    },
    {
      "epoch": 0.039093041438623924,
      "step": 50,
      "train/forward_time_ms": 4.365582466125488,
      "train/step_time_ms": 4.365973472595215
    },
    {
      "epoch": 0.07818608287724785,
      "grad_norm": 1.1905535459518433,
      "learning_rate": 9.922595777951526e-05,
      "loss": 1.4278,
      "step": 100
    },
    {
      "epoch": 0.07818608287724785,
      "step": 100,
      "train/forward_time_ms": 2.523183822631836,
      "train/loss": 0.9573122262954712,
      "train/loss_affordance": 0.3262179493904114,
      "train/loss_compute_time_ms": 0.347137451171875,
      "train/loss_risk": 0.3262179493904114,
      "train/loss_structure": 0.30487632751464844
    },
    {
      "epoch": 0.07818608287724785,
      "step": 100,
      "train/forward_time_ms": 4.442892074584961,
      "train/step_time_ms": 4.443349838256836
    },
    {
      "epoch": 0.11727912431587177,
      "grad_norm": 0.9550257921218872,
      "learning_rate": 9.8835027365129e-05,
      "loss": 0.7707,
      "step": 150
    },
    {
      "epoch": 0.11727912431587177,
      "step": 150,
      "train/forward_time_ms": 2.255678176879883,
      "train/loss": 0.5929203629493713,
      "train/loss_affordance": 0.19075583666563034,
      "train/loss_compute_time_ms": 0.3604888916015625,
      "train/loss_risk": 0.19075583666563034,
      "train/loss_structure": 0.21140868961811066
    },
    {
      "epoch": 0.11727912431587177,
      "step": 150,
      "train/forward_time_ms": 4.124593734741211,
      "train/step_time_ms": 4.124999046325684
    },
    {
      "epoch": 0.1563721657544957,
      "grad_norm": 0.49991342425346375,
      "learning_rate": 9.844409695074277e-05,
      "loss": 0.4657,
      "step": 200
    },
    {
      "epoch": 0.1563721657544957,
      "step": 200,
      "train/forward_time_ms": 2.256631851196289,
      "train/loss": 0.36142292618751526,
      "train/loss_affordance": 0.10940438508987427,
      "train/loss_compute_time_ms": 0.29754638671875,
      "train/loss_risk": 0.10940438508987427,
      "train/loss_structure": 0.14261415600776672
    },
    {
      "epoch": 0.1563721657544957,
      "step": 200,
      "train/forward_time_ms": 4.20863151550293,
      "train/step_time_ms": 4.209089279174805
    },
    {
      "epoch": 0.19546520719311963,
      "grad_norm": 0.297693133354187,
      "learning_rate": 9.805316653635653e-05,
      "loss": 0.3663,
      "step": 250
    },
    {
      "epoch": 0.19546520719311963,
      "step": 250,
      "train/forward_time_ms": 2.553224563598633,
      "train/loss": 0.4113646447658539,
      "train/loss_affordance": 0.11792997270822525,
      "train/loss_compute_time_ms": 0.2701282501220703,
      "train/loss_risk": 0.11792997270822525,
      "train/loss_structure": 0.17550469934940338
    },
    {
      "epoch": 0.19546520719311963,
      "step": 250,
      "train/forward_time_ms": 4.157586097717285,
      "train/step_time_ms": 4.158058166503906
    },
    {
      "epoch": 0.23455824863174354,
      "grad_norm": 0.3664762079715729,
      "learning_rate": 9.76622361219703e-05,
      "loss": 0.3386,
      "step": 300
    },
    {
      "epoch": 0.23455824863174354,
      "step": 300,
      "train/forward_time_ms": 2.5262832641601562,
      "train/loss": 0.34943878650665283,
      "train/loss_affordance": 0.10051965713500977,
      "train/loss_compute_time_ms": 0.3197193145751953,
      "train/loss_risk": 0.10051965713500977,
      "train/loss_structure": 0.1483994722366333
    },
    {
      "epoch": 0.23455824863174354,
      "step": 300,
      "train/forward_time_ms": 4.222879409790039,
      "train/step_time_ms": 4.223337173461914
    },
    {
      "epoch": 0.2736512900703675,
      "grad_norm": 0.3610072731971741,
      "learning_rate": 9.727130570758406e-05,
      "loss": 0.3167,
      "step": 350
    },
    {
      "epoch": 0.2736512900703675,
      "step": 350,
      "train/forward_time_ms": 2.25067138671875,
      "train/loss": 0.25336188077926636,
      "train/loss_affordance": 0.07589758187532425,
      "train/loss_compute_time_ms": 0.3044605255126953,
      "train/loss_risk": 0.07589758187532425,
      "train/loss_structure": 0.10156671702861786
    },
    {
      "epoch": 0.2736512900703675,
      "step": 350,
      "train/forward_time_ms": 4.314403533935547,
      "train/step_time_ms": 4.31485652923584
    },
    {
      "epoch": 0.3127443315089914,
      "grad_norm": 0.43891945481300354,
      "learning_rate": 9.688037529319781e-05,
      "loss": 0.2944,
      "step": 400
    },
    {
      "epoch": 0.3127443315089914,
      "step": 400,
      "train/forward_time_ms": 2.1419525146484375,
      "train/loss": 0.28212204575538635,
      "train/loss_affordance": 0.08540952205657959,
      "train/loss_compute_time_ms": 0.29969215393066406,
      "train/loss_risk": 0.08540952205657959,
      "train/loss_structure": 0.11130300164222717
    },
    {
      "epoch": 0.3127443315089914,
      "step": 400,
      "train/forward_time_ms": 4.242887496948242,
      "train/step_time_ms": 4.243302345275879
    },
    {
      "epoch": 0.3518373729476153,
      "grad_norm": 0.36118730902671814,
      "learning_rate": 9.648944487881157e-05,
      "loss": 0.2736,
      "step": 450
    },
    {
      "epoch": 0.3518373729476153,
      "step": 450,
      "train/forward_time_ms": 2.3224353790283203,
      "train/loss": 0.27836909890174866,
      "train/loss_affordance": 0.08382802084088326,
      "train/loss_compute_time_ms": 0.3197193145751953,
      "train/loss_risk": 0.08382802084088326,
      "train/loss_structure": 0.11071305721998215
    },
    {
      "epoch": 0.3518373729476153,
      "step": 450,
      "train/forward_time_ms": 4.196186065673828,
      "train/step_time_ms": 4.196648597717285
    },
    {
      "epoch": 0.39093041438623927,
      "grad_norm": 0.42874255776405334,
      "learning_rate": 9.609851446442534e-05,
      "loss": 0.2649,
      "step": 500
    },
    {
      "epoch": 0.39093041438623927,
      "step": 500,
      "train/forward_time_ms": 2.5453567504882812,
      "train/loss": 0.20255149900913239,
      "train/loss_affordance": 0.056879885494709015,
      "train/loss_compute_time_ms": 0.42891502380371094,
      "train/loss_risk": 0.056879885494709015,
      "train/loss_structure": 0.08879172801971436
    },
    {
      "epoch": 0.39093041438623927,
      "step": 500,
      "train/forward_time_ms": 4.179348945617676,
      "train/step_time_ms": 4.179744720458984
    },
    {
      "epoch": 0.4300234558248632,
      "grad_norm": 0.36983799934387207,
      "learning_rate": 9.57075840500391e-05,
      "loss": 0.2476,
      "step": 550
    },
    {
      "epoch": 0.4300234558248632,
      "step": 550,
      "train/forward_time_ms": 2.435922622680664,
      "train/loss": 0.2385157346725464,
      "train/loss_affordance": 0.0650193840265274,
      "train/loss_compute_time_ms": 0.3883838653564453,
      "train/loss_risk": 0.0650193840265274,
      "train/loss_structure": 0.10847696661949158
    },
    {
      "epoch": 0.4300234558248632,
      "step": 550,
      "train/forward_time_ms": 4.207468032836914,
      "train/step_time_ms": 4.207897186279297
    },
    {
      "epoch": 0.4691164972634871,
      "grad_norm": 0.18529358506202698,
      "learning_rate": 9.531665363565287e-05,
      "loss": 0.2243,
      "step": 600
    },
    {
      "epoch": 0.4691164972634871,
      "step": 600,
      "train/forward_time_ms": 2.8831958770751953,
      "train/loss": 0.18239948153495789,
      "train/loss_affordance": 0.05518859624862671,
      "train/loss_compute_time_ms": 0.30231475830078125,
      "train/loss_risk": 0.05518859624862671,
      "train/loss_structure": 0.07202228903770447
    },
    {
      "epoch": 0.4691164972634871,
      "step": 600,
      "train/forward_time_ms": 4.380598068237305,
      "train/step_time_ms": 4.381041526794434
    },
    {
      "epoch": 0.508209538702111,
      "grad_norm": 0.30476364493370056,
      "learning_rate": 9.492572322126661e-05,
      "loss": 0.2208,
      "step": 650
    },
    {
      "epoch": 0.508209538702111,
      "step": 650,
      "train/forward_time_ms": 2.7086734771728516,
      "train/loss": 0.1499485969543457,
      "train/loss_affordance": 0.04549523629248142,
      "train/loss_compute_time_ms": 0.4024505615234375,
      "train/loss_risk": 0.04549523629248142,
      "train/loss_structure": 0.05895812436938286
    },
    {
      "epoch": 0.508209538702111,
      "step": 650,
      "train/forward_time_ms": 4.223346710205078,
      "train/step_time_ms": 4.223799705505371
    },
    {
      "epoch": 0.547302580140735,
      "grad_norm": 0.42773985862731934,
      "learning_rate": 9.453479280688038e-05,
      "loss": 0.1989,
      "step": 700
    },
    {
      "epoch": 0.547302580140735,
      "step": 700,
      "train/forward_time_ms": 2.476215362548828,
      "train/loss": 0.16143378615379333,
      "train/loss_affordance": 0.04589696601033211,
      "train/loss_compute_time_ms": 0.3814697265625,
      "train/loss_risk": 0.04589696601033211,
      "train/loss_structure": 0.06963985413312912
    },
    {
      "epoch": 0.547302580140735,
      "step": 700,
      "train/forward_time_ms": 4.368948936462402,
      "train/step_time_ms": 4.369354248046875
    },
    {
      "epoch": 0.5863956215793589,
      "grad_norm": 0.16780859231948853,
      "learning_rate": 9.414386239249414e-05,
      "loss": 0.1825,
      "step": 750
    },
    {
      "epoch": 0.5863956215793589,
      "step": 750,
      "train/forward_time_ms": 2.515077590942383,
      "train/loss": 0.18848967552185059,
      "train/loss_affordance": 0.05986097827553749,
      "train/loss_compute_time_ms": 0.3864765167236328,
      "train/loss_risk": 0.05986097827553749,
      "train/loss_structure": 0.0687677189707756
    },
    {
      "epoch": 0.5863956215793589,
      "step": 750,
      "train/forward_time_ms": 4.452452659606934,
      "train/step_time_ms": 4.452881813049316
    },
    {
      "epoch": 0.6254886630179828,
      "grad_norm": 0.49233371019363403,
      "learning_rate": 9.375293197810791e-05,
      "loss": 0.1855,
      "step": 800
    },
    {
      "epoch": 0.6254886630179828,
      "step": 800,
      "train/forward_time_ms": 2.353668212890625,
      "train/loss": 0.11926133185625076,
      "train/loss_affordance": 0.03645947203040123,
      "train/loss_compute_time_ms": 0.3933906555175781,
      "train/loss_risk": 0.03645947203040123,
      "train/loss_structure": 0.0463423877954483
    },
    {
      "epoch": 0.6254886630179828,
      "step": 800,
      "train/forward_time_ms": 4.08876895904541,
      "train/step_time_ms": 4.089150428771973
    },
    {
      "epoch": 0.6645817044566067,
      "grad_norm": 0.154769629240036,
      "learning_rate": 9.336200156372165e-05,
      "loss": 0.1778,
      "step": 850
    },
    {
      "epoch": 0.6645817044566067,
      "step": 850,
      "train/forward_time_ms": 2.144336700439453,
      "train/loss": 0.16973918676376343,
      "train/loss_affordance": 0.05102664232254028,
      "train/loss_compute_time_ms": 0.2949237823486328,
      "train/loss_risk": 0.05102664232254028,
      "train/loss_structure": 0.06768590211868286
    },
    {
      "epoch": 0.6645817044566067,
      "step": 850,
      "train/forward_time_ms": 4.382729530334473,
      "train/step_time_ms": 4.383139610290527
    },
    {
      "epoch": 0.7036747458952306,
      "grad_norm": 0.4325530230998993,
      "learning_rate": 9.297107114933542e-05,
      "loss": 0.1676,
      "step": 900
    },
    {
      "epoch": 0.7036747458952306,
      "step": 900,
      "train/forward_time_ms": 2.3136138916015625,
      "train/loss": 0.13626594841480255,
      "train/loss_affordance": 0.03992496803402901,
      "train/loss_compute_time_ms": 0.3135204315185547,
      "train/loss_risk": 0.03992496803402901,
      "train/loss_structure": 0.05641601234674454
    },
    {
      "epoch": 0.7036747458952306,
      "step": 900,
      "train/forward_time_ms": 4.124288558959961,
      "train/step_time_ms": 4.124665260314941
    },
    {
      "epoch": 0.7427677873338546,
      "grad_norm": 0.16522297263145447,
      "learning_rate": 9.258014073494918e-05,
      "loss": 0.1714,
      "step": 950
    },
    {
      "epoch": 0.7427677873338546,
      "step": 950,
      "train/forward_time_ms": 2.210378646850586,
      "train/loss": 0.16199147701263428,
      "train/loss_affordance": 0.04313010722398758,
      "train/loss_compute_time_ms": 0.3437995910644531,
      "train/loss_risk": 0.04313010722398758,
      "train/loss_structure": 0.07573126256465912
    },
    {
      "epoch": 0.7427677873338546,
      "step": 950,
      "train/forward_time_ms": 4.225654602050781,
      "train/step_time_ms": 4.226131439208984
    },
    {
      "epoch": 0.7818608287724785,
      "grad_norm": 0.3800358474254608,
      "learning_rate": 9.218921032056295e-05,
      "loss": 0.1617,
      "step": 1000
    },
    {
      "epoch": 0.7818608287724785,
      "step": 1000,
      "train/forward_time_ms": 2.4509429931640625,
      "train/loss": 0.12232758849859238,
      "train/loss_affordance": 0.0350410807877779,
      "train/loss_compute_time_ms": 0.41556358337402344,
      "train/loss_risk": 0.0350410807877779,
      "train/loss_structure": 0.052245426923036575
    },
    {
      "epoch": 0.7818608287724785,
      "step": 1000,
      "train/forward_time_ms": 4.190859794616699,
      "train/step_time_ms": 4.191288948059082
    },
    {
      "epoch": 0.8209538702111024,
      "grad_norm": 0.2131715714931488,
      "learning_rate": 9.17982799061767e-05,
      "loss": 0.1618,
      "step": 1050
    },
    {
      "epoch": 0.8209538702111024,
      "step": 1050,
      "train/forward_time_ms": 2.356290817260742,
      "train/loss": 0.12734653055667877,
      "train/loss_affordance": 0.03927142173051834,
      "train/loss_compute_time_ms": 0.29754638671875,
      "train/loss_risk": 0.03927142173051834,
      "train/loss_structure": 0.04880368709564209
    },
    {
      "epoch": 0.8209538702111024,
      "step": 1050,
      "train/forward_time_ms": 4.153275489807129,
      "train/step_time_ms": 4.1536760330200195
    },
    {
      "epoch": 0.8600469116497264,
      "grad_norm": 0.32867956161499023,
      "learning_rate": 9.140734949179046e-05,
      "loss": 0.1556,
      "step": 1100
    },
    {
      "epoch": 0.8600469116497264,
      "step": 1100,
      "train/forward_time_ms": 2.445220947265625,
      "train/loss": 0.10593637824058533,
      "train/loss_affordance": 0.0373968780040741,
      "train/loss_compute_time_ms": 0.3159046173095703,
      "train/loss_risk": 0.0373968780040741,
      "train/loss_structure": 0.031142622232437134
    },
    {
      "epoch": 0.8600469116497264,
      "step": 1100,
      "train/forward_time_ms": 4.340252876281738,
      "train/step_time_ms": 4.340710639953613
    },
    {
      "epoch": 0.8991399530883503,
      "grad_norm": 0.4059682786464691,
      "learning_rate": 9.101641907740422e-05,
      "loss": 0.1491,
      "step": 1150
    },
    {
      "epoch": 0.8991399530883503,
      "step": 1150,
      "train/forward_time_ms": 2.4709701538085938,
      "train/loss": 0.13263343274593353,
      "train/loss_affordance": 0.04391361027956009,
      "train/loss_compute_time_ms": 0.3845691680908203,
      "train/loss_risk": 0.04391361027956009,
      "train/loss_structure": 0.044806212186813354
    },
    {
      "epoch": 0.8991399530883503,
      "step": 1150,
      "train/forward_time_ms": 4.07567024230957,
      "train/step_time_ms": 4.076080322265625
    },
    {
      "epoch": 0.9382329945269742,
      "grad_norm": 0.5766966342926025,
      "learning_rate": 9.062548866301799e-05,
      "loss": 0.1534,
      "step": 1200
    },
    {
      "epoch": 0.9382329945269742,
      "step": 1200,
      "train/forward_time_ms": 2.616405487060547,
      "train/loss": 0.19548407196998596,
      "train/loss_affordance": 0.059704892337322235,
      "train/loss_compute_time_ms": 0.3685951232910156,
      "train/loss_risk": 0.059704892337322235,
      "train/loss_structure": 0.07607428729534149
    },
    {
      "epoch": 0.9382329945269742,
      "step": 1200,
      "train/forward_time_ms": 4.208412170410156,
      "train/step_time_ms": 4.208817481994629
    },
    {
      "epoch": 0.9773260359655981,
      "grad_norm": 0.3978569507598877,
      "learning_rate": 9.023455824863175e-05,
      "loss": 0.145,
      "step": 1250
    },
    {
      "epoch": 0.9773260359655981,
      "step": 1250,
      "train/forward_time_ms": 2.3751258850097656,
      "train/loss": 0.1910819709300995,
      "train/loss_affordance": 0.05715666338801384,
      "train/loss_compute_time_ms": 0.3223419189453125,
      "train/loss_risk": 0.05715666338801384,
      "train/loss_structure": 0.07676864415407181
    },
    {
      "epoch": 0.9773260359655981,
      "step": 1250,
      "train/forward_time_ms": 4.232287406921387,
      "train/step_time_ms": 4.232726097106934
    },
    {
      "epoch": 1.016419077404222,
      "grad_norm": 0.38101959228515625,
      "learning_rate": 8.984362783424552e-05,
      "loss": 0.1454,
      "step": 1300
    },
    {
      "epoch": 1.016419077404222,
      "step": 1300,
      "train/forward_time_ms": 2.284526824951172,
      "train/loss": 0.1317586600780487,
      "train/loss_affordance": 0.03658253885805607,
      "train/loss_compute_time_ms": 0.2932548522949219,
      "train/loss_risk": 0.03658253885805607,
      "train/loss_structure": 0.05859358236193657
    },
    {
      "epoch": 1.016419077404222,
      "step": 1300,
      "train/forward_time_ms": 4.1924333572387695,
      "train/step_time_ms": 4.19285774230957
    },
    {
      "epoch": 1.055512118842846,
      "grad_norm": 0.54607754945755,
      "learning_rate": 8.945269741985926e-05,
      "loss": 0.1441,
      "step": 1350
    },
    {
      "epoch": 1.055512118842846,
      "step": 1350,
      "train/forward_time_ms": 2.3467540740966797,
      "train/loss": 0.16386114060878754,
      "train/loss_affordance": 0.04455247148871422,
      "train/loss_compute_time_ms": 0.3020763397216797,
      "train/loss_risk": 0.04455247148871422,
      "train/loss_structure": 0.0747561976313591
    },
    {
      "epoch": 1.055512118842846,
      "step": 1350,
      "train/forward_time_ms": 4.488692283630371,
      "train/step_time_ms": 4.4892072677612305
    },
    {
      "epoch": 1.09460516028147,
      "grad_norm": 0.20234020054340363,
      "learning_rate": 8.906176700547303e-05,
      "loss": 0.1326,
      "step": 1400
    },
    {
      "epoch": 1.09460516028147,
      "step": 1400,
      "train/forward_time_ms": 2.484560012817383,
      "train/loss": 0.12762823700904846,
      "train/loss_affordance": 0.04163657873868942,
      "train/loss_compute_time_ms": 0.31280517578125,
      "train/loss_risk": 0.04163657873868942,
      "train/loss_structure": 0.04435507953166962
    },
    {
      "epoch": 1.09460516028147,
      "step": 1400,
      "train/forward_time_ms": 4.394927024841309,
      "train/step_time_ms": 4.3953657150268555
    },
    {
      "epoch": 1.1336982017200938,
      "grad_norm": 0.3557855784893036,
      "learning_rate": 8.867083659108679e-05,
      "loss": 0.1374,
      "step": 1450
    },
    {
      "epoch": 1.1336982017200938,
      "step": 1450,
      "train/forward_time_ms": 2.330303192138672,
      "train/loss": 0.1710752546787262,
      "train/loss_affordance": 0.05281567573547363,
      "train/loss_compute_time_ms": 0.34046173095703125,
      "train/loss_risk": 0.05281567573547363,
      "train/loss_structure": 0.06544390320777893
    },
    {
      "epoch": 1.1336982017200938,
      "step": 1450,
      "train/forward_time_ms": 4.585056304931641,
      "train/step_time_ms": 4.585509300231934
    },
    {
      "epoch": 1.1727912431587177,
      "grad_norm": 0.28402596712112427,
      "learning_rate": 8.827990617670056e-05,
      "loss": 0.1383,
      "step": 1500
    },
    {
      "epoch": 1.1727912431587177,
      "step": 1500,
      "train/forward_time_ms": 2.2695064544677734,
      "train/loss": 0.1342124044895172,
      "train/loss_affordance": 0.03646907024085522,
      "train/loss_compute_time_ms": 0.34332275390625,
      "train/loss_risk": 0.03646907024085522,
      "train/loss_structure": 0.06127426400780678
    },
    {
      "epoch": 1.1727912431587177,
      "step": 1500,
      "train/forward_time_ms": 4.140644073486328,
      "train/step_time_ms": 4.141063690185547
    },
    {
      "epoch": 1.2118842845973417,
      "grad_norm": 0.6170012950897217,
      "learning_rate": 8.78889757623143e-05,
      "loss": 0.1351,
      "step": 1550
    },
    {
      "epoch": 1.2118842845973417,
      "step": 1550,
      "train/forward_time_ms": 2.499818801879883,
      "train/loss": 0.13273487985134125,
      "train/loss_affordance": 0.03124600276350975,
      "train/loss_compute_time_ms": 0.3299713134765625,
      "train/loss_risk": 0.03124600276350975,
      "train/loss_structure": 0.07024287432432175
    },
    {
      "epoch": 1.2118842845973417,
      "step": 1550,
      "train/forward_time_ms": 4.183621406555176,
      "train/step_time_ms": 4.184055328369141
    },
    {
      "epoch": 1.2509773260359656,
      "grad_norm": 0.5102974772453308,
      "learning_rate": 8.749804534792807e-05,
      "loss": 0.1276,
      "step": 1600
    },
    {
      "epoch": 1.2509773260359656,
      "step": 1600,
      "train/forward_time_ms": 2.2149085998535156,
      "train/loss": 0.0917554423213005,
      "train/loss_affordance": 0.030580676160752773,
      "train/loss_compute_time_ms": 0.32973289489746094,
      "train/loss_risk": 0.030580676160752773,
      "train/loss_structure": 0.03059408999979496
    },
    {
      "epoch": 1.2509773260359656,
      "step": 1600,
      "train/forward_time_ms": 4.548530578613281,
      "train/step_time_ms": 4.548969268798828
    },
    {
      "epoch": 1.2900703674745895,
      "grad_norm": 0.4354690909385681,
      "learning_rate": 8.710711493354183e-05,
      "loss": 0.1239,
      "step": 1650
    },
    {
      "epoch": 1.2900703674745895,
      "step": 1650,
      "train/forward_time_ms": 2.323150634765625,
      "train/loss": 0.08418278396129608,
      "train/loss_affordance": 0.026532383635640144,
      "train/loss_compute_time_ms": 0.2846717834472656,
      "train/loss_risk": 0.026532383635640144,
      "train/loss_structure": 0.031118016690015793
    },
    {
      "epoch": 1.2900703674745895,
      "step": 1650,
      "train/forward_time_ms": 4.16567325592041,
      "train/step_time_ms": 4.166049957275391
    },
    {
      "epoch": 1.3291634089132134,
      "grad_norm": 0.3226727843284607,
      "learning_rate": 8.67161845191556e-05,
      "loss": 0.1259,
      "step": 1700
    },
    {
      "epoch": 1.3291634089132134,
      "step": 1700,
      "train/forward_time_ms": 2.4933815002441406,
      "train/loss": 0.06923983991146088,
      "train/loss_affordance": 0.01903800666332245,
      "train/loss_compute_time_ms": 0.28824806213378906,
      "train/loss_risk": 0.01903800666332245,
      "train/loss_structure": 0.03116382658481598
    },
    {
      "epoch": 1.3291634089132134,
      "step": 1700,
      "train/forward_time_ms": 4.126381874084473,
      "train/step_time_ms": 4.126758575439453
    },
    {
      "epoch": 1.3682564503518373,
      "grad_norm": 0.3423694372177124,
      "learning_rate": 8.632525410476936e-05,
      "loss": 0.1214,
      "step": 1750
    },
    {
      "epoch": 1.3682564503518373,
      "step": 1750,
      "train/forward_time_ms": 5.514621734619141,
      "train/loss": 0.12029115855693817,
      "train/loss_affordance": 0.033853210508823395,
      "train/loss_compute_time_ms": 0.28705596923828125,
      "train/loss_risk": 0.033853210508823395,
      "train/loss_structure": 0.05258473753929138
    },
    {
      "epoch": 1.3682564503518373,
      "step": 1750,
      "train/forward_time_ms": 4.239301681518555,
      "train/step_time_ms": 4.239745140075684
    },
    {
      "epoch": 1.4073494917904612,
      "grad_norm": 0.26166749000549316,
      "learning_rate": 8.593432369038311e-05,
      "loss": 0.1262,
      "step": 1800
    },
    {
      "epoch": 1.4073494917904612,
      "step": 1800,
      "train/forward_time_ms": 2.186298370361328,
      "train/loss": 0.1339876353740692,
      "train/loss_affordance": 0.03363679721951485,
      "train/loss_compute_time_ms": 0.29349327087402344,
      "train/loss_risk": 0.03363679721951485,
      "train/loss_structure": 0.06671404093503952
    },
    {
      "epoch": 1.4073494917904612,
      "step": 1800,
      "train/forward_time_ms": 4.1664886474609375,
      "train/step_time_ms": 4.166855812072754
    },
    {
      "epoch": 1.4464425332290851,
      "grad_norm": 0.3091724216938019,
      "learning_rate": 8.554339327599687e-05,
      "loss": 0.123,
      "step": 1850
    },
    {
      "epoch": 1.4464425332290851,
      "step": 1850,
      "train/forward_time_ms": 2.4826526641845703,
      "train/loss": 0.14131513237953186,
      "train/loss_affordance": 0.04405499994754791,
      "train/loss_compute_time_ms": 0.41174888610839844,
      "train/loss_risk": 0.04405499994754791,
      "train/loss_structure": 0.053205132484436035
    },
    {
      "epoch": 1.4464425332290851,
      "step": 1850,
      "train/forward_time_ms": 4.432792663574219,
      "train/step_time_ms": 4.433236122131348
    },
    {
      "epoch": 1.485535574667709,
      "grad_norm": 0.21231485903263092,
      "learning_rate": 8.515246286161064e-05,
      "loss": 0.1257,
      "step": 1900
    },
    {
      "epoch": 1.485535574667709,
      "step": 1900,
      "train/forward_time_ms": 2.2847652435302734,
      "train/loss": 0.10574563592672348,
      "train/loss_affordance": 0.024474618956446648,
      "train/loss_compute_time_ms": 0.301361083984375,
      "train/loss_risk": 0.024474618956446648,
      "train/loss_structure": 0.056796398013830185
    },
    {
      "epoch": 1.485535574667709,
      "step": 1900,
      "train/forward_time_ms": 4.21170711517334,
      "train/step_time_ms": 4.212155342102051
    },
    {
      "epoch": 1.524628616106333,
      "grad_norm": 0.36662882566452026,
      "learning_rate": 8.47615324472244e-05,
      "loss": 0.112,
      "step": 1950
    },
    {
      "epoch": 1.524628616106333,
      "step": 1950,
      "train/forward_time_ms": 2.340078353881836,
      "train/loss": 0.1030542328953743,
      "train/loss_affordance": 0.029475636780261993,
      "train/loss_compute_time_ms": 0.30684471130371094,
      "train/loss_risk": 0.029475636780261993,
      "train/loss_structure": 0.04410295933485031
    },
    {
      "epoch": 1.524628616106333,
      "step": 1950,
      "train/forward_time_ms": 4.145240783691406,
      "train/step_time_ms": 4.145603179931641
    },
    {
      "epoch": 1.5637216575449568,
      "grad_norm": 0.37252286076545715,
      "learning_rate": 8.437060203283817e-05,
      "loss": 0.1132,
      "step": 2000
    },
    {
      "epoch": 1.5637216575449568,
      "step": 2000,
      "train/forward_time_ms": 2.531290054321289,
      "train/loss": 0.13205072283744812,
      "train/loss_affordance": 0.04136713780462742,
      "train/loss_compute_time_ms": 0.3180503845214844,
      "train/loss_risk": 0.04136713780462742,
      "train/loss_structure": 0.04931644722819328
    },
    {
      "epoch": 1.5637216575449568,
      "step": 2000,
      "train/forward_time_ms": 4.224534034729004,
      "train/step_time_ms": 4.224996566772461
    },
    {
      "epoch": 1.602814698983581,
      "grad_norm": 0.27424687147140503,
      "learning_rate": 8.397967161845191e-05,
      "loss": 0.1101,
      "step": 2050
    },
    {
      "epoch": 1.602814698983581,
      "step": 2050,
      "train/forward_time_ms": 2.4750232696533203,
      "train/loss": 0.14941295981407166,
      "train/loss_affordance": 0.04718988388776779,
      "train/loss_compute_time_ms": 0.3020763397216797,
      "train/loss_risk": 0.04718988388776779,
      "train/loss_structure": 0.05503319203853607
    },
    {
      "epoch": 1.602814698983581,
      "step": 2050,
      "train/forward_time_ms": 4.2060136795043945,
      "train/step_time_ms": 4.206452369689941
    },
    {
      "epoch": 1.6419077404222049,
      "grad_norm": 0.4197620749473572,
      "learning_rate": 8.358874120406568e-05,
      "loss": 0.1102,
      "step": 2100
    },
    {
      "epoch": 1.6419077404222049,
      "step": 2100,
      "train/forward_time_ms": 2.3560523986816406,
      "train/loss": 0.13782769441604614,
      "train/loss_affordance": 0.04542560875415802,
      "train/loss_compute_time_ms": 0.31256675720214844,
      "train/loss_risk": 0.04542560875415802,
      "train/loss_structure": 0.0469764769077301
    },
    {
      "epoch": 1.6419077404222049,
      "step": 2100,
      "train/forward_time_ms": 4.414243698120117,
      "train/step_time_ms": 4.414663314819336
    },
    {
      "epoch": 1.6810007818608288,
      "grad_norm": 0.4796431362628937,
      "learning_rate": 8.319781078967944e-05,
      "loss": 0.1049,
      "step": 2150
    },
    {
      "epoch": 1.6810007818608288,
      "step": 2150,
      "train/forward_time_ms": 2.257108688354492,
      "train/loss": 0.1056743711233139,
      "train/loss_affordance": 0.03708973899483681,
      "train/loss_compute_time_ms": 0.2887248992919922,
      "train/loss_risk": 0.03708973899483681,
      "train/loss_structure": 0.03149489313364029
    },
    {
      "epoch": 1.6810007818608288,
      "step": 2150,
      "train/forward_time_ms": 4.246253967285156,
      "train/step_time_ms": 4.246692657470703
    },
    {
      "epoch": 1.7200938232994527,
      "grad_norm": 0.25323814153671265,
      "learning_rate": 8.280688037529321e-05,
      "loss": 0.1119,
      "step": 2200
    },
    {
      "epoch": 1.7200938232994527,
      "step": 2200,
      "train/forward_time_ms": 2.3581981658935547,
      "train/loss": 0.10972584784030914,
      "train/loss_affordance": 0.03156634792685509,
      "train/loss_compute_time_ms": 0.354766845703125,
      "train/loss_risk": 0.03156634792685509,
      "train/loss_structure": 0.04659315198659897
    },
    {
      "epoch": 1.7200938232994527,
      "step": 2200,
      "train/forward_time_ms": 4.108762741088867,
      "train/step_time_ms": 4.109196662902832
    },
    {
      "epoch": 1.7591868647380766,
      "grad_norm": 0.36730384826660156,
      "learning_rate": 8.241594996090695e-05,
      "loss": 0.1066,
      "step": 2250
    },
    {
      "epoch": 1.7591868647380766,
      "step": 2250,
      "train/forward_time_ms": 2.2716522216796875,
      "train/loss": 0.14718759059906006,
      "train/loss_affordance": 0.03993082046508789,
      "train/loss_compute_time_ms": 0.3123283386230469,
      "train/loss_risk": 0.03993082046508789,
      "train/loss_structure": 0.06732594966888428
    },
    {
      "epoch": 1.7591868647380766,
      "step": 2250,
      "train/forward_time_ms": 4.216394424438477,
      "train/step_time_ms": 4.216828346252441
    },
    {
      "epoch": 1.7982799061767005,
      "grad_norm": 0.5948790311813354,
      "learning_rate": 8.202501954652072e-05,
      "loss": 0.1042,
      "step": 2300
    },
    {
      "epoch": 1.7982799061767005,
      "step": 2300,
      "train/forward_time_ms": 2.2363662719726562,
      "train/loss": 0.10298383235931396,
      "train/loss_affordance": 0.03250427730381489,
      "train/loss_compute_time_ms": 0.30803680419921875,
      "train/loss_risk": 0.03250427730381489,
      "train/loss_structure": 0.03797527775168419
    },
    {
      "epoch": 1.7982799061767005,
      "step": 2300,
      "train/forward_time_ms": 4.162421226501465,
      "train/step_time_ms": 4.162817001342773
    },
    {
      "epoch": 1.8373729476153244,
      "grad_norm": 0.2310125082731247,
      "learning_rate": 8.163408913213448e-05,
      "loss": 0.1055,
      "step": 2350
    },
    {
      "epoch": 1.8373729476153244,
      "step": 2350,
      "train/forward_time_ms": 2.763032913208008,
      "train/loss": 0.1201583594083786,
      "train/loss_affordance": 0.03415573388338089,
      "train/loss_compute_time_ms": 0.31566619873046875,
      "train/loss_risk": 0.03415573388338089,
      "train/loss_structure": 0.05184689164161682
    },
    {
      "epoch": 1.8373729476153244,
      "step": 2350,
      "train/forward_time_ms": 4.303407669067383,
      "train/step_time_ms": 4.30384635925293
    },
    {
      "epoch": 1.8764659890539483,
      "grad_norm": 0.4650409519672394,
      "learning_rate": 8.124315871774825e-05,
      "loss": 0.1002,
      "step": 2400
    },
    {
      "epoch": 1.8764659890539483,
      "step": 2400,
      "train/forward_time_ms": 2.396106719970703,
      "train/loss": 0.1271376758813858,
      "train/loss_affordance": 0.03612472489476204,
      "train/loss_compute_time_ms": 0.2727508544921875,
      "train/loss_risk": 0.03612472489476204,
      "train/loss_structure": 0.054888226091861725
    },
    {
      "epoch": 1.8764659890539483,
      "step": 2400,
      "train/forward_time_ms": 4.31818962097168,
      "train/step_time_ms": 4.318652153015137
    },
    {
      "epoch": 1.9155590304925725,
      "grad_norm": 0.16829730570316315,
      "learning_rate": 8.0852228303362e-05,
      "loss": 0.1019,
      "step": 2450
    },
    {
      "epoch": 1.9155590304925725,
      "step": 2450,
      "train/forward_time_ms": 2.2215843200683594,
      "train/loss": 0.10230034589767456,
      "train/loss_affordance": 0.031165888532996178,
      "train/loss_compute_time_ms": 0.2636909484863281,
      "train/loss_risk": 0.031165888532996178,
      "train/loss_structure": 0.039968568831682205
    },
    {
      "epoch": 1.9155590304925725,
      "step": 2450,
      "train/forward_time_ms": 4.124479293823242,
      "train/step_time_ms": 4.124875068664551
    },
    {
      "epoch": 1.9546520719311964,
      "grad_norm": 0.2354659140110016,
      "learning_rate": 8.046129788897576e-05,
      "loss": 0.104,
      "step": 2500
    },
    {
      "epoch": 1.9546520719311964,
      "step": 2500,
      "train/forward_time_ms": 2.4247169494628906,
      "train/loss": 0.12747113406658173,
      "train/loss_affordance": 0.04152530059218407,
      "train/loss_compute_time_ms": 0.36597251892089844,
      "train/loss_risk": 0.04152530059218407,
      "train/loss_structure": 0.04442053288221359
    },
    {
      "epoch": 1.9546520719311964,
      "step": 2500,
      "train/forward_time_ms": 4.166073799133301,
      "train/step_time_ms": 4.166479110717773
    },
    {
      "epoch": 1.9937451133698203,
      "grad_norm": 0.616115927696228,
      "learning_rate": 8.007036747458952e-05,
      "loss": 0.1046,
      "step": 2550
    },
    {
      "epoch": 1.9937451133698203,
      "step": 2550,
      "train/forward_time_ms": 2.377748489379883,
      "train/loss": 0.08946327865123749,
      "train/loss_affordance": 0.0283132903277874,
      "train/loss_compute_time_ms": 0.31876564025878906,
      "train/loss_risk": 0.0283132903277874,
      "train/loss_structure": 0.03283669799566269
    },
    {
      "epoch": 1.9937451133698203,
      "step": 2550,
      "train/forward_time_ms": 4.201350212097168,
      "train/step_time_ms": 4.201774597167969
    },
    {
      "epoch": 2.032838154808444,
      "grad_norm": 0.37810802459716797,
      "learning_rate": 7.967943706020329e-05,
      "loss": 0.0974,
      "step": 2600
    },
    {
      "epoch": 2.032838154808444,
      "step": 2600,
      "train/forward_time_ms": 2.368450164794922,
      "train/loss": 0.12201185524463654,
      "train/loss_affordance": 0.03594624251127243,
      "train/loss_compute_time_ms": 0.32138824462890625,
      "train/loss_risk": 0.03594624251127243,
      "train/loss_structure": 0.050119370222091675
    },
    {
      "epoch": 2.032838154808444,
      "step": 2600,
      "train/forward_time_ms": 4.392809867858887,
      "train/step_time_ms": 4.393243789672852
    },
    {
      "epoch": 2.071931196247068,
      "grad_norm": 0.6455633044242859,
      "learning_rate": 7.928850664581705e-05,
      "loss": 0.1011,
      "step": 2650
    },
    {
      "epoch": 2.071931196247068,
      "step": 2650,
      "train/forward_time_ms": 2.5691986083984375,
      "train/loss": 0.09549403190612793,
      "train/loss_affordance": 0.024593038484454155,
      "train/loss_compute_time_ms": 0.3654956817626953,
      "train/loss_risk": 0.024593038484454155,
      "train/loss_structure": 0.04630795493721962
    },
    {
      "epoch": 2.071931196247068,
      "step": 2650,
      "train/forward_time_ms": 4.170637130737305,
      "train/step_time_ms": 4.171099662780762
    },
    {
      "epoch": 2.111024237685692,
      "grad_norm": 0.28039073944091797,
      "learning_rate": 7.889757623143082e-05,
      "loss": 0.0942,
      "step": 2700
    },
    {
      "epoch": 2.111024237685692,
      "step": 2700,
      "train/forward_time_ms": 2.285003662109375,
      "train/loss": 0.10868006944656372,
      "train/loss_affordance": 0.029780995100736618,
      "train/loss_compute_time_ms": 0.3097057342529297,
      "train/loss_risk": 0.029780995100736618,
      "train/loss_structure": 0.049118079245090485
    },
    {
      "epoch": 2.111024237685692,
      "step": 2700,
      "train/forward_time_ms": 4.168815612792969,
      "train/step_time_ms": 4.169201850891113
    },
    {
      "epoch": 2.150117279124316,
      "grad_norm": 0.14728368818759918,
      "learning_rate": 7.850664581704456e-05,
      "loss": 0.0975,
      "step": 2750
    },
    {
      "epoch": 2.150117279124316,
      "step": 2750,
      "train/forward_time_ms": 2.4204254150390625,
      "train/loss": 0.09303825348615646,
      "train/loss_affordance": 0.026037443429231644,
      "train/loss_compute_time_ms": 0.32067298889160156,
      "train/loss_risk": 0.026037443429231644,
      "train/loss_structure": 0.040963366627693176
    },
    {
      "epoch": 2.150117279124316,
      "step": 2750,
      "train/forward_time_ms": 4.27823543548584,
      "train/step_time_ms": 4.278602600097656
    },
    {
      "epoch": 2.18921032056294,
      "grad_norm": 0.24679170548915863,
      "learning_rate": 7.811571540265833e-05,
      "loss": 0.0905,
      "step": 2800
    },
    {
      "epoch": 2.18921032056294,
      "step": 2800,
      "train/forward_time_ms": 2.299785614013672,
      "train/loss": 0.0654774010181427,
      "train/loss_affordance": 0.021227406337857246,
      "train/loss_compute_time_ms": 0.33855438232421875,
      "train/loss_risk": 0.021227406337857246,
      "train/loss_structure": 0.023022588342428207
    },
    {
      "epoch": 2.18921032056294,
      "step": 2800,
      "train/forward_time_ms": 4.209856986999512,
      "train/step_time_ms": 4.210290908813477
    },
    {
      "epoch": 2.2283033620015638,
      "grad_norm": 0.4498688578605652,
      "learning_rate": 7.772478498827209e-05,
      "loss": 0.0909,
      "step": 2850
    },
    {
      "epoch": 2.2283033620015638,
      "step": 2850,
      "train/forward_time_ms": 2.2051334381103516,
      "train/loss": 0.0720876008272171,
      "train/loss_affordance": 0.025468608364462852,
      "train/loss_compute_time_ms": 0.31304359436035156,
      "train/loss_risk": 0.025468608364462852,
      "train/loss_structure": 0.021150384098291397
    },
    {
      "epoch": 2.2283033620015638,
      "step": 2850,
      "train/forward_time_ms": 4.324021339416504,
      "train/step_time_ms": 4.324493408203125
    },
    {
      "epoch": 2.2673964034401877,
      "grad_norm": 0.2553889751434326,
      "learning_rate": 7.733385457388586e-05,
      "loss": 0.0927,
      "step": 2900
    },
    {
      "epoch": 2.2673964034401877,
      "step": 2900,
      "train/forward_time_ms": 2.8679370880126953,
      "train/loss": 0.07553155720233917,
      "train/loss_affordance": 0.018263788893818855,
      "train/loss_compute_time_ms": 0.39577484130859375,
      "train/loss_risk": 0.018263788893818855,
      "train/loss_structure": 0.03900397941470146
    },
    {
      "epoch": 2.2673964034401877,
      "step": 2900,
      "train/forward_time_ms": 4.163379669189453,
      "train/step_time_ms": 4.163775444030762
    },
    {
      "epoch": 2.3064894448788116,
      "grad_norm": 0.21950484812259674,
      "learning_rate": 7.69429241594996e-05,
      "loss": 0.0891,
      "step": 2950
    },
    {
      "epoch": 2.3064894448788116,
      "step": 2950,
      "train/forward_time_ms": 3.0329227447509766,
      "train/loss": 0.08065694570541382,
      "train/loss_affordance": 0.021211933344602585,
      "train/loss_compute_time_ms": 0.3635883331298828,
      "train/loss_risk": 0.021211933344602585,
      "train/loss_structure": 0.03823307901620865
    },
    {
      "epoch": 2.3064894448788116,
      "step": 2950,
      "train/forward_time_ms": 4.166593551635742,
      "train/step_time_ms": 4.166975021362305
    },
    {
      "epoch": 2.3455824863174355,
      "grad_norm": 0.2853900194168091,
      "learning_rate": 7.655199374511337e-05,
      "loss": 0.0873,
      "step": 3000
    },
    {
      "epoch": 2.3455824863174355,
      "step": 3000,
      "train/forward_time_ms": 2.427816390991211,
      "train/loss": 0.08200913667678833,
      "train/loss_affordance": 0.029751230031251907,
      "train/loss_compute_time_ms": 0.3230571746826172,
      "train/loss_risk": 0.029751230031251907,
      "train/loss_structure": 0.022506676614284515
    },
    {
      "epoch": 2.3455824863174355,
      "step": 3000,
      "train/forward_time_ms": 4.147076606750488,
      "train/step_time_ms": 4.147500991821289
    },
    {
      "epoch": 2.3846755277560594,
      "grad_norm": 0.3986143469810486,
      "learning_rate": 7.616106333072713e-05,
      "loss": 0.0928,
      "step": 3050
    },
    {
      "epoch": 2.3846755277560594,
      "step": 3050,
      "train/forward_time_ms": 2.454996109008789,
      "train/loss": 0.11708275973796844,
      "train/loss_affordance": 0.0320160835981369,
      "train/loss_compute_time_ms": 0.2791881561279297,
      "train/loss_risk": 0.0320160835981369,
      "train/loss_structure": 0.05305059254169464
    },
    {
      "epoch": 2.3846755277560594,
      "step": 3050,
      "train/forward_time_ms": 4.147071838378906,
      "train/step_time_ms": 4.147491455078125
    },
    {
      "epoch": 2.4237685691946833,
      "grad_norm": 0.43779227137565613,
      "learning_rate": 7.57701329163409e-05,
      "loss": 0.0873,
      "step": 3100
    },
    {
      "epoch": 2.4237685691946833,
      "step": 3100,
      "train/forward_time_ms": 2.496957778930664,
      "train/loss": 0.0999968945980072,
      "train/loss_affordance": 0.03365020267665386,
      "train/loss_compute_time_ms": 0.39076805114746094,
      "train/loss_risk": 0.03365020267665386,
      "train/loss_structure": 0.03269648924469948
    },
    {
      "epoch": 2.4237685691946833,
      "step": 3100,
      "train/forward_time_ms": 4.428577423095703,
      "train/step_time_ms": 4.429054260253906
    },
    {
      "epoch": 2.462861610633307,
      "grad_norm": 0.43483248353004456,
      "learning_rate": 7.537920250195466e-05,
      "loss": 0.0899,
      "step": 3150
    },
    {
      "epoch": 2.462861610633307,
      "step": 3150,
      "train/forward_time_ms": 2.8336048126220703,
      "train/loss": 0.08516894280910492,
      "train/loss_affordance": 0.02436654269695282,
      "train/loss_compute_time_ms": 0.32973289489746094,
      "train/loss_risk": 0.02436654269695282,
      "train/loss_structure": 0.03643585741519928
    },
    {
      "epoch": 2.462861610633307,
      "step": 3150,
      "train/forward_time_ms": 4.195051193237305,
      "train/step_time_ms": 4.195461273193359
    },
    {
      "epoch": 2.501954652071931,
      "grad_norm": 0.20861713588237762,
      "learning_rate": 7.498827208756841e-05,
      "loss": 0.0864,
      "step": 3200
    },
    {
      "epoch": 2.501954652071931,
      "step": 3200,
      "train/forward_time_ms": 2.197265625,
      "train/loss": 0.09768054634332657,
      "train/loss_affordance": 0.018744181841611862,
      "train/loss_compute_time_ms": 0.4322528839111328,
      "train/loss_risk": 0.018744181841611862,
      "train/loss_structure": 0.060192182660102844
    },
    {
      "epoch": 2.501954652071931,
      "step": 3200,
      "train/forward_time_ms": 4.161190986633301,
      "train/step_time_ms": 4.161596298217773
    },
    {
      "epoch": 2.541047693510555,
      "grad_norm": 0.2159084677696228,
      "learning_rate": 7.459734167318217e-05,
      "loss": 0.0876,
      "step": 3250
    },
    {
      "epoch": 2.541047693510555,
      "step": 3250,
      "train/forward_time_ms": 2.7582645416259766,
      "train/loss": 0.09793538600206375,
      "train/loss_affordance": 0.02804410457611084,
      "train/loss_compute_time_ms": 0.3101825714111328,
      "train/loss_risk": 0.02804410457611084,
      "train/loss_structure": 0.04184717684984207
    },
    {
      "epoch": 2.541047693510555,
      "step": 3250,
      "train/forward_time_ms": 4.242916107177734,
      "train/step_time_ms": 4.243316650390625
    },
    {
      "epoch": 2.580140734949179,
      "grad_norm": 0.5076453685760498,
      "learning_rate": 7.420641125879594e-05,
      "loss": 0.0858,
      "step": 3300
    },
    {
      "epoch": 2.580140734949179,
      "step": 3300,
      "train/forward_time_ms": 2.187013626098633,
      "train/loss": 0.10173314064741135,
      "train/loss_affordance": 0.03260813653469086,
      "train/loss_compute_time_ms": 0.3039836883544922,
      "train/loss_risk": 0.03260813653469086,
      "train/loss_structure": 0.03651686757802963
    },
    {
      "epoch": 2.580140734949179,
      "step": 3300,
      "train/forward_time_ms": 4.202914237976074,
      "train/step_time_ms": 4.203324317932129
    },
    {
      "epoch": 2.619233776387803,
      "grad_norm": 0.16591320931911469,
      "learning_rate": 7.38154808444097e-05,
      "loss": 0.0873,
      "step": 3350
    },
    {
      "epoch": 2.619233776387803,
      "step": 3350,
      "train/forward_time_ms": 2.290010452270508,
      "train/loss": 0.07413510978221893,
      "train/loss_affordance": 0.01918972097337246,
      "train/loss_compute_time_ms": 0.30493736267089844,
      "train/loss_risk": 0.01918972097337246,
      "train/loss_structure": 0.035755667835474014
    },
    {
      "epoch": 2.619233776387803,
      "step": 3350,
      "train/forward_time_ms": 4.364838600158691,
      "train/step_time_ms": 4.365286827087402
    },
    {
      "epoch": 2.6583268178264268,
      "grad_norm": 0.37660783529281616,
      "learning_rate": 7.342455043002347e-05,
      "loss": 0.0833,
      "step": 3400
    },
    {
      "epoch": 2.6583268178264268,
      "step": 3400,
      "train/forward_time_ms": 2.1851062774658203,
      "train/loss": 0.08032578229904175,
      "train/loss_affordance": 0.025836762972176075,
      "train/loss_compute_time_ms": 0.29468536376953125,
      "train/loss_risk": 0.025836762972176075,
      "train/loss_structure": 0.028652256354689598
    },
    {
      "epoch": 2.6583268178264268,
      "step": 3400,
      "train/forward_time_ms": 4.151263236999512,
      "train/step_time_ms": 4.151625633239746
    },
    {
      "epoch": 2.6974198592650507,
      "grad_norm": 0.5250551700592041,
      "learning_rate": 7.303362001563721e-05,
      "loss": 0.0845,
      "step": 3450
    },
    {
      "epoch": 2.6974198592650507,
      "step": 3450,
      "train/forward_time_ms": 2.1800994873046875,
      "train/loss": 0.07189944386482239,
      "train/loss_affordance": 0.024265890941023827,
      "train/loss_compute_time_ms": 0.293731689453125,
      "train/loss_risk": 0.024265890941023827,
      "train/loss_structure": 0.023367661982774734
    },
    {
      "epoch": 2.6974198592650507,
      "step": 3450,
      "train/forward_time_ms": 4.178323745727539,
      "train/step_time_ms": 4.178738594055176
    },
    {
      "epoch": 2.7365129007036746,
      "grad_norm": 0.25928816199302673,
      "learning_rate": 7.264268960125098e-05,
      "loss": 0.0809,
      "step": 3500
    },
    {
      "epoch": 2.7365129007036746,
      "step": 3500,
      "train/forward_time_ms": 2.5167465209960938,
      "train/loss": 0.07492359727621078,
      "train/loss_affordance": 0.0226134629920125,
      "train/loss_compute_time_ms": 0.3418922424316406,
      "train/loss_risk": 0.0226134629920125,
      "train/loss_structure": 0.029696671292185783
    },
    {
      "epoch": 2.7365129007036746,
      "step": 3500,
      "train/forward_time_ms": 4.168591499328613,
      "train/step_time_ms": 4.1690778732299805
    },
    {
      "epoch": 2.775605942142299,
      "grad_norm": 0.29735898971557617,
      "learning_rate": 7.225175918686474e-05,
      "loss": 0.0846,
      "step": 3550
    },
    {
      "epoch": 2.775605942142299,
      "step": 3550,
      "train/forward_time_ms": 2.4976730346679688,
      "train/loss": 0.08680227398872375,
      "train/loss_affordance": 0.027902694419026375,
      "train/loss_compute_time_ms": 0.3311634063720703,
      "train/loss_risk": 0.027902694419026375,
      "train/loss_structure": 0.030996885150671005
    },
    {
      "epoch": 2.775605942142299,
      "step": 3550,
      "train/forward_time_ms": 4.170632362365723,
      "train/step_time_ms": 4.1710710525512695
    },
    {
      "epoch": 2.8146989835809224,
      "grad_norm": 0.3353678286075592,
      "learning_rate": 7.186082877247851e-05,
      "loss": 0.0814,
      "step": 3600
    },
    {
      "epoch": 2.8146989835809224,
      "step": 3600,
      "train/forward_time_ms": 2.5243759155273438,
      "train/loss": 0.07867219299077988,
      "train/loss_affordance": 0.025250742211937904,
      "train/loss_compute_time_ms": 0.3249645233154297,
      "train/loss_risk": 0.025250742211937904,
      "train/loss_structure": 0.028170708566904068
    },
    {
      "epoch": 2.8146989835809224,
      "step": 3600,
      "train/forward_time_ms": 4.5156145095825195,
      "train/step_time_ms": 4.516086578369141
    },
    {
      "epoch": 2.8537920250195468,
      "grad_norm": 0.12394217401742935,
      "learning_rate": 7.146989835809225e-05,
      "loss": 0.0824,
      "step": 3650
    },
    {
      "epoch": 2.8537920250195468,
      "step": 3650,
      "train/forward_time_ms": 2.755880355834961,
      "train/loss": 0.07607533037662506,
      "train/loss_affordance": 0.02329627051949501,
      "train/loss_compute_time_ms": 0.3256797790527344,
      "train/loss_risk": 0.02329627051949501,
      "train/loss_structure": 0.02948278933763504
    },
    {
      "epoch": 2.8537920250195468,
      "step": 3650,
      "train/forward_time_ms": 4.405827522277832,
      "train/step_time_ms": 4.406290054321289
    },
    {
      "epoch": 2.8928850664581702,
      "grad_norm": 0.40519171953201294,
      "learning_rate": 7.107896794370602e-05,
      "loss": 0.08,
      "step": 3700
    },
    {
      "epoch": 2.8928850664581702,
      "step": 3700,
      "train/forward_time_ms": 2.258777618408203,
      "train/loss": 0.07443686574697495,
      "train/loss_affordance": 0.02570669911801815,
      "train/loss_compute_time_ms": 0.3094673156738281,
      "train/loss_risk": 0.02570669911801815,
      "train/loss_structure": 0.023023467510938644
    },
    {
      "epoch": 2.8928850664581702,
      "step": 3700,
      "train/forward_time_ms": 4.216585159301758,
      "train/step_time_ms": 4.217014312744141
    },
    {
      "epoch": 2.9319781078967946,
      "grad_norm": 0.4279195964336395,
      "learning_rate": 7.068803752931978e-05,
      "loss": 0.0793,
      "step": 3750
    },
    {
      "epoch": 2.9319781078967946,
      "step": 3750,
      "train/forward_time_ms": 2.2547245025634766,
      "train/loss": 0.08757707476615906,
      "train/loss_affordance": 0.02746640518307686,
      "train/loss_compute_time_ms": 0.3008842468261719,
      "train/loss_risk": 0.02746640518307686,
      "train/loss_structure": 0.03264426440000534
    },
    {
      "epoch": 2.9319781078967946,
      "step": 3750,
      "train/forward_time_ms": 4.135532379150391,
      "train/step_time_ms": 4.135932922363281
    },
    {
      "epoch": 2.971071149335418,
      "grad_norm": 0.16443908214569092,
      "learning_rate": 7.029710711493355e-05,
      "loss": 0.0819,
      "step": 3800
    },
    {
      "epoch": 2.971071149335418,
      "step": 3800,
      "train/forward_time_ms": 2.3996829986572266,
      "train/loss": 0.07469154894351959,
      "train/loss_affordance": 0.02694979589432478,
      "train/loss_compute_time_ms": 0.2925395965576172,
      "train/loss_risk": 0.02694979589432478,
      "train/loss_structure": 0.020791957154870033
    },
    {
      "epoch": 2.971071149335418,
      "step": 3800,
      "train/forward_time_ms": 4.217376708984375,
      "train/step_time_ms": 4.217772483825684
    },
    {
      "epoch": 3.0101641907740424,
      "grad_norm": 0.3640737533569336,
      "learning_rate": 6.99061767005473e-05,
      "loss": 0.0758,
      "step": 3850
    },
    {
      "epoch": 3.0101641907740424,
      "step": 3850,
      "train/forward_time_ms": 2.3009777069091797,
      "train/loss": 0.06070123612880707,
      "train/loss_affordance": 0.015841429121792316,
      "train/loss_compute_time_ms": 0.30994415283203125,
      "train/loss_risk": 0.015841429121792316,
      "train/loss_structure": 0.029018377885222435
    },
    {
      "epoch": 3.0101641907740424,
      "step": 3850,
      "train/forward_time_ms": 4.455313682556152,
      "train/step_time_ms": 4.455761909484863
    },
    {
      "epoch": 3.0492572322126663,
      "grad_norm": 0.48934775590896606,
      "learning_rate": 6.951524628616106e-05,
      "loss": 0.0769,
      "step": 3900
    },
    {
      "epoch": 3.0492572322126663,
      "step": 3900,
      "train/forward_time_ms": 2.6702880859375,
      "train/loss": 0.07231353968381882,
      "train/loss_affordance": 0.017976805567741394,
      "train/loss_compute_time_ms": 0.33164024353027344,
      "train/loss_risk": 0.017976805567741394,
      "train/loss_structure": 0.03635992854833603
    },
    {
      "epoch": 3.0492572322126663,
      "step": 3900,
      "train/forward_time_ms": 4.336576461791992,
      "train/step_time_ms": 4.337005615234375
    },
    {
      "epoch": 3.0883502736512902,
      "grad_norm": 0.29787567257881165,
      "learning_rate": 6.912431587177482e-05,
      "loss": 0.0737,
      "step": 3950
    },
    {
      "epoch": 3.0883502736512902,
      "step": 3950,
      "train/forward_time_ms": 2.497434616088867,
      "train/loss": 0.07153556495904922,
      "train/loss_affordance": 0.023312367498874664,
      "train/loss_compute_time_ms": 0.34689903259277344,
      "train/loss_risk": 0.023312367498874664,
      "train/loss_structure": 0.024910829961299896
    },
    {
      "epoch": 3.0883502736512902,
      "step": 3950,
      "train/forward_time_ms": 4.249787330627441,
      "train/step_time_ms": 4.250178337097168
    },
    {
      "epoch": 3.127443315089914,
      "grad_norm": 0.36418044567108154,
      "learning_rate": 6.873338545738859e-05,
      "loss": 0.0763,
      "step": 4000
    },
    {
      "epoch": 3.127443315089914,
      "step": 4000,
      "train/forward_time_ms": 2.695322036743164,
      "train/loss": 0.07704256474971771,
      "train/loss_affordance": 0.01857353374361992,
      "train/loss_compute_time_ms": 0.4062652587890625,
      "train/loss_risk": 0.01857353374361992,
      "train/loss_structure": 0.039895497262477875
    },
    {
      "epoch": 3.127443315089914,
      "step": 4000,
      "train/forward_time_ms": 4.34140682220459,
      "train/step_time_ms": 4.341831207275391
    },
    {
      "epoch": 3.166536356528538,
      "grad_norm": 0.2844928801059723,
      "learning_rate": 6.834245504300235e-05,
      "loss": 0.0741,
      "step": 4050
    },
    {
      "epoch": 3.166536356528538,
      "step": 4050,
      "train/forward_time_ms": 2.4993419647216797,
      "train/loss": 0.07860402762889862,
      "train/loss_affordance": 0.024086106568574905,
      "train/loss_compute_time_ms": 0.3933906555175781,
      "train/loss_risk": 0.024086106568574905,
      "train/loss_structure": 0.03043181449174881
    },
    {
      "epoch": 3.166536356528538,
      "step": 4050,
      "train/forward_time_ms": 4.279975891113281,
      "train/step_time_ms": 4.280414581298828
    },
    {
      "epoch": 3.205629397967162,
      "grad_norm": 0.24847561120986938,
      "learning_rate": 6.795152462861612e-05,
      "loss": 0.0752,
      "step": 4100
    },
    {
      "epoch": 3.205629397967162,
      "step": 4100,
      "train/forward_time_ms": 2.2385120391845703,
      "train/loss": 0.0649784505367279,
      "train/loss_affordance": 0.017479130998253822,
      "train/loss_compute_time_ms": 0.3027915954589844,
      "train/loss_risk": 0.017479130998253822,
      "train/loss_structure": 0.03002018854022026
    },
    {
      "epoch": 3.205629397967162,
      "step": 4100,
      "train/forward_time_ms": 4.48643684387207,
      "train/step_time_ms": 4.486932754516602
    },
    {
      "epoch": 3.244722439405786,
      "grad_norm": 0.1621590107679367,
      "learning_rate": 6.756059421422986e-05,
      "loss": 0.074,
      "step": 4150
    },
    {
      "epoch": 3.244722439405786,
      "step": 4150,
      "train/forward_time_ms": 2.559661865234375,
      "train/loss": 0.07318733632564545,
      "train/loss_affordance": 0.024831602349877357,
      "train/loss_compute_time_ms": 0.35071372985839844,
      "train/loss_risk": 0.024831602349877357,
      "train/loss_structure": 0.023524131625890732
    },
    {
      "epoch": 3.244722439405786,
      "step": 4150,
      "train/forward_time_ms": 4.158425331115723,
      "train/step_time_ms": 4.158816337585449
    },
    {
      "epoch": 3.2838154808444098,
      "grad_norm": 0.37917187809944153,
      "learning_rate": 6.716966379984363e-05,
      "loss": 0.0755,
      "step": 4200
    },
    {
      "epoch": 3.2838154808444098,
      "step": 4200,
      "train/forward_time_ms": 2.34222412109375,
      "train/loss": 0.07720182090997696,
      "train/loss_affordance": 0.02455381490290165,
      "train/loss_compute_time_ms": 0.2999305725097656,
      "train/loss_risk": 0.02455381490290165,
      "train/loss_structure": 0.02809419110417366
    },
    {
      "epoch": 3.2838154808444098,
      "step": 4200,
      "train/forward_time_ms": 4.203486442565918,
      "train/step_time_ms": 4.203968048095703
    },
    {
      "epoch": 3.3229085222830337,
      "grad_norm": 0.28247565031051636,
      "learning_rate": 6.677873338545739e-05,
      "loss": 0.0709,
      "step": 4250
    },
    {
      "epoch": 3.3229085222830337,
      "step": 4250,
      "train/forward_time_ms": 2.6717185974121094,
      "train/loss": 0.08745090663433075,
      "train/loss_affordance": 0.031567628495395184,
      "train/loss_compute_time_ms": 0.3180503845214844,
      "train/loss_risk": 0.031567628495395184,
      "train/loss_structure": 0.024315649643540382
    },
    {
      "epoch": 3.3229085222830337,
      "step": 4250,
      "train/forward_time_ms": 4.204134941101074,
      "train/step_time_ms": 4.204602241516113
    },
    {
      "epoch": 3.3620015637216576,
      "grad_norm": 0.23299117386341095,
      "learning_rate": 6.638780297107116e-05,
      "loss": 0.0775,
      "step": 4300
    },
    {
      "epoch": 3.3620015637216576,
      "step": 4300,
      "train/forward_time_ms": 3.173828125,
      "train/loss": 0.08401226997375488,
      "train/loss_affordance": 0.017540525645017624,
      "train/loss_compute_time_ms": 0.41937828063964844,
      "train/loss_risk": 0.017540525645017624,
      "train/loss_structure": 0.048931218683719635
    },
    {
      "epoch": 3.3620015637216576,
      "step": 4300,
      "train/forward_time_ms": 4.280586242675781,
      "train/step_time_ms": 4.281020164489746
    },
    {
      "epoch": 3.4010946051602815,
      "grad_norm": 0.26896217465400696,
      "learning_rate": 6.59968725566849e-05,
      "loss": 0.0702,
      "step": 4350
    },
    {
      "epoch": 3.4010946051602815,
      "step": 4350,
      "train/forward_time_ms": 2.333402633666992,
      "train/loss": 0.05941902473568916,
      "train/loss_affordance": 0.015222144313156605,
      "train/loss_compute_time_ms": 0.3116130828857422,
      "train/loss_risk": 0.015222144313156605,
      "train/loss_structure": 0.028974736109375954
    },
    {
      "epoch": 3.4010946051602815,
      "step": 4350,
      "train/forward_time_ms": 4.270172119140625,
      "train/step_time_ms": 4.27060604095459
    },
    {
      "epoch": 3.4401876465989054,
      "grad_norm": 0.341098815202713,
      "learning_rate": 6.560594214229867e-05,
      "loss": 0.0715,
      "step": 4400
    },
    {
      "epoch": 3.4401876465989054,
      "step": 4400,
      "train/forward_time_ms": 2.554655075073242,
      "train/loss": 0.07978110015392303,
      "train/loss_affordance": 0.02561886329203844,
      "train/loss_compute_time_ms": 0.3151893615722656,
      "train/loss_risk": 0.02561886329203844,
      "train/loss_structure": 0.028543373569846153
    },
    {
      "epoch": 3.4401876465989054,
      "step": 4400,
      "train/forward_time_ms": 4.198164939880371,
      "train/step_time_ms": 4.198579788208008
    },
    {
      "epoch": 3.4792806880375293,
      "grad_norm": 0.4360896050930023,
      "learning_rate": 6.521501172791243e-05,
      "loss": 0.0706,
      "step": 4450
    },
    {
      "epoch": 3.4792806880375293,
      "step": 4450,
      "train/forward_time_ms": 2.5529861450195312,
      "train/loss": 0.06285793334245682,
      "train/loss_affordance": 0.020301954820752144,
      "train/loss_compute_time_ms": 0.3039836883544922,
      "train/loss_risk": 0.020301954820752144,
      "train/loss_structure": 0.02225402370095253
    },
    {
      "epoch": 3.4792806880375293,
      "step": 4450,
      "train/forward_time_ms": 4.1748809814453125,
      "train/step_time_ms": 4.175276756286621
    },
    {
      "epoch": 3.5183737294761532,
      "grad_norm": 0.18782788515090942,
      "learning_rate": 6.48240813135262e-05,
      "loss": 0.0701,
      "step": 4500
    },
    {
      "epoch": 3.5183737294761532,
      "step": 4500,
      "train/forward_time_ms": 4.399776458740234,
      "train/loss": 0.05843506008386612,
      "train/loss_affordance": 0.023155927192419767,
      "train/loss_compute_time_ms": 0.34427642822265625,
      "train/loss_risk": 0.023155927192419767,
      "train/loss_structure": 0.012123205699026585
    },
    {
      "epoch": 3.5183737294761532,
      "step": 4500,
      "train/forward_time_ms": 4.195399284362793,
      "train/step_time_ms": 4.195761680603027
    },
    {
      "epoch": 3.557466770914777,
      "grad_norm": 0.2957090139389038,
      "learning_rate": 6.443315089913996e-05,
      "loss": 0.0712,
      "step": 4550
    },
    {
      "epoch": 3.557466770914777,
      "step": 4550,
      "train/forward_time_ms": 2.439737319946289,
      "train/loss": 0.0713556557893753,
      "train/loss_affordance": 0.026232989504933357,
      "train/loss_compute_time_ms": 0.3523826599121094,
      "train/loss_risk": 0.026232989504933357,
      "train/loss_structure": 0.01888967677950859
    },
    {
      "epoch": 3.557466770914777,
      "step": 4550,
      "train/forward_time_ms": 4.318819046020508,
      "train/step_time_ms": 4.319257736206055
    },
    {
      "epoch": 3.596559812353401,
      "grad_norm": 0.12968310713768005,
      "learning_rate": 6.404222048475371e-05,
      "loss": 0.0698,
      "step": 4600
    },
    {
      "epoch": 3.596559812353401,
      "step": 4600,
      "train/forward_time_ms": 2.318143844604492,
      "train/loss": 0.05441921949386597,
      "train/loss_affordance": 0.017727671191096306,
      "train/loss_compute_time_ms": 0.3120899200439453,
      "train/loss_risk": 0.017727671191096306,
      "train/loss_structure": 0.018963877111673355
    },
    {
      "epoch": 3.596559812353401,
      "step": 4600,
      "train/forward_time_ms": 4.313554763793945,
      "train/step_time_ms": 4.313955307006836
    },
    {
      "epoch": 3.635652853792025,
      "grad_norm": 0.8859845399856567,
      "learning_rate": 6.365129007036747e-05,
      "loss": 0.0691,
      "step": 4650
    },
    {
      "epoch": 3.635652853792025,
      "step": 4650,
      "train/forward_time_ms": 2.5959014892578125,
      "train/loss": 0.072453573346138,
      "train/loss_affordance": 0.02101114857941866,
      "train/loss_compute_time_ms": 0.3025531768798828,
      "train/loss_risk": 0.02101114857941866,
      "train/loss_structure": 0.030431276187300682
    },
    {
      "epoch": 3.635652853792025,
      "step": 4650,
      "train/forward_time_ms": 4.188117980957031,
      "train/step_time_ms": 4.188575744628906
    },
    {
      "epoch": 3.674745895230649,
      "grad_norm": 0.2791857421398163,
      "learning_rate": 6.326035965598124e-05,
      "loss": 0.0691,
      "step": 4700
    },
    {
      "epoch": 3.674745895230649,
      "step": 4700,
      "train/forward_time_ms": 2.5556087493896484,
      "train/loss": 0.07212921231985092,
      "train/loss_affordance": 0.02258484996855259,
      "train/loss_compute_time_ms": 0.30422210693359375,
      "train/loss_risk": 0.02258484996855259,
      "train/loss_structure": 0.026959512382745743
    },
    {
      "epoch": 3.674745895230649,
      "step": 4700,
      "train/forward_time_ms": 4.191751480102539,
      "train/step_time_ms": 4.192132949829102
    },
    {
      "epoch": 3.713838936669273,
      "grad_norm": 0.14107653498649597,
      "learning_rate": 6.2869429241595e-05,
      "loss": 0.0724,
      "step": 4750
    },
    {
      "epoch": 3.713838936669273,
      "step": 4750,
      "train/forward_time_ms": 2.2962093353271484,
      "train/loss": 0.07618267834186554,
      "train/loss_affordance": 0.024923332035541534,
      "train/loss_compute_time_ms": 0.3151893615722656,
      "train/loss_risk": 0.024923332035541534,
      "train/loss_structure": 0.02633601427078247
    },
    {
      "epoch": 3.713838936669273,
      "step": 4750,
      "train/forward_time_ms": 4.245152473449707,
      "train/step_time_ms": 4.245638847351074
    },
    {
      "epoch": 3.7529319781078967,
      "grad_norm": 0.30225494503974915,
      "learning_rate": 6.247849882720877e-05,
      "loss": 0.0672,
      "step": 4800
    },
    {
      "epoch": 3.7529319781078967,
      "step": 4800,
      "train/forward_time_ms": 2.917051315307617,
      "train/loss": 0.054481737315654755,
      "train/loss_affordance": 0.021075213328003883,
      "train/loss_compute_time_ms": 0.4127025604248047,
      "train/loss_risk": 0.021075213328003883,
      "train/loss_structure": 0.012331310659646988
    },
    {
      "epoch": 3.7529319781078967,
      "step": 4800,
      "train/forward_time_ms": 4.350247383117676,
      "train/step_time_ms": 4.3506574630737305
    },
    {
      "epoch": 3.7920250195465206,
      "grad_norm": 0.21517926454544067,
      "learning_rate": 6.208756841282251e-05,
      "loss": 0.0676,
      "step": 4850
    },
    {
      "epoch": 3.7920250195465206,
      "step": 4850,
      "train/forward_time_ms": 2.1791458129882812,
      "train/loss": 0.07015369087457657,
      "train/loss_affordance": 0.020594730973243713,
      "train/loss_compute_time_ms": 0.30612945556640625,
      "train/loss_risk": 0.020594730973243713,
      "train/loss_structure": 0.028964228928089142
    },
    {
      "epoch": 3.7920250195465206,
      "step": 4850,
      "train/forward_time_ms": 4.1483306884765625,
      "train/step_time_ms": 4.148764610290527
    },
    {
      "epoch": 3.8311180609851445,
      "grad_norm": 0.5391219258308411,
      "learning_rate": 6.169663799843628e-05,
      "loss": 0.0658,
      "step": 4900
    },
    {
      "epoch": 3.8311180609851445,
      "step": 4900,
      "train/forward_time_ms": 2.3736953735351562,
      "train/loss": 0.08057057857513428,
      "train/loss_affordance": 0.025322865694761276,
      "train/loss_compute_time_ms": 0.30350685119628906,
      "train/loss_risk": 0.025322865694761276,
      "train/loss_structure": 0.029924847185611725
    },
    {
      "epoch": 3.8311180609851445,
      "step": 4900,
      "train/forward_time_ms": 4.112558364868164,
      "train/step_time_ms": 4.112992286682129
    },
    {
      "epoch": 3.8702111024237684,
      "grad_norm": 0.37179872393608093,
      "learning_rate": 6.130570758405004e-05,
      "loss": 0.0672,
      "step": 4950
    },
    {
      "epoch": 3.8702111024237684,
      "step": 4950,
      "train/forward_time_ms": 2.2711753845214844,
      "train/loss": 0.05945203825831413,
      "train/loss_affordance": 0.019428144209086895,
      "train/loss_compute_time_ms": 0.3113746643066406,
      "train/loss_risk": 0.019428144209086895,
      "train/loss_structure": 0.020595749840140343
    },
    {
      "epoch": 3.8702111024237684,
      "step": 4950,
      "train/forward_time_ms": 4.279193878173828,
      "train/step_time_ms": 4.279661178588867
    },
    {
      "epoch": 3.9093041438623923,
      "grad_norm": 0.2962939739227295,
      "learning_rate": 6.091477716966381e-05,
      "loss": 0.0661,
      "step": 5000
    },
    {
      "epoch": 3.9093041438623923,
      "step": 5000,
      "train/forward_time_ms": 2.9671192169189453,
      "train/loss": 0.06066391244530678,
      "train/loss_affordance": 0.017109581269323826,
      "train/loss_compute_time_ms": 0.43487548828125,
      "train/loss_risk": 0.017109581269323826,
      "train/loss_structure": 0.026444749906659126
    },
    {
      "epoch": 3.9093041438623923,
      "step": 5000,
      "train/forward_time_ms": 4.3705034255981445,
      "train/step_time_ms": 4.370913505554199
    },
    {
      "epoch": 3.9483971853010162,
      "grad_norm": 0.22754839062690735,
      "learning_rate": 6.052384675527757e-05,
      "loss": 0.0658,
      "step": 5050
    },
    {
      "epoch": 3.9483971853010162,
      "step": 5050,
      "train/forward_time_ms": 2.713918685913086,
      "train/loss": 0.07361160218715668,
      "train/loss_affordance": 0.02935784077271819,
      "train/loss_compute_time_ms": 0.4813671112060547,
      "train/loss_risk": 0.02935784077271819,
      "train/loss_structure": 0.014895920641720295
    },
    {
      "epoch": 3.9483971853010162,
      "step": 5050,
      "train/forward_time_ms": 4.316511154174805,
      "train/step_time_ms": 4.3169450759887695
    },
    {
      "epoch": 3.9874902267396406,
      "grad_norm": 0.35573166608810425,
      "learning_rate": 6.013291634089132e-05,
      "loss": 0.0655,
      "step": 5100
    },
    {
      "epoch": 3.9874902267396406,
      "step": 5100,
      "train/forward_time_ms": 2.002716064453125,
      "train/loss": 0.05706898495554924,
      "train/loss_affordance": 0.01955772005021572,
      "train/loss_compute_time_ms": 0.3020763397216797,
      "train/loss_risk": 0.01955772005021572,
      "train/loss_structure": 0.017953544855117798
    },
    {
      "epoch": 3.9874902267396406,
      "step": 5100,
      "train/forward_time_ms": 4.199404716491699,
      "train/step_time_ms": 4.199824333190918
    },
    {
      "epoch": 4.026583268178264,
      "grad_norm": 0.17229795455932617,
      "learning_rate": 5.9741985926505086e-05,
      "loss": 0.0657,
      "step": 5150
    },
    {
      "epoch": 4.026583268178264,
      "step": 5150,
      "train/forward_time_ms": 2.2668838500976562,
      "train/loss": 0.06501060724258423,
      "train/loss_affordance": 0.021913999691605568,
      "train/loss_compute_time_ms": 0.339508056640625,
      "train/loss_risk": 0.021913999691605568,
      "train/loss_structure": 0.021182607859373093
    },
    {
      "epoch": 4.026583268178264,
      "step": 5150,
      "train/forward_time_ms": 4.229698181152344,
      "train/step_time_ms": 4.230170249938965
    },
    {
      "epoch": 4.065676309616888,
      "grad_norm": 0.1910075545310974,
      "learning_rate": 5.935105551211885e-05,
      "loss": 0.0661,
      "step": 5200
    },
    {
      "epoch": 4.065676309616888,
      "step": 5200,
      "train/forward_time_ms": 2.401113510131836,
      "train/loss": 0.057146281003952026,
      "train/loss_affordance": 0.019286266528069973,
      "train/loss_compute_time_ms": 0.28777122497558594,
      "train/loss_risk": 0.019286266528069973,
      "train/loss_structure": 0.01857374794781208
    },
    {
      "epoch": 4.065676309616888,
      "step": 5200,
      "train/forward_time_ms": 4.116635322570801,
      "train/step_time_ms": 4.117093086242676
    },
    {
      "epoch": 4.104769351055512,
      "grad_norm": 0.1522655338048935,
      "learning_rate": 5.896012509773261e-05,
      "loss": 0.0638,
      "step": 5250
    },
    {
      "epoch": 4.104769351055512,
      "step": 5250,
      "train/forward_time_ms": 2.645254135131836,
      "train/loss": 0.07028757780790329,
      "train/loss_affordance": 0.027963769622147083,
      "train/loss_compute_time_ms": 0.30517578125,
      "train/loss_risk": 0.027963769622147083,
      "train/loss_structure": 0.014360038563609123
    },
    {
      "epoch": 4.104769351055512,
      "step": 5250,
      "train/forward_time_ms": 4.183635711669922,
      "train/step_time_ms": 4.184050559997559
    },
    {
      "epoch": 4.143862392494136,
      "grad_norm": 0.25500062108039856,
      "learning_rate": 5.856919468334636e-05,
      "loss": 0.0648,
      "step": 5300
    },
    {
      "epoch": 4.143862392494136,
      "step": 5300,
      "train/forward_time_ms": 2.2504329681396484,
      "train/loss": 0.06950689107179642,
      "train/loss_affordance": 0.02557371463626623,
      "train/loss_compute_time_ms": 0.30231475830078125,
      "train/loss_risk": 0.02557371463626623,
      "train/loss_structure": 0.018359461799263954
    },
    {
      "epoch": 4.143862392494136,
      "step": 5300,
      "train/forward_time_ms": 4.384894371032715,
      "train/step_time_ms": 4.385356903076172
    },
    {
      "epoch": 4.18295543393276,
      "grad_norm": 0.1513317972421646,
      "learning_rate": 5.817826426896013e-05,
      "loss": 0.0676,
      "step": 5350
    },
    {
      "epoch": 4.18295543393276,
      "step": 5350,
      "train/forward_time_ms": 2.3193359375,
      "train/loss": 0.061217088252305984,
      "train/loss_affordance": 0.0196059700101614,
      "train/loss_compute_time_ms": 0.3044605255126953,
      "train/loss_risk": 0.0196059700101614,
      "train/loss_structure": 0.022005148231983185
    },
    {
      "epoch": 4.18295543393276,
      "step": 5350,
      "train/forward_time_ms": 4.133620262145996,
      "train/step_time_ms": 4.134025573730469
    },
    {
      "epoch": 4.222048475371384,
      "grad_norm": 0.1232995092868805,
      "learning_rate": 5.778733385457389e-05,
      "loss": 0.0652,
      "step": 5400
    },
    {
      "epoch": 4.222048475371384,
      "step": 5400,
      "train/forward_time_ms": 2.373933792114258,
      "train/loss": 0.06881503760814667,
      "train/loss_affordance": 0.020367191173136234,
      "train/loss_compute_time_ms": 0.29397010803222656,
      "train/loss_risk": 0.020367191173136234,
      "train/loss_structure": 0.0280806552618742
    },
    {
      "epoch": 4.222048475371384,
      "step": 5400,
      "train/forward_time_ms": 4.156680107116699,
      "train/step_time_ms": 4.157085418701172
    },
    {
      "epoch": 4.2611415168100075,
      "grad_norm": 0.447008341550827,
      "learning_rate": 5.7396403440187654e-05,
      "loss": 0.0619,
      "step": 5450
    },
    {
      "epoch": 4.2611415168100075,
      "step": 5450,
      "train/forward_time_ms": 2.302885055541992,
      "train/loss": 0.07317312061786652,
      "train/loss_affordance": 0.024009927175939083,
      "train/loss_compute_time_ms": 0.3943443298339844,
      "train/loss_risk": 0.024009927175939083,
      "train/loss_structure": 0.02515326626598835
    },
    {
      "epoch": 4.2611415168100075,
      "step": 5450,
      "train/forward_time_ms": 4.233736991882324,
      "train/step_time_ms": 4.234185218811035
    },
    {
      "epoch": 4.300234558248632,
      "grad_norm": 0.42522546648979187,
      "learning_rate": 5.700547302580142e-05,
      "loss": 0.0622,
      "step": 5500
    },
    {
      "epoch": 4.300234558248632,
      "step": 5500,
      "train/forward_time_ms": 2.3479461669921875,
      "train/loss": 0.05989999324083328,
      "train/loss_affordance": 0.01916427630931139,
      "train/loss_compute_time_ms": 0.3364086151123047,
      "train/loss_risk": 0.01916427630931139,
      "train/loss_structure": 0.021571440622210503
    },
    {
      "epoch": 4.300234558248632,
      "step": 5500,
      "train/forward_time_ms": 4.235897064208984,
      "train/step_time_ms": 4.236364364624023
    },
    {
      "epoch": 4.339327599687255,
      "grad_norm": 0.2786698043346405,
      "learning_rate": 5.661454261141517e-05,
      "loss": 0.0611,
      "step": 5550
    },
    {
      "epoch": 4.339327599687255,
      "step": 5550,
      "train/forward_time_ms": 2.323627471923828,
      "train/loss": 0.04351053014397621,
      "train/loss_affordance": 0.011566204950213432,
      "train/loss_compute_time_ms": 0.28967857360839844,
      "train/loss_risk": 0.011566204950213432,
      "train/loss_structure": 0.020378120243549347
    },
    {
      "epoch": 4.339327599687255,
      "step": 5550,
      "train/forward_time_ms": 4.254260063171387,
      "train/step_time_ms": 4.254698753356934
    },
    {
      "epoch": 4.37842064112588,
      "grad_norm": 0.15736091136932373,
      "learning_rate": 5.622361219702893e-05,
      "loss": 0.0656,
      "step": 5600
    },
    {
      "epoch": 4.37842064112588,
      "step": 5600,
      "train/forward_time_ms": 2.9850006103515625,
      "train/loss": 0.04903879016637802,
      "train/loss_affordance": 0.017165700905025005,
      "train/loss_compute_time_ms": 0.33855438232421875,
      "train/loss_risk": 0.017165700905025005,
      "train/loss_structure": 0.01470738835632801
    },
    {
      "epoch": 4.37842064112588,
      "step": 5600,
      "train/forward_time_ms": 4.153780937194824,
      "train/step_time_ms": 4.154176712036133
    },
    {
      "epoch": 4.417513682564503,
      "grad_norm": 0.23957443237304688,
      "learning_rate": 5.5832681782642695e-05,
      "loss": 0.0626,
      "step": 5650
    },
    {
      "epoch": 4.417513682564503,
      "step": 5650,
      "train/forward_time_ms": 2.424955368041992,
      "train/loss": 0.056401025503873825,
      "train/loss_affordance": 0.01906595379114151,
      "train/loss_compute_time_ms": 0.2961158752441406,
      "train/loss_risk": 0.01906595379114151,
      "train/loss_structure": 0.018269117921590805
    },
    {
      "epoch": 4.417513682564503,
      "step": 5650,
      "train/forward_time_ms": 4.248323440551758,
      "train/step_time_ms": 4.2487382888793945
    },
    {
      "epoch": 4.4566067240031275,
      "grad_norm": 0.34261584281921387,
      "learning_rate": 5.544175136825646e-05,
      "loss": 0.0616,
      "step": 5700
    },
    {
      "epoch": 4.4566067240031275,
      "step": 5700,
      "train/forward_time_ms": 2.4170875549316406,
      "train/loss": 0.04570383578538895,
      "train/loss_affordance": 0.015497777611017227,
      "train/loss_compute_time_ms": 0.3829002380371094,
      "train/loss_risk": 0.015497777611017227,
      "train/loss_structure": 0.014708280563354492
    },
    {
      "epoch": 4.4566067240031275,
      "step": 5700,
      "train/forward_time_ms": 4.363980293273926,
      "train/step_time_ms": 4.3643999099731445
    },
    {
      "epoch": 4.495699765441751,
      "grad_norm": 0.2500469386577606,
      "learning_rate": 5.505082095387022e-05,
      "loss": 0.0597,
      "step": 5750
    },
    {
      "epoch": 4.495699765441751,
      "step": 5750,
      "train/forward_time_ms": 2.0117759704589844,
      "train/loss": 0.0640353411436081,
      "train/loss_affordance": 0.019957789219915867,
      "train/loss_compute_time_ms": 0.2582073211669922,
      "train/loss_risk": 0.019957789219915867,
      "train/loss_structure": 0.02411976270377636
    },
    {
      "epoch": 4.495699765441751,
      "step": 5750,
      "train/forward_time_ms": 4.164752960205078,
      "train/step_time_ms": 4.165172576904297
    },
    {
      "epoch": 4.534792806880375,
      "grad_norm": 0.32304003834724426,
      "learning_rate": 5.465989053948397e-05,
      "loss": 0.0633,
      "step": 5800
    },
    {
      "epoch": 4.534792806880375,
      "step": 5800,
      "train/forward_time_ms": 2.625703811645508,
      "train/loss": 0.062157005071640015,
      "train/loss_affordance": 0.019573653116822243,
      "train/loss_compute_time_ms": 0.2720355987548828,
      "train/loss_risk": 0.019573653116822243,
      "train/loss_structure": 0.02300969883799553
    },
    {
      "epoch": 4.534792806880375,
      "step": 5800,
      "train/forward_time_ms": 4.354720115661621,
      "train/step_time_ms": 4.355177879333496
    },
    {
      "epoch": 4.573885848319,
      "grad_norm": 0.3360392451286316,
      "learning_rate": 5.4268960125097736e-05,
      "loss": 0.059,
      "step": 5850
    },
    {
      "epoch": 4.573885848319,
      "step": 5850,
      "train/forward_time_ms": 2.586841583251953,
      "train/loss": 0.0731922835111618,
      "train/loss_affordance": 0.022925322875380516,
      "train/loss_compute_time_ms": 0.34236907958984375,
      "train/loss_risk": 0.022925322875380516,
      "train/loss_structure": 0.027341637760400772
    },
    {
      "epoch": 4.573885848319,
      "step": 5850,
      "train/forward_time_ms": 4.168753623962402,
      "train/step_time_ms": 4.1692304611206055
    },
    {
      "epoch": 4.612978889757623,
      "grad_norm": 0.11695884168148041,
      "learning_rate": 5.38780297107115e-05,
      "loss": 0.0644,
      "step": 5900
    },
    {
      "epoch": 4.612978889757623,
      "step": 5900,
      "train/forward_time_ms": 2.8734207153320312,
      "train/loss": 0.06905782222747803,
      "train/loss_affordance": 0.01921004243195057,
      "train/loss_compute_time_ms": 0.33974647521972656,
      "train/loss_risk": 0.01921004243195057,
      "train/loss_structure": 0.03063773736357689
    },
    {
      "epoch": 4.612978889757623,
      "step": 5900,
      "train/forward_time_ms": 4.214911460876465,
      "train/step_time_ms": 4.215331077575684
    },
    {
      "epoch": 4.652071931196247,
      "grad_norm": 0.39430907368659973,
      "learning_rate": 5.348709929632526e-05,
      "loss": 0.0614,
      "step": 5950
    },
    {
      "epoch": 4.652071931196247,
      "step": 5950,
      "train/forward_time_ms": 2.7408599853515625,
      "train/loss": 0.049026090651750565,
      "train/loss_affordance": 0.015323268249630928,
      "train/loss_compute_time_ms": 0.30684471130371094,
      "train/loss_risk": 0.015323268249630928,
      "train/loss_structure": 0.01837955415248871
    },
    {
      "epoch": 4.652071931196247,
      "step": 5950,
      "train/forward_time_ms": 4.064536094665527,
      "train/step_time_ms": 4.064898490905762
    },
    {
      "epoch": 4.691164972634871,
      "grad_norm": 0.24003718793392181,
      "learning_rate": 5.309616888193901e-05,
      "loss": 0.0607,
      "step": 6000
    },
    {
      "epoch": 4.691164972634871,
      "step": 6000,
      "train/forward_time_ms": 2.382993698120117,
      "train/loss": 0.053516216576099396,
      "train/loss_affordance": 0.01580799277871847,
      "train/loss_compute_time_ms": 0.3750324249267578,
      "train/loss_risk": 0.01580799277871847,
      "train/loss_structure": 0.021900231018662453
    },
    {
      "epoch": 4.691164972634871,
      "step": 6000,
      "train/forward_time_ms": 4.1551971435546875,
      "train/step_time_ms": 4.155588150024414
    },
    {
      "epoch": 4.730258014073495,
      "grad_norm": 0.35873937606811523,
      "learning_rate": 5.270523846755278e-05,
      "loss": 0.0611,
      "step": 6050
    },
    {
      "epoch": 4.730258014073495,
      "step": 6050,
      "train/forward_time_ms": 2.7608871459960938,
      "train/loss": 0.05664868652820587,
      "train/loss_affordance": 0.02150370180606842,
      "train/loss_compute_time_ms": 0.4477500915527344,
      "train/loss_risk": 0.02150370180606842,
      "train/loss_structure": 0.01364128291606903
    },
    {
      "epoch": 4.730258014073495,
      "step": 6050,
      "train/forward_time_ms": 4.507136344909668,
      "train/step_time_ms": 4.507541656494141
    },
    {
      "epoch": 4.769351055512119,
      "grad_norm": 0.19352008402347565,
      "learning_rate": 5.231430805316654e-05,
      "loss": 0.0574,
      "step": 6100
    },
    {
      "epoch": 4.769351055512119,
      "step": 6100,
      "train/forward_time_ms": 2.5153160095214844,
      "train/loss": 0.0805158019065857,
      "train/loss_affordance": 0.028849623166024685,
      "train/loss_compute_time_ms": 0.3752708435058594,
      "train/loss_risk": 0.028849623166024685,
      "train/loss_structure": 0.022816555574536324
    },
    {
      "epoch": 4.769351055512119,
      "step": 6100,
      "train/forward_time_ms": 4.504671096801758,
      "train/step_time_ms": 4.505186080932617
    },
    {
      "epoch": 4.808444096950743,
      "grad_norm": 0.3773784041404724,
      "learning_rate": 5.1923377638780304e-05,
      "loss": 0.0586,
      "step": 6150
    },
    {
      "epoch": 4.808444096950743,
      "step": 6150,
      "train/forward_time_ms": 2.3484230041503906,
      "train/loss": 0.06262391805648804,
      "train/loss_affordance": 0.022394336760044098,
      "train/loss_compute_time_ms": 0.2760887145996094,
      "train/loss_risk": 0.022394336760044098,
      "train/loss_structure": 0.01783524453639984
    },
    {
      "epoch": 4.808444096950743,
      "step": 6150,
      "train/forward_time_ms": 4.390373229980469,
      "train/step_time_ms": 4.3907928466796875
    },
    {
      "epoch": 4.847537138389367,
      "grad_norm": 0.28833335638046265,
      "learning_rate": 5.153244722439407e-05,
      "loss": 0.0611,
      "step": 6200
    },
    {
      "epoch": 4.847537138389367,
      "step": 6200,
      "train/forward_time_ms": 2.9146671295166016,
      "train/loss": 0.052631013095378876,
      "train/loss_affordance": 0.018647825345396996,
      "train/loss_compute_time_ms": 0.3466606140136719,
      "train/loss_risk": 0.018647825345396996,
      "train/loss_structure": 0.015335362404584885
    },
    {
      "epoch": 4.847537138389367,
      "step": 6200,
      "train/forward_time_ms": 4.225831031799316,
      "train/step_time_ms": 4.226217269897461
    },
    {
      "epoch": 4.886630179827991,
      "grad_norm": 0.16913114488124847,
      "learning_rate": 5.114151681000782e-05,
      "loss": 0.0604,
      "step": 6250
    },
    {
      "epoch": 4.886630179827991,
      "step": 6250,
      "train/forward_time_ms": 2.3543834686279297,
      "train/loss": 0.09739216417074203,
      "train/loss_affordance": 0.02982821874320507,
      "train/loss_compute_time_ms": 0.33974647521972656,
      "train/loss_risk": 0.02982821874320507,
      "train/loss_structure": 0.037735726684331894
    },
    {
      "epoch": 4.886630179827991,
      "step": 6250,
      "train/forward_time_ms": 4.31612491607666,
      "train/step_time_ms": 4.316563606262207
    },
    {
      "epoch": 4.925723221266614,
      "grad_norm": 0.20214052498340607,
      "learning_rate": 5.075058639562158e-05,
      "loss": 0.0587,
      "step": 6300
    },
    {
      "epoch": 4.925723221266614,
      "step": 6300,
      "train/forward_time_ms": 2.7132034301757812,
      "train/loss": 0.06840039044618607,
      "train/loss_affordance": 0.025748852640390396,
      "train/loss_compute_time_ms": 0.3612041473388672,
      "train/loss_risk": 0.025748852640390396,
      "train/loss_structure": 0.016902685165405273
    },
    {
      "epoch": 4.925723221266614,
      "step": 6300,
      "train/forward_time_ms": 4.4396162033081055,
      "train/step_time_ms": 4.4400787353515625
    },
    {
      "epoch": 4.964816262705239,
      "grad_norm": 0.28188079595565796,
      "learning_rate": 5.0359655981235345e-05,
      "loss": 0.057,
      "step": 6350
    },
    {
      "epoch": 4.964816262705239,
      "step": 6350,
      "train/forward_time_ms": 2.216339111328125,
      "train/loss": 0.061509378254413605,
      "train/loss_affordance": 0.021509867161512375,
      "train/loss_compute_time_ms": 0.30803680419921875,
      "train/loss_risk": 0.021509867161512375,
      "train/loss_structure": 0.018489643931388855
    },
    {
      "epoch": 4.964816262705239,
      "step": 6350,
      "train/forward_time_ms": 4.270358085632324,
      "train/step_time_ms": 4.270782470703125
    },
    {
      "epoch": 5.003909304143862,
      "grad_norm": 0.3685058355331421,
      "learning_rate": 4.99687255668491e-05,
      "loss": 0.061,
      "step": 6400
    },
    {
      "epoch": 5.003909304143862,
      "step": 6400,
      "train/forward_time_ms": 2.641916275024414,
      "train/loss": 0.05777783691883087,
      "train/loss_affordance": 0.019901606254279613,
      "train/loss_compute_time_ms": 0.3204345703125,
      "train/loss_risk": 0.019901606254279613,
      "train/loss_structure": 0.017974624410271645
    },
    {
      "epoch": 5.003909304143862,
      "step": 6400,
      "train/forward_time_ms": 4.291205406188965,
      "train/step_time_ms": 4.2916059494018555
    },
    {
      "epoch": 5.043002345582487,
      "grad_norm": 0.1774817705154419,
      "learning_rate": 4.9577795152462865e-05,
      "loss": 0.059,
      "step": 6450
    },
    {
      "epoch": 5.043002345582487,
      "step": 6450,
      "train/forward_time_ms": 2.637624740600586,
      "train/loss": 0.04981130734086037,
      "train/loss_affordance": 0.015151253901422024,
      "train/loss_compute_time_ms": 0.3037452697753906,
      "train/loss_risk": 0.015151253901422024,
      "train/loss_structure": 0.01950879953801632
    },
    {
      "epoch": 5.043002345582487,
      "step": 6450,
      "train/forward_time_ms": 4.2290496826171875,
      "train/step_time_ms": 4.229435920715332
    },
    {
      "epoch": 5.08209538702111,
      "grad_norm": 0.40735265612602234,
      "learning_rate": 4.918686473807663e-05,
      "loss": 0.0564,
      "step": 6500
    },
    {
      "epoch": 5.08209538702111,
      "step": 6500,
      "train/forward_time_ms": 3.632783889770508,
      "train/loss": 0.0744747593998909,
      "train/loss_affordance": 0.025117136538028717,
      "train/loss_compute_time_ms": 0.5242824554443359,
      "train/loss_risk": 0.025117136538028717,
      "train/loss_structure": 0.024240486323833466
    },
    {
      "epoch": 5.08209538702111,
      "step": 6500,
      "train/forward_time_ms": 4.5233964920043945,
      "train/step_time_ms": 4.523873329162598
    },
    {
      "epoch": 5.121188428459734,
      "grad_norm": 0.21162696182727814,
      "learning_rate": 4.8795934323690386e-05,
      "loss": 0.0595,
      "step": 6550
    },
    {
      "epoch": 5.121188428459734,
      "step": 6550,
      "train/forward_time_ms": 2.2077560424804688,
      "train/loss": 0.041300732642412186,
      "train/loss_affordance": 0.011912614107131958,
      "train/loss_compute_time_ms": 0.3037452697753906,
      "train/loss_risk": 0.011912614107131958,
      "train/loss_structure": 0.01747550442814827
    },
    {
      "epoch": 5.121188428459734,
      "step": 6550,
      "train/forward_time_ms": 4.286870956420898,
      "train/step_time_ms": 4.287290573120117
    },
    {
      "epoch": 5.160281469898358,
      "grad_norm": 0.1823287010192871,
      "learning_rate": 4.840500390930415e-05,
      "loss": 0.0555,
      "step": 6600
    },
    {
      "epoch": 5.160281469898358,
      "step": 6600,
      "train/forward_time_ms": 2.7151107788085938,
      "train/loss": 0.06562094390392303,
      "train/loss_affordance": 0.020396633073687553,
      "train/loss_compute_time_ms": 0.32067298889160156,
      "train/loss_risk": 0.020396633073687553,
      "train/loss_structure": 0.024827677756547928
    },
    {
      "epoch": 5.160281469898358,
      "step": 6600,
      "train/forward_time_ms": 4.369516372680664,
      "train/step_time_ms": 4.369940757751465
    },
    {
      "epoch": 5.199374511336982,
      "grad_norm": 0.2695768475532532,
      "learning_rate": 4.8014073494917906e-05,
      "loss": 0.0572,
      "step": 6650
    },
    {
      "epoch": 5.199374511336982,
      "step": 6650,
      "train/forward_time_ms": 2.2885799407958984,
      "train/loss": 0.0570334792137146,
      "train/loss_affordance": 0.022125558461993933,
      "train/loss_compute_time_ms": 0.35309791564941406,
      "train/loss_risk": 0.022125558461993933,
      "train/loss_structure": 0.012782362289726734
    },
    {
      "epoch": 5.199374511336982,
      "step": 6650,
      "train/forward_time_ms": 4.304614067077637,
      "train/step_time_ms": 4.305024147033691
    },
    {
      "epoch": 5.238467552775606,
      "grad_norm": 0.19043999910354614,
      "learning_rate": 4.762314308053167e-05,
      "loss": 0.0585,
      "step": 6700
    },
    {
      "epoch": 5.238467552775606,
      "step": 6700,
      "train/forward_time_ms": 2.2428035736083984,
      "train/loss": 0.08117030560970306,
      "train/loss_affordance": 0.026903102174401283,
      "train/loss_compute_time_ms": 0.3159046173095703,
      "train/loss_risk": 0.026903102174401283,
      "train/loss_structure": 0.027364101260900497
    },
    {
      "epoch": 5.238467552775606,
      "step": 6700,
      "train/forward_time_ms": 4.171137809753418,
      "train/step_time_ms": 4.171590805053711
    },
    {
      "epoch": 5.27756059421423,
      "grad_norm": 0.20459918677806854,
      "learning_rate": 4.723221266614543e-05,
      "loss": 0.0576,
      "step": 6750
    },
    {
      "epoch": 5.27756059421423,
      "step": 6750,
      "train/forward_time_ms": 2.427339553833008,
      "train/loss": 0.05056314915418625,
      "train/loss_affordance": 0.016811455599963665,
      "train/loss_compute_time_ms": 0.3044605255126953,
      "train/loss_risk": 0.016811455599963665,
      "train/loss_structure": 0.01694023795425892
    },
    {
      "epoch": 5.27756059421423,
      "step": 6750,
      "train/forward_time_ms": 4.481267929077148,
      "train/step_time_ms": 4.4817352294921875
    },
    {
      "epoch": 5.3166536356528535,
      "grad_norm": 0.1921604722738266,
      "learning_rate": 4.684128225175919e-05,
      "loss": 0.0554,
      "step": 6800
    },
    {
      "epoch": 5.3166536356528535,
      "step": 6800,
      "train/forward_time_ms": 2.5854110717773438,
      "train/loss": 0.04358931630849838,
      "train/loss_affordance": 0.013280038721859455,
      "train/loss_compute_time_ms": 0.3476142883300781,
      "train/loss_risk": 0.013280038721859455,
      "train/loss_structure": 0.017029238864779472
    },
    {
      "epoch": 5.3166536356528535,
      "step": 6800,
      "train/forward_time_ms": 4.343652725219727,
      "train/step_time_ms": 4.344062805175781
    },
    {
      "epoch": 5.355746677091478,
      "grad_norm": 0.22310441732406616,
      "learning_rate": 4.6450351837372954e-05,
      "loss": 0.0592,
      "step": 6850
    },
    {
      "epoch": 5.355746677091478,
      "step": 6850,
      "train/forward_time_ms": 2.3221969604492188,
      "train/loss": 0.06323010474443436,
      "train/loss_affordance": 0.0215195519849658,
      "train/loss_compute_time_ms": 0.29730796813964844,
      "train/loss_risk": 0.0215195519849658,
      "train/loss_structure": 0.020191000774502754
    },
    {
      "epoch": 5.355746677091478,
      "step": 6850,
      "train/forward_time_ms": 4.162859916687012,
      "train/step_time_ms": 4.163322448730469
    },
    {
      "epoch": 5.394839718530101,
      "grad_norm": 0.1707947999238968,
      "learning_rate": 4.605942142298671e-05,
      "loss": 0.0546,
      "step": 6900
    },
    {
      "epoch": 5.394839718530101,
      "step": 6900,
      "train/forward_time_ms": 2.162933349609375,
      "train/loss": 0.05561542510986328,
      "train/loss_affordance": 0.02428351854905486,
      "train/loss_compute_time_ms": 0.3275871276855469,
      "train/loss_risk": 0.02428351854905486,
      "train/loss_structure": 0.007048388011753559
    },
    {
      "epoch": 5.394839718530101,
      "step": 6900,
      "train/forward_time_ms": 4.163961410522461,
      "train/step_time_ms": 4.164443016052246
    },
    {
      "epoch": 5.433932759968726,
      "grad_norm": 0.2817240059375763,
      "learning_rate": 4.5668491008600475e-05,
      "loss": 0.0554,
      "step": 6950
    },
    {
      "epoch": 5.433932759968726,
      "step": 6950,
      "train/forward_time_ms": 2.218008041381836,
      "train/loss": 0.04462893307209015,
      "train/loss_affordance": 0.014551274012774229,
      "train/loss_compute_time_ms": 0.30231475830078125,
      "train/loss_risk": 0.014551274012774229,
      "train/loss_structure": 0.01552638504654169
    },
    {
      "epoch": 5.433932759968726,
      "step": 6950,
      "train/forward_time_ms": 4.238033294677734,
      "train/step_time_ms": 4.238529205322266
    },
    {
      "epoch": 5.473025801407349,
      "grad_norm": 0.1505056768655777,
      "learning_rate": 4.527756059421423e-05,
      "loss": 0.0581,
      "step": 7000
    },
    {
      "epoch": 5.473025801407349,
      "step": 7000,
      "train/forward_time_ms": 2.8867721557617188,
      "train/loss": 0.045326072722673416,
      "train/loss_affordance": 0.013664577156305313,
      "train/loss_compute_time_ms": 0.45299530029296875,
      "train/loss_risk": 0.013664577156305313,
      "train/loss_structure": 0.01799691841006279
    },
    {
      "epoch": 5.473025801407349,
      "step": 7000,
      "train/forward_time_ms": 4.4695234298706055,
      "train/step_time_ms": 4.4699811935424805
    },
    {
      "epoch": 5.5121188428459735,
      "grad_norm": 0.18691571056842804,
      "learning_rate": 4.4886630179827995e-05,
      "loss": 0.0561,
      "step": 7050
    },
    {
      "epoch": 5.5121188428459735,
      "step": 7050,
      "train/forward_time_ms": 2.3889541625976562,
      "train/loss": 0.05174548923969269,
      "train/loss_affordance": 0.01815174287185073,
      "train/loss_compute_time_ms": 0.3025531768798828,
      "train/loss_risk": 0.01815174287185073,
      "train/loss_structure": 0.01544200349599123
    },
    {
      "epoch": 5.5121188428459735,
      "step": 7050,
      "train/forward_time_ms": 4.262862205505371,
      "train/step_time_ms": 4.263300895690918
    },
    {
      "epoch": 5.551211884284597,
      "grad_norm": 0.27700504660606384,
      "learning_rate": 4.449569976544176e-05,
      "loss": 0.0593,
      "step": 7100
    },
    {
      "epoch": 5.551211884284597,
      "step": 7100,
      "train/forward_time_ms": 2.0787715911865234,
      "train/loss": 0.060001932084560394,
      "train/loss_affordance": 0.017803742550313473,
      "train/loss_compute_time_ms": 0.2803802490234375,
      "train/loss_risk": 0.017803742550313473,
      "train/loss_structure": 0.02439444698393345
    },
    {
      "epoch": 5.551211884284597,
      "step": 7100,
      "train/forward_time_ms": 4.176979064941406,
      "train/step_time_ms": 4.177346229553223
    },
    {
      "epoch": 5.590304925723221,
      "grad_norm": 0.1497027426958084,
      "learning_rate": 4.4104769351055516e-05,
      "loss": 0.0546,
      "step": 7150
    },
    {
      "epoch": 5.590304925723221,
      "step": 7150,
      "train/forward_time_ms": 2.371549606323242,
      "train/loss": 0.06272060424089432,
      "train/loss_affordance": 0.025617042556405067,
      "train/loss_compute_time_ms": 0.3237724304199219,
      "train/loss_risk": 0.025617042556405067,
      "train/loss_structure": 0.011486519128084183
    },
    {
      "epoch": 5.590304925723221,
      "step": 7150,
      "train/forward_time_ms": 4.245877265930176,
      "train/step_time_ms": 4.2462873458862305
    },
    {
      "epoch": 5.629397967161845,
      "grad_norm": 0.3099824786186218,
      "learning_rate": 4.371383893666928e-05,
      "loss": 0.0609,
      "step": 7200
    },
    {
      "epoch": 5.629397967161845,
      "step": 7200,
      "train/forward_time_ms": 2.527475357055664,
      "train/loss": 0.054005932062864304,
      "train/loss_affordance": 0.01860402524471283,
      "train/loss_compute_time_ms": 0.4353523254394531,
      "train/loss_risk": 0.01860402524471283,
      "train/loss_structure": 0.016797881573438644
    },
    {
      "epoch": 5.629397967161845,
      "step": 7200,
      "train/forward_time_ms": 4.214959144592285,
      "train/step_time_ms": 4.215383529663086
    },
    {
      "epoch": 5.668491008600469,
      "grad_norm": 0.3103283941745758,
      "learning_rate": 4.3322908522283036e-05,
      "loss": 0.0558,
      "step": 7250
    },
    {
      "epoch": 5.668491008600469,
      "step": 7250,
      "train/forward_time_ms": 2.061128616333008,
      "train/loss": 0.07361504435539246,
      "train/loss_affordance": 0.024770627729594707,
      "train/loss_compute_time_ms": 0.29540061950683594,
      "train/loss_risk": 0.024770627729594707,
      "train/loss_structure": 0.02407378889620304
    },
    {
      "epoch": 5.668491008600469,
      "step": 7250,
      "train/forward_time_ms": 4.395961761474609,
      "train/step_time_ms": 4.396405220031738
    },
    {
      "epoch": 5.7075840500390935,
      "grad_norm": 0.7108017802238464,
      "learning_rate": 4.29319781078968e-05,
      "loss": 0.0559,
      "step": 7300
    },
    {
      "epoch": 5.7075840500390935,
      "step": 7300,
      "train/forward_time_ms": 2.470731735229492,
      "train/loss": 0.06598563492298126,
      "train/loss_affordance": 0.022912248969078064,
      "train/loss_compute_time_ms": 0.4324913024902344,
      "train/loss_risk": 0.022912248969078064,
      "train/loss_structure": 0.020161136984825134
    },
    {
      "epoch": 5.7075840500390935,
      "step": 7300,
      "train/forward_time_ms": 4.171237945556641,
      "train/step_time_ms": 4.171581268310547
    },
    {
      "epoch": 5.746677091477717,
      "grad_norm": 0.176755890250206,
      "learning_rate": 4.254104769351056e-05,
      "loss": 0.0565,
      "step": 7350
    },
    {
      "epoch": 5.746677091477717,
      "step": 7350,
      "train/forward_time_ms": 2.165079116821289,
      "train/loss": 0.05970950424671173,
      "train/loss_affordance": 0.016436602920293808,
      "train/loss_compute_time_ms": 0.3304481506347656,
      "train/loss_risk": 0.016436602920293808,
      "train/loss_structure": 0.026836298406124115
    },
    {
      "epoch": 5.746677091477717,
      "step": 7350,
      "train/forward_time_ms": 4.130764007568359,
      "train/step_time_ms": 4.131197929382324
    },
    {
      "epoch": 5.7857701329163405,
      "grad_norm": 0.1780691146850586,
      "learning_rate": 4.215011727912432e-05,
      "loss": 0.0526,
      "step": 7400
    },
    {
      "epoch": 5.7857701329163405,
      "step": 7400,
      "train/forward_time_ms": 2.7196407318115234,
      "train/loss": 0.06356902420520782,
      "train/loss_affordance": 0.021759611554443836,
      "train/loss_compute_time_ms": 0.31113624572753906,
      "train/loss_risk": 0.021759611554443836,
      "train/loss_structure": 0.020049801096320152
    },
    {
      "epoch": 5.7857701329163405,
      "step": 7400,
      "train/forward_time_ms": 4.090824127197266,
      "train/step_time_ms": 4.091229438781738
    },
    {
      "epoch": 5.824863174354965,
      "grad_norm": 0.34053683280944824,
      "learning_rate": 4.1759186864738084e-05,
      "loss": 0.0531,
      "step": 7450
    },
    {
      "epoch": 5.824863174354965,
      "step": 7450,
      "train/forward_time_ms": 2.850055694580078,
      "train/loss": 0.044766269624233246,
      "train/loss_affordance": 0.012659195810556412,
      "train/loss_compute_time_ms": 0.2911090850830078,
      "train/loss_risk": 0.012659195810556412,
      "train/loss_structure": 0.019447878003120422
    },
    {
      "epoch": 5.824863174354965,
      "step": 7450,
      "train/forward_time_ms": 4.299426078796387,
      "train/step_time_ms": 4.299793243408203
    },
    {
      "epoch": 5.863956215793589,
      "grad_norm": 0.3469073176383972,
      "learning_rate": 4.136825645035184e-05,
      "loss": 0.0547,
      "step": 7500
    },
    {
      "epoch": 5.863956215793589,
      "step": 7500,
      "train/forward_time_ms": 2.4080276489257812,
      "train/loss": 0.06286052614450455,
      "train/loss_affordance": 0.021079549565911293,
      "train/loss_compute_time_ms": 0.4143714904785156,
      "train/loss_risk": 0.021079549565911293,
      "train/loss_structure": 0.02070142701268196
    },
    {
      "epoch": 5.863956215793589,
      "step": 7500,
      "train/forward_time_ms": 4.552578926086426,
      "train/step_time_ms": 4.553046226501465
    },
    {
      "epoch": 5.903049257232213,
      "grad_norm": 0.40661129355430603,
      "learning_rate": 4.0977326035965604e-05,
      "loss": 0.0547,
      "step": 7550
    },
    {
      "epoch": 5.903049257232213,
      "step": 7550,
      "train/forward_time_ms": 2.311229705810547,
      "train/loss": 0.062134675681591034,
      "train/loss_affordance": 0.02187035232782364,
      "train/loss_compute_time_ms": 0.35452842712402344,
      "train/loss_risk": 0.02187035232782364,
      "train/loss_structure": 0.018393971025943756
    },
    {
      "epoch": 5.903049257232213,
      "step": 7550,
      "train/forward_time_ms": 4.164214134216309,
      "train/step_time_ms": 4.164633750915527
    },
    {
      "epoch": 5.942142298670836,
      "grad_norm": 0.20657850801944733,
      "learning_rate": 4.058639562157936e-05,
      "loss": 0.0554,
      "step": 7600
    },
    {
      "epoch": 5.942142298670836,
      "step": 7600,
      "train/forward_time_ms": 2.3429393768310547,
      "train/loss": 0.048298146575689316,
      "train/loss_affordance": 0.013896774500608444,
      "train/loss_compute_time_ms": 0.3046989440917969,
      "train/loss_risk": 0.013896774500608444,
      "train/loss_structure": 0.020504597574472427
    },
    {
      "epoch": 5.942142298670836,
      "step": 7600,
      "train/forward_time_ms": 4.228730201721191,
      "train/step_time_ms": 4.22917366027832
    },
    {
      "epoch": 5.9812353401094605,
      "grad_norm": 0.3188052475452423,
      "learning_rate": 4.0195465207193125e-05,
      "loss": 0.0566,
      "step": 7650
    },
    {
      "epoch": 5.9812353401094605,
      "step": 7650,
      "train/forward_time_ms": 2.6388168334960938,
      "train/loss": 0.0536825954914093,
      "train/loss_affordance": 0.020054114051163197,
      "train/loss_compute_time_ms": 0.3077983856201172,
      "train/loss_risk": 0.020054114051163197,
      "train/loss_structure": 0.013574367389082909
    },
    {
      "epoch": 5.9812353401094605,
      "step": 7650,
      "train/forward_time_ms": 4.221482276916504,
      "train/step_time_ms": 4.221897125244141
    },
    {
      "epoch": 6.020328381548085,
      "grad_norm": 0.12724569439888,
      "learning_rate": 3.980453479280688e-05,
      "loss": 0.0554,
      "step": 7700
    },
    {
      "epoch": 6.020328381548085,
      "step": 7700,
      "train/forward_time_ms": 3.078460693359375,
      "train/loss": 0.055632416158914566,
      "train/loss_affordance": 0.0208634901791811,
      "train/loss_compute_time_ms": 0.5393028259277344,
      "train/loss_risk": 0.0208634901791811,
      "train/loss_structure": 0.013905435800552368
    },
    {
      "epoch": 6.020328381548085,
      "step": 7700,
      "train/forward_time_ms": 4.308881759643555,
      "train/step_time_ms": 4.3093156814575195
    },
    {
      "epoch": 6.059421422986708,
      "grad_norm": 0.29055365920066833,
      "learning_rate": 3.9413604378420645e-05,
      "loss": 0.0533,
      "step": 7750
    },
    {
      "epoch": 6.059421422986708,
      "step": 7750,
      "train/forward_time_ms": 2.457857131958008,
      "train/loss": 0.0658641904592514,
      "train/loss_affordance": 0.020548194646835327,
      "train/loss_compute_time_ms": 0.29587745666503906,
      "train/loss_risk": 0.020548194646835327,
      "train/loss_structure": 0.02476780116558075
    },
    {
      "epoch": 6.059421422986708,
      "step": 7750,
      "train/forward_time_ms": 4.355745315551758,
      "train/step_time_ms": 4.35610294342041
    },
    {
      "epoch": 6.098514464425333,
      "grad_norm": 0.3748752772808075,
      "learning_rate": 3.902267396403441e-05,
      "loss": 0.0541,
      "step": 7800
    },
    {
      "epoch": 6.098514464425333,
      "step": 7800,
      "train/forward_time_ms": 2.3751258850097656,
      "train/loss": 0.0563213974237442,
      "train/loss_affordance": 0.01929594110697508,
      "train/loss_compute_time_ms": 0.30922889709472656,
      "train/loss_risk": 0.01929594110697508,
      "train/loss_structure": 0.017729515209794044
    },
    {
      "epoch": 6.098514464425333,
      "step": 7800,
      "train/forward_time_ms": 4.169373512268066,
      "train/step_time_ms": 4.169807434082031
    },
    {
      "epoch": 6.137607505863956,
      "grad_norm": 0.20697247982025146,
      "learning_rate": 3.8631743549648166e-05,
      "loss": 0.0562,
      "step": 7850
    },
    {
      "epoch": 6.137607505863956,
      "step": 7850,
      "train/forward_time_ms": 2.346515655517578,
      "train/loss": 0.0531616285443306,
      "train/loss_affordance": 0.017891625873744488,
      "train/loss_compute_time_ms": 0.3638267517089844,
      "train/loss_risk": 0.017891625873744488,
      "train/loss_structure": 0.01737837679684162
    },
    {
      "epoch": 6.137607505863956,
      "step": 7850,
      "train/forward_time_ms": 4.215297698974609,
      "train/step_time_ms": 4.215688705444336
    },
    {
      "epoch": 6.1767005473025804,
      "grad_norm": 0.21670985221862793,
      "learning_rate": 3.824081313526193e-05,
      "loss": 0.0509,
      "step": 7900
    },
    {
      "epoch": 6.1767005473025804,
      "step": 7900,
      "train/forward_time_ms": 2.698659896850586,
      "train/loss": 0.05160827189683914,
      "train/loss_affordance": 0.017509398981928825,
      "train/loss_compute_time_ms": 0.34689903259277344,
      "train/loss_risk": 0.017509398981928825,
      "train/loss_structure": 0.01658947393298149
    },
    {
      "epoch": 6.1767005473025804,
      "step": 7900,
      "train/forward_time_ms": 4.259920120239258,
      "train/step_time_ms": 4.260344505310059
    },
    {
      "epoch": 6.215793588741204,
      "grad_norm": 0.26634806394577026,
      "learning_rate": 3.7849882720875686e-05,
      "loss": 0.0561,
      "step": 7950
    },
    {
      "epoch": 6.215793588741204,
      "step": 7950,
      "train/forward_time_ms": 2.241373062133789,
      "train/loss": 0.040774449706077576,
      "train/loss_affordance": 0.014084868133068085,
      "train/loss_compute_time_ms": 0.29969215393066406,
      "train/loss_risk": 0.014084868133068085,
      "train/loss_structure": 0.012604713439941406
    },
    {
      "epoch": 6.215793588741204,
      "step": 7950,
      "train/forward_time_ms": 4.45462703704834,
      "train/step_time_ms": 4.455022811889648
    },
    {
      "epoch": 6.254886630179828,
      "grad_norm": 0.22044061124324799,
      "learning_rate": 3.745895230648945e-05,
      "loss": 0.0523,
      "step": 8000
    },
    {
      "epoch": 6.254886630179828,
      "step": 8000,
      "train/forward_time_ms": 3.4880638122558594,
      "train/loss": 0.05053829401731491,
      "train/loss_affordance": 0.018513154238462448,
      "train/loss_compute_time_ms": 0.38051605224609375,
      "train/loss_risk": 0.018513154238462448,
      "train/loss_structure": 0.013511985540390015
    },
    {
      "epoch": 6.254886630179828,
      "step": 8000,
      "train/forward_time_ms": 4.261903762817383,
      "train/step_time_ms": 4.262328147888184
    },
    {
      "epoch": 6.293979671618452,
      "grad_norm": 0.14777563512325287,
      "learning_rate": 3.706802189210321e-05,
      "loss": 0.0515,
      "step": 8050
    },
    {
      "epoch": 6.293979671618452,
      "step": 8050,
      "train/forward_time_ms": 2.2258758544921875,
      "train/loss": 0.05377480387687683,
      "train/loss_affordance": 0.016852176748216152,
      "train/loss_compute_time_ms": 0.2732276916503906,
      "train/loss_risk": 0.016852176748216152,
      "train/loss_structure": 0.020070450380444527
    },
    {
      "epoch": 6.293979671618452,
      "step": 8050,
      "train/forward_time_ms": 4.079165458679199,
      "train/step_time_ms": 4.079580307006836
    },
    {
      "epoch": 6.333072713057076,
      "grad_norm": 0.5422919988632202,
      "learning_rate": 3.667709147771697e-05,
      "loss": 0.0524,
      "step": 8100
    },
    {
      "epoch": 6.333072713057076,
      "step": 8100,
      "train/forward_time_ms": 2.187967300415039,
      "train/loss": 0.038252778351306915,
      "train/loss_affordance": 0.012138713151216507,
      "train/loss_compute_time_ms": 0.2613067626953125,
      "train/loss_risk": 0.012138713151216507,
      "train/loss_structure": 0.013975352048873901
    },
    {
      "epoch": 6.333072713057076,
      "step": 8100,
      "train/forward_time_ms": 4.23248291015625,
      "train/step_time_ms": 4.232912063598633
    },
    {
      "epoch": 6.3721657544956996,
      "grad_norm": 0.4051675796508789,
      "learning_rate": 3.6286161063330734e-05,
      "loss": 0.0563,
      "step": 8150
    },
    {
      "epoch": 6.3721657544956996,
      "step": 8150,
      "train/forward_time_ms": 2.220630645751953,
      "train/loss": 0.06205005943775177,
      "train/loss_affordance": 0.022287674248218536,
      "train/loss_compute_time_ms": 0.263214111328125,
      "train/loss_risk": 0.022287674248218536,
      "train/loss_structure": 0.017474710941314697
    },
    {
      "epoch": 6.3721657544956996,
      "step": 8150,
      "train/forward_time_ms": 4.1841840744018555,
      "train/step_time_ms": 4.184627532958984
    },
    {
      "epoch": 6.411258795934324,
      "grad_norm": 0.4175052344799042,
      "learning_rate": 3.589523064894449e-05,
      "loss": 0.0546,
      "step": 8200
    },
    {
      "epoch": 6.411258795934324,
      "step": 8200,
      "train/forward_time_ms": 2.696514129638672,
      "train/loss": 0.06597298383712769,
      "train/loss_affordance": 0.026311862748116255,
      "train/loss_compute_time_ms": 0.4398822784423828,
      "train/loss_risk": 0.026311862748116255,
      "train/loss_structure": 0.013349258340895176
    },
    {
      "epoch": 6.411258795934324,
      "step": 8200,
      "train/forward_time_ms": 4.35969352722168,
      "train/step_time_ms": 4.360179901123047
    },
    {
      "epoch": 6.450351837372947,
      "grad_norm": 0.17256537079811096,
      "learning_rate": 3.5504300234558255e-05,
      "loss": 0.0532,
      "step": 8250
    },
    {
      "epoch": 6.450351837372947,
      "step": 8250,
      "train/forward_time_ms": 2.223968505859375,
      "train/loss": 0.06070438772439957,
      "train/loss_affordance": 0.018406839109957218,
      "train/loss_compute_time_ms": 0.3108978271484375,
      "train/loss_risk": 0.018406839109957218,
      "train/loss_structure": 0.02389070950448513
    },
    {
      "epoch": 6.450351837372947,
      "step": 8250,
      "train/forward_time_ms": 4.245266914367676,
      "train/step_time_ms": 4.245691299438477
    },
    {
      "epoch": 6.489444878811572,
      "grad_norm": 0.29789748787879944,
      "learning_rate": 3.511336982017201e-05,
      "loss": 0.0521,
      "step": 8300
    },
    {
      "epoch": 6.489444878811572,
      "step": 8300,
      "train/forward_time_ms": 2.3746490478515625,
      "train/loss": 0.04639733210206032,
      "train/loss_affordance": 0.01657583937048912,
      "train/loss_compute_time_ms": 0.45228004455566406,
      "train/loss_risk": 0.01657583937048912,
      "train/loss_structure": 0.013245653361082077
    },
    {
      "epoch": 6.489444878811572,
      "step": 8300,
      "train/forward_time_ms": 4.237070083618164,
      "train/step_time_ms": 4.237456321716309
    },
    {
      "epoch": 6.528537920250195,
      "grad_norm": 0.45867735147476196,
      "learning_rate": 3.4722439405785775e-05,
      "loss": 0.0532,
      "step": 8350
    },
    {
      "epoch": 6.528537920250195,
      "step": 8350,
      "train/forward_time_ms": 2.285003662109375,
      "train/loss": 0.07365725189447403,
      "train/loss_affordance": 0.02935698628425598,
      "train/loss_compute_time_ms": 0.3256797790527344,
      "train/loss_risk": 0.02935698628425598,
      "train/loss_structure": 0.014943279325962067
    },
    {
      "epoch": 6.528537920250195,
      "step": 8350,
      "train/forward_time_ms": 4.110860824584961,
      "train/step_time_ms": 4.111266136169434
    },
    {
      "epoch": 6.5676309616888195,
      "grad_norm": 0.17776541411876678,
      "learning_rate": 3.433150899139953e-05,
      "loss": 0.0534,
      "step": 8400
    },
    {
      "epoch": 6.5676309616888195,
      "step": 8400,
      "train/forward_time_ms": 2.47955322265625,
      "train/loss": 0.045691199600696564,
      "train/loss_affordance": 0.01769102644175291,
      "train/loss_compute_time_ms": 0.34046173095703125,
      "train/loss_risk": 0.01769102644175291,
      "train/loss_structure": 0.010309146717190742
    },
    {
      "epoch": 6.5676309616888195,
      "step": 8400,
      "train/forward_time_ms": 4.164390563964844,
      "train/step_time_ms": 4.164762496948242
    },
    {
      "epoch": 6.606724003127443,
      "grad_norm": 0.17897945642471313,
      "learning_rate": 3.3940578577013295e-05,
      "loss": 0.0549,
      "step": 8450
    },
    {
      "epoch": 6.606724003127443,
      "step": 8450,
      "train/forward_time_ms": 2.3603439331054688,
      "train/loss": 0.05908326059579849,
      "train/loss_affordance": 0.01857144571840763,
      "train/loss_compute_time_ms": 0.32973289489746094,
      "train/loss_risk": 0.01857144571840763,
      "train/loss_structure": 0.02194036915898323
    },
    {
      "epoch": 6.606724003127443,
      "step": 8450,
      "train/forward_time_ms": 4.630680084228516,
      "train/step_time_ms": 4.631233215332031
    },
    {
      "epoch": 6.645817044566067,
      "grad_norm": 0.20538757741451263,
      "learning_rate": 3.354964816262706e-05,
      "loss": 0.0532,
      "step": 8500
    },
    {
      "epoch": 6.645817044566067,
      "step": 8500,
      "train/forward_time_ms": 2.361297607421875,
      "train/loss": 0.0662524551153183,
      "train/loss_affordance": 0.027237506583333015,
      "train/loss_compute_time_ms": 0.3559589385986328,
      "train/loss_risk": 0.027237506583333015,
      "train/loss_structure": 0.011777441948652267
    },
    {
      "epoch": 6.645817044566067,
      "step": 8500,
      "train/forward_time_ms": 4.23375129699707,
      "train/step_time_ms": 4.234151840209961
    },
    {
      "epoch": 6.684910086004691,
      "grad_norm": 0.4898104667663574,
      "learning_rate": 3.3158717748240816e-05,
      "loss": 0.05,
      "step": 8550
    },
    {
      "epoch": 6.684910086004691,
      "step": 8550,
      "train/forward_time_ms": 2.3941993713378906,
      "train/loss": 0.0693417638540268,
      "train/loss_affordance": 0.025038438849151134,
      "train/loss_compute_time_ms": 0.2560615539550781,
      "train/loss_risk": 0.025038438849151134,
      "train/loss_structure": 0.019264886155724525
    },
    {
      "epoch": 6.684910086004691,
      "step": 8550,
      "train/forward_time_ms": 4.159140586853027,
      "train/step_time_ms": 4.159526824951172
    },
    {
      "epoch": 6.724003127443315,
      "grad_norm": 0.2862711250782013,
      "learning_rate": 3.276778733385458e-05,
      "loss": 0.0538,
      "step": 8600
    },
    {
      "epoch": 6.724003127443315,
      "step": 8600,
      "train/forward_time_ms": 2.464771270751953,
      "train/loss": 0.05857080593705177,
      "train/loss_affordance": 0.018518873490393162,
      "train/loss_compute_time_ms": 0.4258155822753906,
      "train/loss_risk": 0.018518873490393162,
      "train/loss_structure": 0.02153305895626545
    },
    {
      "epoch": 6.724003127443315,
      "step": 8600,
      "train/forward_time_ms": 4.218196868896484,
      "train/step_time_ms": 4.218630790710449
    },
    {
      "epoch": 6.763096168881939,
      "grad_norm": 0.22659964859485626,
      "learning_rate": 3.2376856919468336e-05,
      "loss": 0.0533,
      "step": 8650
    },
    {
      "epoch": 6.763096168881939,
      "step": 8650,
      "train/forward_time_ms": 2.3224353790283203,
      "train/loss": 0.046239688992500305,
      "train/loss_affordance": 0.016418826766312122,
      "train/loss_compute_time_ms": 0.4177093505859375,
      "train/loss_risk": 0.016418826766312122,
      "train/loss_structure": 0.01340203545987606
    },
    {
      "epoch": 6.763096168881939,
      "step": 8650,
      "train/forward_time_ms": 4.248061180114746,
      "train/step_time_ms": 4.2484331130981445
    },
    {
      "epoch": 6.802189210320563,
      "grad_norm": 0.23170067369937897,
      "learning_rate": 3.19859265050821e-05,
      "loss": 0.0509,
      "step": 8700
    },
    {
      "epoch": 6.802189210320563,
      "step": 8700,
      "train/forward_time_ms": 2.4442672729492188,
      "train/loss": 0.06031438335776329,
      "train/loss_affordance": 0.01898280344903469,
      "train/loss_compute_time_ms": 0.3075599670410156,
      "train/loss_risk": 0.01898280344903469,
      "train/loss_structure": 0.02234877645969391
    },
    {
      "epoch": 6.802189210320563,
      "step": 8700,
      "train/forward_time_ms": 4.388999938964844,
      "train/step_time_ms": 4.389457702636719
    },
    {
      "epoch": 6.841282251759187,
      "grad_norm": 0.4899943768978119,
      "learning_rate": 3.159499609069586e-05,
      "loss": 0.0522,
      "step": 8750
    },
    {
      "epoch": 6.841282251759187,
      "step": 8750,
      "train/forward_time_ms": 2.52532958984375,
      "train/loss": 0.0539344921708107,
      "train/loss_affordance": 0.020503772422671318,
      "train/loss_compute_time_ms": 0.31495094299316406,
      "train/loss_risk": 0.020503772422671318,
      "train/loss_structure": 0.012926947325468063
    },
    {
      "epoch": 6.841282251759187,
      "step": 8750,
      "train/forward_time_ms": 4.204816818237305,
      "train/step_time_ms": 4.205207824707031
    },
    {
      "epoch": 6.880375293197811,
      "grad_norm": 0.4724428653717041,
      "learning_rate": 3.120406567630962e-05,
      "loss": 0.0561,
      "step": 8800
    },
    {
      "epoch": 6.880375293197811,
      "step": 8800,
      "train/forward_time_ms": 2.467632293701172,
      "train/loss": 0.08977815508842468,
      "train/loss_affordance": 0.03619190584868193,
      "train/loss_compute_time_ms": 0.2970695495605469,
      "train/loss_risk": 0.03619190584868193,
      "train/loss_structure": 0.01739434339106083
    },
    {
      "epoch": 6.880375293197811,
      "step": 8800,
      "train/forward_time_ms": 4.090976715087891,
      "train/step_time_ms": 4.091424942016602
    },
    {
      "epoch": 6.919468334636434,
      "grad_norm": 0.571171224117279,
      "learning_rate": 3.0813135261923384e-05,
      "loss": 0.0536,
      "step": 8850
    },
    {
      "epoch": 6.919468334636434,
      "step": 8850,
      "train/forward_time_ms": 2.416849136352539,
      "train/loss": 0.0583450123667717,
      "train/loss_affordance": 0.018203750252723694,
      "train/loss_compute_time_ms": 0.377655029296875,
      "train/loss_risk": 0.018203750252723694,
      "train/loss_structure": 0.02193751186132431
    },
    {
      "epoch": 6.919468334636434,
      "step": 8850,
      "train/forward_time_ms": 4.172186851501465,
      "train/step_time_ms": 4.172601699829102
    },
    {
      "epoch": 6.958561376075059,
      "grad_norm": 0.2275133728981018,
      "learning_rate": 3.0422204847537138e-05,
      "loss": 0.052,
      "step": 8900
    },
    {
      "epoch": 6.958561376075059,
      "step": 8900,
      "train/forward_time_ms": 3.2711029052734375,
      "train/loss": 0.06597405672073364,
      "train/loss_affordance": 0.02521092537790537,
      "train/loss_compute_time_ms": 0.4935264587402344,
      "train/loss_risk": 0.02521092537790537,
      "train/loss_structure": 0.015552205964922905
    },
    {
      "epoch": 6.958561376075059,
      "step": 8900,
      "train/forward_time_ms": 4.3335676193237305,
      "train/step_time_ms": 4.3340349197387695
    },
    {
      "epoch": 6.997654417513683,
      "grad_norm": 0.12748666107654572,
      "learning_rate": 3.00312744331509e-05,
      "loss": 0.0524,
      "step": 8950
    },
    {
      "epoch": 6.997654417513683,
      "step": 8950,
      "train/forward_time_ms": 2.5153160095214844,
      "train/loss": 0.06728274375200272,
      "train/loss_affordance": 0.02672193432226777,
      "train/loss_compute_time_ms": 0.30040740966796875,
      "train/loss_risk": 0.02672193432226777,
      "train/loss_structure": 0.013838875107467175
    },
    {
      "epoch": 6.997654417513683,
      "step": 8950,
      "train/forward_time_ms": 4.369721412658691,
      "train/step_time_ms": 4.37016487121582
    },
    {
      "epoch": 7.0367474589523065,
      "grad_norm": 0.38895413279533386,
      "learning_rate": 2.9640344018764658e-05,
      "loss": 0.0538,
      "step": 9000
    },
    {
      "epoch": 7.0367474589523065,
      "step": 9000,
      "train/forward_time_ms": 2.9757022857666016,
      "train/loss": 0.03994577378034592,
      "train/loss_affordance": 0.01406279718503356,
      "train/loss_compute_time_ms": 0.3790855407714844,
      "train/loss_risk": 0.01406279718503356,
      "train/loss_structure": 0.011820179410278797
    },
    {
      "epoch": 7.0367474589523065,
      "step": 9000,
      "train/forward_time_ms": 4.228415489196777,
      "train/step_time_ms": 4.228849411010742
    },
    {
      "epoch": 7.075840500390931,
      "grad_norm": 0.3705644905567169,
      "learning_rate": 2.9249413604378422e-05,
      "loss": 0.0509,
      "step": 9050
    },
    {
      "epoch": 7.075840500390931,
      "step": 9050,
      "train/forward_time_ms": 2.3345947265625,
      "train/loss": 0.041051167994737625,
      "train/loss_affordance": 0.013964058831334114,
      "train/loss_compute_time_ms": 0.3056526184082031,
      "train/loss_risk": 0.013964058831334114,
      "train/loss_structure": 0.013123050332069397
    },
    {
      "epoch": 7.075840500390931,
      "step": 9050,
      "train/forward_time_ms": 4.221310615539551,
      "train/step_time_ms": 4.2217302322387695
    },
    {
      "epoch": 7.114933541829554,
      "grad_norm": 0.31718167662620544,
      "learning_rate": 2.8858483189992182e-05,
      "loss": 0.0496,
      "step": 9100
    },
    {
      "epoch": 7.114933541829554,
      "step": 9100,
      "train/forward_time_ms": 2.2852420806884766,
      "train/loss": 0.05571451783180237,
      "train/loss_affordance": 0.019706713035702705,
      "train/loss_compute_time_ms": 0.3631114959716797,
      "train/loss_risk": 0.019706713035702705,
      "train/loss_structure": 0.016301091760396957
    },
    {
      "epoch": 7.114933541829554,
      "step": 9100,
      "train/forward_time_ms": 4.233908653259277,
      "train/step_time_ms": 4.234342575073242
    },
    {
      "epoch": 7.154026583268179,
      "grad_norm": 0.200997993350029,
      "learning_rate": 2.8467552775605942e-05,
      "loss": 0.0499,
      "step": 9150
    },
    {
      "epoch": 7.154026583268179,
      "step": 9150,
      "train/forward_time_ms": 2.785205841064453,
      "train/loss": 0.052748408168554306,
      "train/loss_affordance": 0.02122629340738058,
      "train/loss_compute_time_ms": 0.32639503479003906,
      "train/loss_risk": 0.02122629340738058,
      "train/loss_structure": 0.010295821353793144
    },
    {
      "epoch": 7.154026583268179,
      "step": 9150,
      "train/forward_time_ms": 4.385256767272949,
      "train/step_time_ms": 4.38572883605957
    },
    {
      "epoch": 7.193119624706802,
      "grad_norm": 0.22010424733161926,
      "learning_rate": 2.8076622361219706e-05,
      "loss": 0.0508,
      "step": 9200
    },
    {
      "epoch": 7.193119624706802,
      "step": 9200,
      "train/forward_time_ms": 2.310037612915039,
      "train/loss": 0.028333529829978943,
      "train/loss_affordance": 0.009479705709964037,
      "train/loss_compute_time_ms": 0.4315376281738281,
      "train/loss_risk": 0.009479705709964037,
      "train/loss_structure": 0.009374118410050869
    },
    {
      "epoch": 7.193119624706802,
      "step": 9200,
      "train/forward_time_ms": 4.192724227905273,
      "train/step_time_ms": 4.193115234375
    },
    {
      "epoch": 7.2322126661454265,
      "grad_norm": 0.1552715003490448,
      "learning_rate": 2.7685691946833463e-05,
      "loss": 0.051,
      "step": 9250
    },
    {
      "epoch": 7.2322126661454265,
      "step": 9250,
      "train/forward_time_ms": 2.4995803833007812,
      "train/loss": 0.045995742082595825,
      "train/loss_affordance": 0.015546298120170832,
      "train/loss_compute_time_ms": 0.44798851013183594,
      "train/loss_risk": 0.015546298120170832,
      "train/loss_structure": 0.014903145842254162
    },
    {
      "epoch": 7.2322126661454265,
      "step": 9250,
      "train/forward_time_ms": 4.303092956542969,
      "train/step_time_ms": 4.303798675537109
    },
    {
      "epoch": 7.27130570758405,
      "grad_norm": 0.1401320993900299,
      "learning_rate": 2.7294761532447226e-05,
      "loss": 0.048,
      "step": 9300
    },
    {
      "epoch": 7.27130570758405,
      "step": 9300,
      "train/forward_time_ms": 2.2678375244140625,
      "train/loss": 0.07829542458057404,
      "train/loss_affordance": 0.02805931679904461,
      "train/loss_compute_time_ms": 0.27632713317871094,
      "train/loss_risk": 0.02805931679904461,
      "train/loss_structure": 0.022176790982484818
    },
    {
      "epoch": 7.27130570758405,
      "step": 9300,
      "train/forward_time_ms": 4.194002151489258,
      "train/step_time_ms": 4.194397926330566
    },
    {
      "epoch": 7.310398749022674,
      "grad_norm": 0.8472580313682556,
      "learning_rate": 2.6903831118060983e-05,
      "loss": 0.0548,
      "step": 9350
    },
    {
      "epoch": 7.310398749022674,
      "step": 9350,
      "train/forward_time_ms": 2.5720596313476562,
      "train/loss": 0.04846217483282089,
      "train/loss_affordance": 0.01452547125518322,
      "train/loss_compute_time_ms": 0.3273487091064453,
      "train/loss_risk": 0.01452547125518322,
      "train/loss_structure": 0.019411232322454453
    },
    {
      "epoch": 7.310398749022674,
      "step": 9350,
      "train/forward_time_ms": 4.218168258666992,
      "train/step_time_ms": 4.2186737060546875
    },
    {
      "epoch": 7.349491790461298,
      "grad_norm": 0.3100738227367401,
      "learning_rate": 2.6512900703674747e-05,
      "loss": 0.0525,
      "step": 9400
    },
    {
      "epoch": 7.349491790461298,
      "step": 9400,
      "train/forward_time_ms": 2.2771358489990234,
      "train/loss": 0.06370082497596741,
      "train/loss_affordance": 0.025627262890338898,
      "train/loss_compute_time_ms": 0.31375885009765625,
      "train/loss_risk": 0.025627262890338898,
      "train/loss_structure": 0.012446299195289612
    },
    {
      "epoch": 7.349491790461298,
      "step": 9400,
      "train/forward_time_ms": 4.4785261154174805,
      "train/step_time_ms": 4.479022026062012
    },
    {
      "epoch": 7.388584831899922,
      "grad_norm": 0.10210290551185608,
      "learning_rate": 2.6121970289288507e-05,
      "loss": 0.0513,
      "step": 9450
    },
    {
      "epoch": 7.388584831899922,
      "step": 9450,
      "train/forward_time_ms": 2.32696533203125,
      "train/loss": 0.07465247809886932,
      "train/loss_affordance": 0.02660391479730606,
      "train/loss_compute_time_ms": 0.3085136413574219,
      "train/loss_risk": 0.02660391479730606,
      "train/loss_structure": 0.021444648504257202
    },
    {
      "epoch": 7.388584831899922,
      "step": 9450,
      "train/forward_time_ms": 4.198827743530273,
      "train/step_time_ms": 4.1992998123168945
    },
    {
      "epoch": 7.427677873338546,
      "grad_norm": 0.4168068468570709,
      "learning_rate": 2.5731039874902267e-05,
      "loss": 0.0503,
      "step": 9500
    },
    {
      "epoch": 7.427677873338546,
      "step": 9500,
      "train/forward_time_ms": 2.248525619506836,
      "train/loss": 0.04338386654853821,
      "train/loss_affordance": 0.013023925945162773,
      "train/loss_compute_time_ms": 0.3173351287841797,
      "train/loss_risk": 0.013023925945162773,
      "train/loss_structure": 0.017336014658212662
    },
    {
      "epoch": 7.427677873338546,
      "step": 9500,
      "train/forward_time_ms": 4.186439514160156,
      "train/step_time_ms": 4.186911582946777
    },
    {
      "epoch": 7.46677091477717,
      "grad_norm": 0.154002845287323,
      "learning_rate": 2.534010946051603e-05,
      "loss": 0.0526,
      "step": 9550
    },
    {
      "epoch": 7.46677091477717,
      "step": 9550,
      "train/forward_time_ms": 2.2470951080322266,
      "train/loss": 0.08970654010772705,
      "train/loss_affordance": 0.02664763480424881,
      "train/loss_compute_time_ms": 0.29087066650390625,
      "train/loss_risk": 0.02664763480424881,
      "train/loss_structure": 0.03641127049922943
    },
    {
      "epoch": 7.46677091477717,
      "step": 9550,
      "train/forward_time_ms": 4.122376441955566,
      "train/step_time_ms": 4.122896194458008
    },
    {
      "epoch": 7.505863956215793,
      "grad_norm": 0.29834651947021484,
      "learning_rate": 2.4949179046129788e-05,
      "loss": 0.0515,
      "step": 9600
    },
    {
      "epoch": 7.505863956215793,
      "step": 9600,
      "train/forward_time_ms": 2.0346641540527344,
      "train/loss": 0.04663500562310219,
      "train/loss_affordance": 0.01862381584942341,
      "train/loss_compute_time_ms": 0.2930164337158203,
      "train/loss_risk": 0.01862381584942341,
      "train/loss_structure": 0.009387373924255371
    },
    {
      "epoch": 7.505863956215793,
      "step": 9600,
      "train/forward_time_ms": 4.195728302001953,
      "train/step_time_ms": 4.1961669921875
    },
    {
      "epoch": 7.544956997654418,
      "grad_norm": 0.4672839045524597,
      "learning_rate": 2.4558248631743548e-05,
      "loss": 0.0511,
      "step": 9650
    },
    {
      "epoch": 7.544956997654418,
      "step": 9650,
      "train/forward_time_ms": 2.3322105407714844,
      "train/loss": 0.050772055983543396,
      "train/loss_affordance": 0.018540496937930584,
      "train/loss_compute_time_ms": 0.3235340118408203,
      "train/loss_risk": 0.018540496937930584,
      "train/loss_structure": 0.013691062107682228
    },
    {
      "epoch": 7.544956997654418,
      "step": 9650,
      "train/forward_time_ms": 4.318346977233887,
      "train/step_time_ms": 4.318728446960449
    },
    {
      "epoch": 7.584050039093041,
      "grad_norm": 0.15160520374774933,
      "learning_rate": 2.4167318217357312e-05,
      "loss": 0.0521,
      "step": 9700
    },
    {
      "epoch": 7.584050039093041,
      "step": 9700,
      "train/forward_time_ms": 2.2296905517578125,
      "train/loss": 0.07373301684856415,
      "train/loss_affordance": 0.02220620308071375,
      "train/loss_compute_time_ms": 0.2980232238769531,
      "train/loss_risk": 0.02220620308071375,
      "train/loss_structure": 0.02932061068713665
    },
    {
      "epoch": 7.584050039093041,
      "step": 9700,
      "train/forward_time_ms": 4.169268608093262,
      "train/step_time_ms": 4.1696977615356445
    },
    {
      "epoch": 7.623143080531666,
      "grad_norm": 0.3525373041629791,
      "learning_rate": 2.3776387802971072e-05,
      "loss": 0.0554,
      "step": 9750
    },
    {
      "epoch": 7.623143080531666,
      "step": 9750,
      "train/forward_time_ms": 2.3920536041259766,
      "train/loss": 0.05390394479036331,
      "train/loss_affordance": 0.018717573024332523,
      "train/loss_compute_time_ms": 0.2727508544921875,
      "train/loss_risk": 0.018717573024332523,
      "train/loss_structure": 0.016468798741698265
    },
    {
      "epoch": 7.623143080531666,
      "step": 9750,
      "train/forward_time_ms": 4.171810150146484,
      "train/step_time_ms": 4.172229766845703
    },
    {
      "epoch": 7.662236121970289,
      "grad_norm": 0.24178019165992737,
      "learning_rate": 2.3385457388584832e-05,
      "loss": 0.0504,
      "step": 9800
    },
    {
      "epoch": 7.662236121970289,
      "step": 9800,
      "train/forward_time_ms": 2.2687911987304688,
      "train/loss": 0.04605751112103462,
      "train/loss_affordance": 0.01649930514395237,
      "train/loss_compute_time_ms": 0.3399848937988281,
      "train/loss_risk": 0.01649930514395237,
      "train/loss_structure": 0.013058900833129883
    },
    {
      "epoch": 7.662236121970289,
      "step": 9800,
      "train/forward_time_ms": 4.120798110961914,
      "train/step_time_ms": 4.121212959289551
    },
    {
      "epoch": 7.701329163408913,
      "grad_norm": 0.23772959411144257,
      "learning_rate": 2.2994526974198592e-05,
      "loss": 0.0542,
      "step": 9850
    },
    {
      "epoch": 7.701329163408913,
      "step": 9850,
      "train/forward_time_ms": 3.1092166900634766,
      "train/loss": 0.04919295385479927,
      "train/loss_affordance": 0.019021542742848396,
      "train/loss_compute_time_ms": 0.3032684326171875,
      "train/loss_risk": 0.019021542742848396,
      "train/loss_structure": 0.011149868369102478
    },
    {
      "epoch": 7.701329163408913,
      "step": 9850,
      "train/forward_time_ms": 4.177336692810059,
      "train/step_time_ms": 4.177751541137695
    },
    {
      "epoch": 7.740422204847537,
      "grad_norm": 0.2294435203075409,
      "learning_rate": 2.2603596559812353e-05,
      "loss": 0.0517,
      "step": 9900
    },
    {
      "epoch": 7.740422204847537,
      "step": 9900,
      "train/forward_time_ms": 2.25830078125,
      "train/loss": 0.05549111217260361,
      "train/loss_affordance": 0.019924361258745193,
      "train/loss_compute_time_ms": 0.30231475830078125,
      "train/loss_risk": 0.019924361258745193,
      "train/loss_structure": 0.01564238965511322
    },
    {
      "epoch": 7.740422204847537,
      "step": 9900,
      "train/forward_time_ms": 4.275341033935547,
      "train/step_time_ms": 4.27577018737793
    },
    {
      "epoch": 7.779515246286161,
      "grad_norm": 0.2895645797252655,
      "learning_rate": 2.2212666145426113e-05,
      "loss": 0.0496,
      "step": 9950
    },
    {
      "epoch": 7.779515246286161,
      "step": 9950,
      "train/forward_time_ms": 2.3369789123535156,
      "train/loss": 0.04724723845720291,
      "train/loss_affordance": 0.01575422566384077,
      "train/loss_compute_time_ms": 0.3333091735839844,
      "train/loss_risk": 0.01575422566384077,
      "train/loss_structure": 0.01573878712952137
    },
    {
      "epoch": 7.779515246286161,
      "step": 9950,
      "train/forward_time_ms": 4.291782379150391,
      "train/step_time_ms": 4.2922163009643555
    },
    {
      "epoch": 7.818608287724785,
      "grad_norm": 0.23146207630634308,
      "learning_rate": 2.1821735731039873e-05,
      "loss": 0.0521,
      "step": 10000
    },
    {
      "epoch": 7.818608287724785,
      "step": 10000,
      "train/forward_time_ms": 2.2516250610351562,
      "train/loss": 0.056850187480449677,
      "train/loss_affordance": 0.02434695139527321,
      "train/loss_compute_time_ms": 0.40459632873535156,
      "train/loss_risk": 0.02434695139527321,
      "train/loss_structure": 0.00815628468990326
    },
    {
      "epoch": 7.818608287724785,
      "step": 10000,
      "train/forward_time_ms": 4.105286598205566,
      "train/step_time_ms": 4.105658531188965
    },
    {
      "epoch": 7.857701329163409,
      "grad_norm": 0.2271895855665207,
      "learning_rate": 2.1430805316653637e-05,
      "loss": 0.0526,
      "step": 10050
    },
    {
      "epoch": 7.857701329163409,
      "step": 10050,
      "train/forward_time_ms": 2.791881561279297,
      "train/loss": 0.05157216638326645,
      "train/loss_affordance": 0.01952914521098137,
      "train/loss_compute_time_ms": 0.2944469451904297,
      "train/loss_risk": 0.01952914521098137,
      "train/loss_structure": 0.012513875961303711
    },
    {
      "epoch": 7.857701329163409,
      "step": 10050,
      "train/forward_time_ms": 4.192776679992676,
      "train/step_time_ms": 4.193201065063477
    },
    {
      "epoch": 7.8967943706020325,
      "grad_norm": 0.18221448361873627,
      "learning_rate": 2.1039874902267397e-05,
      "loss": 0.0501,
      "step": 10100
    },
    {
      "epoch": 7.8967943706020325,
      "step": 10100,
      "train/forward_time_ms": 2.5818347930908203,
      "train/loss": 0.05355530604720116,
      "train/loss_affordance": 0.01812682580202818,
      "train/loss_compute_time_ms": 0.26607513427734375,
      "train/loss_risk": 0.01812682580202818,
      "train/loss_structure": 0.0173016544431448
    },
    {
      "epoch": 7.8967943706020325,
      "step": 10100,
      "train/forward_time_ms": 4.182367324829102,
      "train/step_time_ms": 4.182772636413574
    },
    {
      "epoch": 7.935887412040657,
      "grad_norm": 0.38037312030792236,
      "learning_rate": 2.0648944487881157e-05,
      "loss": 0.051,
      "step": 10150
    },
    {
      "epoch": 7.935887412040657,
      "step": 10150,
      "train/forward_time_ms": 2.790689468383789,
      "train/loss": 0.06494355201721191,
      "train/loss_affordance": 0.01772619318217039,
      "train/loss_compute_time_ms": 0.31638145446777344,
      "train/loss_risk": 0.01772619318217039,
      "train/loss_structure": 0.029491165652871132
    },
    {
      "epoch": 7.935887412040657,
      "step": 10150,
      "train/forward_time_ms": 4.394636154174805,
      "train/step_time_ms": 4.395103454589844
    },
    {
      "epoch": 7.97498045347928,
      "grad_norm": 0.6395598649978638,
      "learning_rate": 2.0258014073494918e-05,
      "loss": 0.0491,
      "step": 10200
    },
    {
      "epoch": 7.97498045347928,
      "step": 10200,
      "train/forward_time_ms": 2.2919178009033203,
      "train/loss": 0.05927841365337372,
      "train/loss_affordance": 0.02192733809351921,
      "train/loss_compute_time_ms": 0.34546852111816406,
      "train/loss_risk": 0.02192733809351921,
      "train/loss_structure": 0.015423737466335297
    },
    {
      "epoch": 7.97498045347928,
      "step": 10200,
      "train/forward_time_ms": 4.136161804199219,
      "train/step_time_ms": 4.136562347412109
    },
    {
      "epoch": 8.014073494917904,
      "grad_norm": 0.36451780796051025,
      "learning_rate": 1.9867083659108678e-05,
      "loss": 0.0513,
      "step": 10250
    },
    {
      "epoch": 8.014073494917904,
      "step": 10250,
      "train/forward_time_ms": 2.415895462036133,
      "train/loss": 0.05696442723274231,
      "train/loss_affordance": 0.021005763672292233,
      "train/loss_compute_time_ms": 0.28228759765625,
      "train/loss_risk": 0.021005763672292233,
      "train/loss_structure": 0.014952899888157845
    },
    {
      "epoch": 8.014073494917904,
      "step": 10250,
      "train/forward_time_ms": 4.252429008483887,
      "train/step_time_ms": 4.252834320068359
    },
    {
      "epoch": 8.053166536356528,
      "grad_norm": 0.4327208399772644,
      "learning_rate": 1.9476153244722438e-05,
      "loss": 0.0488,
      "step": 10300
    },
    {
      "epoch": 8.053166536356528,
      "step": 10300,
      "train/forward_time_ms": 2.5331974029541016,
      "train/loss": 0.0475502610206604,
      "train/loss_affordance": 0.01520421914756298,
      "train/loss_compute_time_ms": 0.3643035888671875,
      "train/loss_risk": 0.01520421914756298,
      "train/loss_structure": 0.01714182272553444
    },
    {
      "epoch": 8.053166536356528,
      "step": 10300,
      "train/forward_time_ms": 4.235739707946777,
      "train/step_time_ms": 4.236135482788086
    },
    {
      "epoch": 8.092259577795152,
      "grad_norm": 0.28504714369773865,
      "learning_rate": 1.90852228303362e-05,
      "loss": 0.0486,
      "step": 10350
    },
    {
      "epoch": 8.092259577795152,
      "step": 10350,
      "train/forward_time_ms": 3.1883716583251953,
      "train/loss": 0.03270559012889862,
      "train/loss_affordance": 0.009706735145300627,
      "train/loss_compute_time_ms": 0.4730224609375,
      "train/loss_risk": 0.009706735145300627,
      "train/loss_structure": 0.013292119838297367
    },
    {
      "epoch": 8.092259577795152,
      "step": 10350,
      "train/forward_time_ms": 4.150066375732422,
      "train/step_time_ms": 4.150547981262207
    },
    {
      "epoch": 8.131352619233777,
      "grad_norm": 0.2874072194099426,
      "learning_rate": 1.8694292415949962e-05,
      "loss": 0.0542,
      "step": 10400
    },
    {
      "epoch": 8.131352619233777,
      "step": 10400,
      "train/forward_time_ms": 2.2640228271484375,
      "train/loss": 0.06209877133369446,
      "train/loss_affordance": 0.023698966950178146,
      "train/loss_compute_time_ms": 0.2694129943847656,
      "train/loss_risk": 0.023698966950178146,
      "train/loss_structure": 0.014700837433338165
    },
    {
      "epoch": 8.131352619233777,
      "step": 10400,
      "train/forward_time_ms": 4.351773262023926,
      "train/step_time_ms": 4.352235794067383
    },
    {
      "epoch": 8.1704456606724,
      "grad_norm": 0.13522645831108093,
      "learning_rate": 1.8303362001563722e-05,
      "loss": 0.0499,
      "step": 10450
    },
    {
      "epoch": 8.1704456606724,
      "step": 10450,
      "train/forward_time_ms": 2.8641223907470703,
      "train/loss": 0.0549502968788147,
      "train/loss_affordance": 0.0207518651150167,
      "train/loss_compute_time_ms": 0.3211498260498047,
      "train/loss_risk": 0.0207518651150167,
      "train/loss_structure": 0.0134465666487813
    },
    {
      "epoch": 8.1704456606724,
      "step": 10450,
      "train/forward_time_ms": 4.256854057312012,
      "train/step_time_ms": 4.257311820983887
    },
    {
      "epoch": 8.209538702111024,
      "grad_norm": 0.3152921199798584,
      "learning_rate": 1.7912431587177482e-05,
      "loss": 0.0502,
      "step": 10500
    },
    {
      "epoch": 8.209538702111024,
      "step": 10500,
      "train/forward_time_ms": 2.6786327362060547,
      "train/loss": 0.07082292437553406,
      "train/loss_affordance": 0.02564812730997801,
      "train/loss_compute_time_ms": 0.3941059112548828,
      "train/loss_risk": 0.02564812730997801,
      "train/loss_structure": 0.01952666975557804
    },
    {
      "epoch": 8.209538702111024,
      "step": 10500,
      "train/forward_time_ms": 4.135260581970215,
      "train/step_time_ms": 4.135675430297852
    },
    {
      "epoch": 8.248631743549648,
      "grad_norm": 0.2911500930786133,
      "learning_rate": 1.7521501172791243e-05,
      "loss": 0.0502,
      "step": 10550
    },
    {
      "epoch": 8.248631743549648,
      "step": 10550,
      "train/forward_time_ms": 2.292156219482422,
      "train/loss": 0.1008014976978302,
      "train/loss_affordance": 0.03326942026615143,
      "train/loss_compute_time_ms": 0.30684471130371094,
      "train/loss_risk": 0.03326942026615143,
      "train/loss_structure": 0.034262657165527344
    },
    {
      "epoch": 8.248631743549648,
      "step": 10550,
      "train/forward_time_ms": 4.119234085083008,
      "train/step_time_ms": 4.119620323181152
    },
    {
      "epoch": 8.287724784988272,
      "grad_norm": 0.5452064275741577,
      "learning_rate": 1.7130570758405003e-05,
      "loss": 0.0528,
      "step": 10600
    },
    {
      "epoch": 8.287724784988272,
      "step": 10600,
      "train/forward_time_ms": 2.5987625122070312,
      "train/loss": 0.038911230862140656,
      "train/loss_affordance": 0.015104728750884533,
      "train/loss_compute_time_ms": 0.3631114959716797,
      "train/loss_risk": 0.015104728750884533,
      "train/loss_structure": 0.00870177336037159
    },
    {
      "epoch": 8.287724784988272,
      "step": 10600,
      "train/forward_time_ms": 4.470205307006836,
      "train/step_time_ms": 4.470682144165039
    },
    {
      "epoch": 8.326817826426897,
      "grad_norm": 0.34693047404289246,
      "learning_rate": 1.6739640344018763e-05,
      "loss": 0.0499,
      "step": 10650
    },
    {
      "epoch": 8.326817826426897,
      "step": 10650,
      "train/forward_time_ms": 2.3262500762939453,
      "train/loss": 0.036337960511446,
      "train/loss_affordance": 0.010615888983011246,
      "train/loss_compute_time_ms": 0.3070831298828125,
      "train/loss_risk": 0.010615888983011246,
      "train/loss_structure": 0.015106182545423508
    },
    {
      "epoch": 8.326817826426897,
      "step": 10650,
      "train/forward_time_ms": 4.117927551269531,
      "train/step_time_ms": 4.118289947509766
    },
    {
      "epoch": 8.36591086786552,
      "grad_norm": 0.4766087234020233,
      "learning_rate": 1.6348709929632527e-05,
      "loss": 0.0518,
      "step": 10700
    },
    {
      "epoch": 8.36591086786552,
      "step": 10700,
      "train/forward_time_ms": 2.20489501953125,
      "train/loss": 0.038699183613061905,
      "train/loss_affordance": 0.015848627546802163,
      "train/loss_compute_time_ms": 0.2818107604980469,
      "train/loss_risk": 0.015848627546802163,
      "train/loss_structure": 0.007001928519457579
    },
    {
      "epoch": 8.36591086786552,
      "step": 10700,
      "train/forward_time_ms": 4.240145683288574,
      "train/step_time_ms": 4.240560531616211
    },
    {
      "epoch": 8.405003909304144,
      "grad_norm": 0.08941135555505753,
      "learning_rate": 1.5957779515246287e-05,
      "loss": 0.0495,
      "step": 10750
    },
    {
      "epoch": 8.405003909304144,
      "step": 10750,
      "train/forward_time_ms": 2.3932456970214844,
      "train/loss": 0.04896433651447296,
      "train/loss_affordance": 0.018390635028481483,
      "train/loss_compute_time_ms": 0.3437995910644531,
      "train/loss_risk": 0.018390635028481483,
      "train/loss_structure": 0.012183066457509995
    },
    {
      "epoch": 8.405003909304144,
      "step": 10750,
      "train/forward_time_ms": 4.161062240600586,
      "train/step_time_ms": 4.161510467529297
    },
    {
      "epoch": 8.444096950742768,
      "grad_norm": 0.49648916721343994,
      "learning_rate": 1.5566849100860047e-05,
      "loss": 0.051,
      "step": 10800
    },
    {
      "epoch": 8.444096950742768,
      "step": 10800,
      "train/forward_time_ms": 2.6819705963134766,
      "train/loss": 0.046062447130680084,
      "train/loss_affordance": 0.011014985851943493,
      "train/loss_compute_time_ms": 0.41675567626953125,
      "train/loss_risk": 0.011014985851943493,
      "train/loss_structure": 0.0240324754267931
    },
    {
      "epoch": 8.444096950742768,
      "step": 10800,
      "train/forward_time_ms": 4.168186187744141,
      "train/step_time_ms": 4.168572425842285
    },
    {
      "epoch": 8.483189992181392,
      "grad_norm": 0.16644960641860962,
      "learning_rate": 1.5175918686473809e-05,
      "loss": 0.0473,
      "step": 10850
    },
    {
      "epoch": 8.483189992181392,
      "step": 10850,
      "train/forward_time_ms": 2.6798248291015625,
      "train/loss": 0.05465759336948395,
      "train/loss_affordance": 0.019897437188774347,
      "train/loss_compute_time_ms": 0.30875205993652344,
      "train/loss_risk": 0.019897437188774347,
      "train/loss_structure": 0.014862718991935253
    },
    {
      "epoch": 8.483189992181392,
      "step": 10850,
      "train/forward_time_ms": 4.367632865905762,
      "train/step_time_ms": 4.368066787719727
    },
    {
      "epoch": 8.522283033620015,
      "grad_norm": 0.4391929805278778,
      "learning_rate": 1.478498827208757e-05,
      "loss": 0.049,
      "step": 10900
    },
    {
      "epoch": 8.522283033620015,
      "step": 10900,
      "train/forward_time_ms": 2.536773681640625,
      "train/loss": 0.041858915239572525,
      "train/loss_affordance": 0.015464772935956717,
      "train/loss_compute_time_ms": 0.3032684326171875,
      "train/loss_risk": 0.015464772935956717,
      "train/loss_structure": 0.010929369367659092
    },
    {
      "epoch": 8.522283033620015,
      "step": 10900,
      "train/forward_time_ms": 4.224381446838379,
      "train/step_time_ms": 4.224820137023926
    },
    {
      "epoch": 8.56137607505864,
      "grad_norm": 0.6006852984428406,
      "learning_rate": 1.439405785770133e-05,
      "loss": 0.0518,
      "step": 10950
    },
    {
      "epoch": 8.56137607505864,
      "step": 10950,
      "train/forward_time_ms": 2.490520477294922,
      "train/loss": 0.07078161835670471,
      "train/loss_affordance": 0.02466635685414076,
      "train/loss_compute_time_ms": 0.3886222839355469,
      "train/loss_risk": 0.02466635685414076,
      "train/loss_structure": 0.021448904648423195
    },
    {
      "epoch": 8.56137607505864,
      "step": 10950,
      "train/forward_time_ms": 4.231877326965332,
      "train/step_time_ms": 4.232301712036133
    },
    {
      "epoch": 8.600469116497264,
      "grad_norm": 0.41987574100494385,
      "learning_rate": 1.400312744331509e-05,
      "loss": 0.0499,
      "step": 11000
    },
    {
      "epoch": 8.600469116497264,
      "step": 11000,
      "train/forward_time_ms": 2.3446083068847656,
      "train/loss": 0.039776936173439026,
      "train/loss_affordance": 0.012504983227699995,
      "train/loss_compute_time_ms": 0.3497600555419922,
      "train/loss_risk": 0.012504983227699995,
      "train/loss_structure": 0.014766969718039036
    },
    {
      "epoch": 8.600469116497264,
      "step": 11000,
      "train/forward_time_ms": 4.268951416015625,
      "train/step_time_ms": 4.269380569458008
    },
    {
      "epoch": 8.639562157935888,
      "grad_norm": 0.3990628719329834,
      "learning_rate": 1.3612197028928852e-05,
      "loss": 0.0522,
      "step": 11050
    },
    {
      "epoch": 8.639562157935888,
      "step": 11050,
      "train/forward_time_ms": 2.4001598358154297,
      "train/loss": 0.0348578542470932,
      "train/loss_affordance": 0.013802420347929,
      "train/loss_compute_time_ms": 0.3516674041748047,
      "train/loss_risk": 0.013802420347929,
      "train/loss_structure": 0.007253013551235199
    },
    {
      "epoch": 8.639562157935888,
      "step": 11050,
      "train/forward_time_ms": 4.262738227844238,
      "train/step_time_ms": 4.263157844543457
    },
    {
      "epoch": 8.67865519937451,
      "grad_norm": 0.30403584241867065,
      "learning_rate": 1.3221266614542612e-05,
      "loss": 0.0487,
      "step": 11100
    },
    {
      "epoch": 8.67865519937451,
      "step": 11100,
      "train/forward_time_ms": 2.4356842041015625,
      "train/loss": 0.043550681322813034,
      "train/loss_affordance": 0.015308531001210213,
      "train/loss_compute_time_ms": 0.3437995910644531,
      "train/loss_risk": 0.015308531001210213,
      "train/loss_structure": 0.012933619320392609
    },
    {
      "epoch": 8.67865519937451,
      "step": 11100,
      "train/forward_time_ms": 4.538722038269043,
      "train/step_time_ms": 4.5391845703125
    },
    {
      "epoch": 8.717748240813135,
      "grad_norm": 0.22786083817481995,
      "learning_rate": 1.2830336200156374e-05,
      "loss": 0.0485,
      "step": 11150
    },
    {
      "epoch": 8.717748240813135,
      "step": 11150,
      "train/forward_time_ms": 2.0329952239990234,
      "train/loss": 0.0406489372253418,
      "train/loss_affordance": 0.014239273499697447,
      "train/loss_compute_time_ms": 0.2830028533935547,
      "train/loss_risk": 0.014239273499697447,
      "train/loss_structure": 0.012170390225946903
    },
    {
      "epoch": 8.717748240813135,
      "step": 11150,
      "train/forward_time_ms": 4.273538589477539,
      "train/step_time_ms": 4.27396297454834
    },
    {
      "epoch": 8.75684128225176,
      "grad_norm": 0.23916999995708466,
      "learning_rate": 1.2439405785770134e-05,
      "loss": 0.0502,
      "step": 11200
    },
    {
      "epoch": 8.75684128225176,
      "step": 11200,
      "train/forward_time_ms": 2.383708953857422,
      "train/loss": 0.07574710249900818,
      "train/loss_affordance": 0.027873695828020573,
      "train/loss_compute_time_ms": 0.32067298889160156,
      "train/loss_risk": 0.027873695828020573,
      "train/loss_structure": 0.019999710842967033
    },
    {
      "epoch": 8.75684128225176,
      "step": 11200,
      "train/forward_time_ms": 4.196405410766602,
      "train/step_time_ms": 4.196815490722656
    },
    {
      "epoch": 8.795934323690384,
      "grad_norm": 0.496272474527359,
      "learning_rate": 1.2048475371383894e-05,
      "loss": 0.0497,
      "step": 11250
    },
    {
      "epoch": 8.795934323690384,
      "step": 11250,
      "train/forward_time_ms": 2.341747283935547,
      "train/loss": 0.05103215575218201,
      "train/loss_affordance": 0.020425520837306976,
      "train/loss_compute_time_ms": 0.3573894500732422,
      "train/loss_risk": 0.020425520837306976,
      "train/loss_structure": 0.010181114077568054
    },
    {
      "epoch": 8.795934323690384,
      "step": 11250,
      "train/forward_time_ms": 4.271678924560547,
      "train/step_time_ms": 4.272103309631348
    },
    {
      "epoch": 8.835027365129006,
      "grad_norm": 0.13352079689502716,
      "learning_rate": 1.1657544956997656e-05,
      "loss": 0.0507,
      "step": 11300
    },
    {
      "epoch": 8.835027365129006,
      "step": 11300,
      "train/forward_time_ms": 2.0990371704101562,
      "train/loss": 0.05389732867479324,
      "train/loss_affordance": 0.015563180670142174,
      "train/loss_compute_time_ms": 0.2560615539550781,
      "train/loss_risk": 0.015563180670142174,
      "train/loss_structure": 0.022770967334508896
    },
    {
      "epoch": 8.835027365129006,
      "step": 11300,
      "train/forward_time_ms": 4.2070770263671875,
      "train/step_time_ms": 4.207501411437988
    },
    {
      "epoch": 8.87412040656763,
      "grad_norm": 0.5925303101539612,
      "learning_rate": 1.1266614542611417e-05,
      "loss": 0.0532,
      "step": 11350
    },
    {
      "epoch": 8.87412040656763,
      "step": 11350,
      "train/forward_time_ms": 2.6078224182128906,
      "train/loss": 0.046637021005153656,
      "train/loss_affordance": 0.01756242336705327,
      "train/loss_compute_time_ms": 0.3323554992675781,
      "train/loss_risk": 0.01756242336705327,
      "train/loss_structure": 0.011512174271047115
    },
    {
      "epoch": 8.87412040656763,
      "step": 11350,
      "train/forward_time_ms": 4.486370086669922,
      "train/step_time_ms": 4.486861228942871
    },
    {
      "epoch": 8.913213448006255,
      "grad_norm": 0.22711887955665588,
      "learning_rate": 1.0875684128225177e-05,
      "loss": 0.0508,
      "step": 11400
    },
    {
      "epoch": 8.913213448006255,
      "step": 11400,
      "train/forward_time_ms": 2.363443374633789,
      "train/loss": 0.07692833989858627,
      "train/loss_affordance": 0.03311153128743172,
      "train/loss_compute_time_ms": 0.34999847412109375,
      "train/loss_risk": 0.03311153128743172,
      "train/loss_structure": 0.01070527732372284
    },
    {
      "epoch": 8.913213448006255,
      "step": 11400,
      "train/forward_time_ms": 4.280481338500977,
      "train/step_time_ms": 4.2809247970581055
    },
    {
      "epoch": 8.95230648944488,
      "grad_norm": 0.34925490617752075,
      "learning_rate": 1.0484753713838937e-05,
      "loss": 0.0495,
      "step": 11450
    },
    {
      "epoch": 8.95230648944488,
      "step": 11450,
      "train/forward_time_ms": 2.366304397583008,
      "train/loss": 0.045205265283584595,
      "train/loss_affordance": 0.014809728134423494,
      "train/loss_compute_time_ms": 0.29921531677246094,
      "train/loss_risk": 0.014809728134423494,
      "train/loss_structure": 0.015585809014737606
    },
    {
      "epoch": 8.95230648944488,
      "step": 11450,
      "train/forward_time_ms": 4.123067855834961,
      "train/step_time_ms": 4.123449325561523
    },
    {
      "epoch": 8.991399530883502,
      "grad_norm": 0.2399785816669464,
      "learning_rate": 1.0093823299452699e-05,
      "loss": 0.0498,
      "step": 11500
    },
    {
      "epoch": 8.991399530883502,
      "step": 11500,
      "train/forward_time_ms": 2.511739730834961,
      "train/loss": 0.03691018000245094,
      "train/loss_affordance": 0.014374849386513233,
      "train/loss_compute_time_ms": 0.4191398620605469,
      "train/loss_risk": 0.014374849386513233,
      "train/loss_structure": 0.008160481229424477
    },
    {
      "epoch": 8.991399530883502,
      "step": 11500,
      "train/forward_time_ms": 4.2110395431518555,
      "train/step_time_ms": 4.21142578125
    },
    {
      "epoch": 9.030492572322126,
      "grad_norm": 0.16097979247570038,
      "learning_rate": 9.70289288506646e-06,
      "loss": 0.0518,
      "step": 11550
    },
    {
      "epoch": 9.030492572322126,
      "step": 11550,
      "train/forward_time_ms": 2.956867218017578,
      "train/loss": 0.042309150099754333,
      "train/loss_affordance": 0.011312039569020271,
      "train/loss_compute_time_ms": 0.4603862762451172,
      "train/loss_risk": 0.011312039569020271,
      "train/loss_structure": 0.01968507096171379
    },
    {
      "epoch": 9.030492572322126,
      "step": 11550,
      "train/forward_time_ms": 4.302349090576172,
      "train/step_time_ms": 4.302763938903809
    },
    {
      "epoch": 9.06958561376075,
      "grad_norm": 0.3945584297180176,
      "learning_rate": 9.31196247068022e-06,
      "loss": 0.0498,
      "step": 11600
    },
    {
      "epoch": 9.06958561376075,
      "step": 11600,
      "train/forward_time_ms": 2.574920654296875,
      "train/loss": 0.03922237083315849,
      "train/loss_affordance": 0.012517916038632393,
      "train/loss_compute_time_ms": 0.31757354736328125,
      "train/loss_risk": 0.012517916038632393,
      "train/loss_structure": 0.014186538755893707
    },
    {
      "epoch": 9.06958561376075,
      "step": 11600,
      "train/forward_time_ms": 4.380903244018555,
      "train/step_time_ms": 4.381322860717773
    },
    {
      "epoch": 9.108678655199375,
      "grad_norm": 0.40960490703582764,
      "learning_rate": 8.92103205629398e-06,
      "loss": 0.0486,
      "step": 11650
    },
    {
      "epoch": 9.108678655199375,
      "step": 11650,
      "train/forward_time_ms": 2.264261245727539,
      "train/loss": 0.05519728362560272,
      "train/loss_affordance": 0.017796403728425503,
      "train/loss_compute_time_ms": 0.2751350402832031,
      "train/loss_risk": 0.017796403728425503,
      "train/loss_structure": 0.019604476168751717
    },
    {
      "epoch": 9.108678655199375,
      "step": 11650,
      "train/forward_time_ms": 4.170985221862793,
      "train/step_time_ms": 4.171414375305176
    },
    {
      "epoch": 9.147771696637998,
      "grad_norm": 0.32921862602233887,
      "learning_rate": 8.530101641907742e-06,
      "loss": 0.0502,
      "step": 11700
    },
    {
      "epoch": 9.147771696637998,
      "step": 11700,
      "train/forward_time_ms": 2.3279190063476562,
      "train/loss": 0.055201247334480286,
      "train/loss_affordance": 0.019750703126192093,
      "train/loss_compute_time_ms": 0.3132820129394531,
      "train/loss_risk": 0.019750703126192093,
      "train/loss_structure": 0.0156998410820961
    },
    {
      "epoch": 9.147771696637998,
      "step": 11700,
      "train/forward_time_ms": 4.213113784790039,
      "train/step_time_ms": 4.21351432800293
    },
    {
      "epoch": 9.186864738076622,
      "grad_norm": 0.19737853109836578,
      "learning_rate": 8.139171227521502e-06,
      "loss": 0.0494,
      "step": 11750
    },
    {
      "epoch": 9.186864738076622,
      "step": 11750,
      "train/forward_time_ms": 2.258777618408203,
      "train/loss": 0.033130716532468796,
      "train/loss_affordance": 0.011793646961450577,
      "train/loss_compute_time_ms": 0.2644062042236328,
      "train/loss_risk": 0.011793646961450577,
      "train/loss_structure": 0.009543422609567642
    },
    {
      "epoch": 9.186864738076622,
      "step": 11750,
      "train/forward_time_ms": 4.318361282348633,
      "train/step_time_ms": 4.318780899047852
    },
    {
      "epoch": 9.225957779515246,
      "grad_norm": 0.15872903168201447,
      "learning_rate": 7.748240813135262e-06,
      "loss": 0.0519,
      "step": 11800
    },
    {
      "epoch": 9.225957779515246,
      "step": 11800,
      "train/forward_time_ms": 3.4227371215820312,
      "train/loss": 0.051938723772764206,
      "train/loss_affordance": 0.017208563163876534,
      "train/loss_compute_time_ms": 0.48422813415527344,
      "train/loss_risk": 0.017208563163876534,
      "train/loss_structure": 0.01752159744501114
    },
    {
      "epoch": 9.225957779515246,
      "step": 11800,
      "train/forward_time_ms": 4.397649765014648,
      "train/step_time_ms": 4.398078918457031
    },
    {
      "epoch": 9.26505082095387,
      "grad_norm": 0.30565035343170166,
      "learning_rate": 7.357310398749023e-06,
      "loss": 0.0465,
      "step": 11850
    },
    {
      "epoch": 9.26505082095387,
      "step": 11850,
      "train/forward_time_ms": 2.3300647735595703,
      "train/loss": 0.06069481745362282,
      "train/loss_affordance": 0.025911149103194475,
      "train/loss_compute_time_ms": 0.29778480529785156,
      "train/loss_risk": 0.025911149103194475,
      "train/loss_structure": 0.008872519247233868
    },
    {
      "epoch": 9.26505082095387,
      "step": 11850,
      "train/forward_time_ms": 4.2459869384765625,
      "train/step_time_ms": 4.246397018432617
    },
    {
      "epoch": 9.304143862392493,
      "grad_norm": 0.14104562997817993,
      "learning_rate": 6.9663799843627835e-06,
      "loss": 0.052,
      "step": 11900
    },
    {
      "epoch": 9.304143862392493,
      "step": 11900,
      "train/forward_time_ms": 2.2737979888916016,
      "train/loss": 0.06397615373134613,
      "train/loss_affordance": 0.021007653325796127,
      "train/loss_compute_time_ms": 0.335693359375,
      "train/loss_risk": 0.021007653325796127,
      "train/loss_structure": 0.021960847079753876
    },
    {
      "epoch": 9.304143862392493,
      "step": 11900,
      "train/forward_time_ms": 4.227819442749023,
      "train/step_time_ms": 4.22823429107666
    },
    {
      "epoch": 9.343236903831118,
      "grad_norm": 0.4995269179344177,
      "learning_rate": 6.575449569976544e-06,
      "loss": 0.0489,
      "step": 11950
    },
    {
      "epoch": 9.343236903831118,
      "step": 11950,
      "train/forward_time_ms": 2.2704601287841797,
      "train/loss": 0.05132494121789932,
      "train/loss_affordance": 0.02049132203683257,
      "train/loss_compute_time_ms": 0.3132820129394531,
      "train/loss_risk": 0.02049132203683257,
      "train/loss_structure": 0.01034229714423418
    },
    {
      "epoch": 9.343236903831118,
      "step": 11950,
      "train/forward_time_ms": 4.207248687744141,
      "train/step_time_ms": 4.207677841186523
    },
    {
      "epoch": 9.382329945269742,
      "grad_norm": 0.38690271973609924,
      "learning_rate": 6.184519155590305e-06,
      "loss": 0.052,
      "step": 12000
    },
    {
      "epoch": 9.382329945269742,
      "step": 12000,
      "train/forward_time_ms": 2.3255348205566406,
      "train/loss": 0.035046663135290146,
      "train/loss_affordance": 0.014556158799678087,
      "train/loss_compute_time_ms": 0.34737586975097656,
      "train/loss_risk": 0.014556158799678087,
      "train/loss_structure": 0.005934345535933971
    },
    {
      "epoch": 9.382329945269742,
      "step": 12000,
      "train/forward_time_ms": 4.162440299987793,
      "train/step_time_ms": 4.1628217697143555
    },
    {
      "epoch": 9.421422986708366,
      "grad_norm": 0.13851298391819,
      "learning_rate": 5.793588741204066e-06,
      "loss": 0.0489,
      "step": 12050
    },
    {
      "epoch": 9.421422986708366,
      "step": 12050,
      "train/forward_time_ms": 2.301454544067383,
      "train/loss": 0.057450637221336365,
      "train/loss_affordance": 0.021746373269706964,
      "train/loss_compute_time_ms": 0.34427642822265625,
      "train/loss_risk": 0.021746373269706964,
      "train/loss_structure": 0.013957890681922436
    },
    {
      "epoch": 9.421422986708366,
      "step": 12050,
      "train/forward_time_ms": 4.355859756469727,
      "train/step_time_ms": 4.3563127517700195
    },
    {
      "epoch": 9.46051602814699,
      "grad_norm": 0.3250865936279297,
      "learning_rate": 5.402658326817827e-06,
      "loss": 0.0486,
      "step": 12100
    },
    {
      "epoch": 9.46051602814699,
      "step": 12100,
      "train/forward_time_ms": 2.705097198486328,
      "train/loss": 0.05286616086959839,
      "train/loss_affordance": 0.01827007532119751,
      "train/loss_compute_time_ms": 0.28896331787109375,
      "train/loss_risk": 0.01827007532119751,
      "train/loss_structure": 0.01632601022720337
    },
    {
      "epoch": 9.46051602814699,
      "step": 12100,
      "train/forward_time_ms": 4.25933837890625,
      "train/step_time_ms": 4.259772300720215
    },
    {
      "epoch": 9.499609069585613,
      "grad_norm": 0.4129270315170288,
      "learning_rate": 5.011727912431587e-06,
      "loss": 0.0516,
      "step": 12150
    },
    {
      "epoch": 9.499609069585613,
      "step": 12150,
      "train/forward_time_ms": 2.6268959045410156,
      "train/loss": 0.054235655814409256,
      "train/loss_affordance": 0.022624550387263298,
      "train/loss_compute_time_ms": 0.3094673156738281,
      "train/loss_risk": 0.022624550387263298,
      "train/loss_structure": 0.00898655503988266
    },
    {
      "epoch": 9.499609069585613,
      "step": 12150,
      "train/forward_time_ms": 4.255561828613281,
      "train/step_time_ms": 4.255990982055664
    },
    {
      "epoch": 9.538702111024238,
      "grad_norm": 0.19058048725128174,
      "learning_rate": 4.620797498045348e-06,
      "loss": 0.0495,
      "step": 12200
    },
    {
      "epoch": 9.538702111024238,
      "step": 12200,
      "train/forward_time_ms": 2.4051666259765625,
      "train/loss": 0.047515563666820526,
      "train/loss_affordance": 0.016089328099042177,
      "train/loss_compute_time_ms": 0.3170967102050781,
      "train/loss_risk": 0.016089328099042177,
      "train/loss_structure": 0.015336907468736172
    },
    {
      "epoch": 9.538702111024238,
      "step": 12200,
      "train/forward_time_ms": 4.121460914611816,
      "train/step_time_ms": 4.121842384338379
    },
    {
      "epoch": 9.577795152462862,
      "grad_norm": 0.521176815032959,
      "learning_rate": 4.229867083659109e-06,
      "loss": 0.0501,
      "step": 12250
    },
    {
      "epoch": 9.577795152462862,
      "step": 12250,
      "train/forward_time_ms": 2.3984909057617188,
      "train/loss": 0.044854942709207535,
      "train/loss_affordance": 0.015213684178888798,
      "train/loss_compute_time_ms": 0.30994415283203125,
      "train/loss_risk": 0.015213684178888798,
      "train/loss_structure": 0.01442757435142994
    },
    {
      "epoch": 9.577795152462862,
      "step": 12250,
      "train/forward_time_ms": 4.236640930175781,
      "train/step_time_ms": 4.23703670501709
    },
    {
      "epoch": 9.616888193901486,
      "grad_norm": 0.552628755569458,
      "learning_rate": 3.83893666927287e-06,
      "loss": 0.0499,
      "step": 12300
    },
    {
      "epoch": 9.616888193901486,
      "step": 12300,
      "train/forward_time_ms": 2.372264862060547,
      "train/loss": 0.03023134171962738,
      "train/loss_affordance": 0.012258868664503098,
      "train/loss_compute_time_ms": 0.3070831298828125,
      "train/loss_risk": 0.012258868664503098,
      "train/loss_structure": 0.005713604390621185
    },
    {
      "epoch": 9.616888193901486,
      "step": 12300,
      "train/forward_time_ms": 4.385967254638672,
      "train/step_time_ms": 4.386439323425293
    },
    {
      "epoch": 9.655981235340109,
      "grad_norm": 0.18372486531734467,
      "learning_rate": 3.44800625488663e-06,
      "loss": 0.0493,
      "step": 12350
    },
    {
      "epoch": 9.655981235340109,
      "step": 12350,
      "train/forward_time_ms": 2.5396347045898438,
      "train/loss": 0.03437218815088272,
      "train/loss_affordance": 0.013185469899326563,
      "train/loss_compute_time_ms": 0.3142356872558594,
      "train/loss_risk": 0.013185469899326563,
      "train/loss_structure": 0.008001248352229595
    },
    {
      "epoch": 9.655981235340109,
      "step": 12350,
      "train/forward_time_ms": 4.229726791381836,
      "train/step_time_ms": 4.230141639709473
    },
    {
      "epoch": 9.695074276778733,
      "grad_norm": 0.37259557843208313,
      "learning_rate": 3.057075840500391e-06,
      "loss": 0.0505,
      "step": 12400
    },
    {
      "epoch": 9.695074276778733,
      "step": 12400,
      "train/forward_time_ms": 2.626657485961914,
      "train/loss": 0.05216614902019501,
      "train/loss_affordance": 0.01598434802144766,
      "train/loss_compute_time_ms": 0.26988983154296875,
      "train/loss_risk": 0.01598434802144766,
      "train/loss_structure": 0.02019745297729969
    },
    {
      "epoch": 9.695074276778733,
      "step": 12400,
      "train/forward_time_ms": 4.241514205932617,
      "train/step_time_ms": 4.241933822631836
    },
    {
      "epoch": 9.734167318217358,
      "grad_norm": 0.4201670289039612,
      "learning_rate": 2.6661454261141517e-06,
      "loss": 0.0497,
      "step": 12450
    },
    {
      "epoch": 9.734167318217358,
      "step": 12450,
      "train/forward_time_ms": 3.9975643157958984,
      "train/loss": 0.05000753328204155,
      "train/loss_affordance": 0.01629732921719551,
      "train/loss_compute_time_ms": 0.27680397033691406,
      "train/loss_risk": 0.01629732921719551,
      "train/loss_structure": 0.017412874847650528
    },
    {
      "epoch": 9.734167318217358,
      "step": 12450,
      "train/forward_time_ms": 4.1570281982421875,
      "train/step_time_ms": 4.15743350982666
    },
    {
      "epoch": 9.773260359655982,
      "grad_norm": 0.1915726512670517,
      "learning_rate": 2.2752150117279123e-06,
      "loss": 0.0521,
      "step": 12500
    }
  ],
  "logging_steps": 50,
  "max_steps": 12790,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
